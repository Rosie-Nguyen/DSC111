{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd, seaborn as sb, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "\n",
    "TEST_SIZE = 0.4 #TODO: TRY ANOTHER\n",
    "RANDOM_SEED = 0 #TODO: TRY ANOTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('OCTROI.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANC_EMPLOI</th>\n",
       "      <th>STITUATION_FAM</th>\n",
       "      <th>MODE_LOGT</th>\n",
       "      <th>AGE_VEH</th>\n",
       "      <th>VN_VO</th>\n",
       "      <th>MARQUE</th>\n",
       "      <th>PRIX_VEH</th>\n",
       "      <th>MT_APPORT</th>\n",
       "      <th>MT_FINANCE</th>\n",
       "      <th>MT_MENS</th>\n",
       "      <th>VR_BALLON</th>\n",
       "      <th>DUREE_CONTRAT</th>\n",
       "      <th>MT_PREST</th>\n",
       "      <th>MT_ASSUR</th>\n",
       "      <th>MOIS_GESTION</th>\n",
       "      <th>AGE_CLI</th>\n",
       "      <th>ANCIENNETE</th>\n",
       "      <th>CIBLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>19584.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19584.65</td>\n",
       "      <td>95.01</td>\n",
       "      <td>19584.63</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/03/2015</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>563</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>16995.00</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>14872.00</td>\n",
       "      <td>312.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/06/2014</td>\n",
       "      <td>64</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>19950.00</td>\n",
       "      <td>3869.0</td>\n",
       "      <td>16081.00</td>\n",
       "      <td>329.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/08/2015</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>17500.00</td>\n",
       "      <td>7143.5</td>\n",
       "      <td>10356.50</td>\n",
       "      <td>217.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/04/2015</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>19740.00</td>\n",
       "      <td>3789.4</td>\n",
       "      <td>15950.60</td>\n",
       "      <td>310.33</td>\n",
       "      <td>7523.04</td>\n",
       "      <td>36</td>\n",
       "      <td>150.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>01/02/2015</td>\n",
       "      <td>34</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANC_EMPLOI  STITUATION_FAM  MODE_LOGT  AGE_VEH VN_VO MARQUE  PRIX_VEH  \\\n",
       "0          65               2        1.0      NaN    VN    REN  19584.65   \n",
       "1         563              11        2.0     28.0    VO    REN  16995.00   \n",
       "2         107               2        2.0     16.0    VO    REN  19950.00   \n",
       "3         143               2        2.0     10.0    VO    REN  17500.00   \n",
       "4         110               2        NaN      7.0    VO    REN  19740.00   \n",
       "\n",
       "   MT_APPORT  MT_FINANCE  MT_MENS  VR_BALLON  DUREE_CONTRAT  MT_PREST  \\\n",
       "0        0.0    19584.65    95.01   19584.63              6       NaN   \n",
       "1     2123.0    14872.00   312.34        NaN             60     150.0   \n",
       "2     3869.0    16081.00   329.93        NaN             60     150.0   \n",
       "3     7143.5    10356.50   217.51        NaN             60     150.0   \n",
       "4     3789.4    15950.60   310.33    7523.04             36     150.0   \n",
       "\n",
       "   MT_ASSUR MOIS_GESTION  AGE_CLI  ANCIENNETE  CIBLE  \n",
       "0       NaN   01/03/2015       28         1.0      0  \n",
       "1       NaN   01/06/2014       64         3.0      0  \n",
       "2       NaN   01/08/2015       51         3.0      0  \n",
       "3       NaN   01/04/2015       42         4.0      0  \n",
       "4     395.0   01/02/2015       34         4.0      0  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8457"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['CIBLE'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANC_EMPLOI</th>\n",
       "      <th>STITUATION_FAM</th>\n",
       "      <th>MODE_LOGT</th>\n",
       "      <th>AGE_VEH</th>\n",
       "      <th>VN_VO</th>\n",
       "      <th>MARQUE</th>\n",
       "      <th>PRIX_VEH</th>\n",
       "      <th>MT_APPORT</th>\n",
       "      <th>MT_FINANCE</th>\n",
       "      <th>MT_MENS</th>\n",
       "      <th>VR_BALLON</th>\n",
       "      <th>DUREE_CONTRAT</th>\n",
       "      <th>MT_PREST</th>\n",
       "      <th>MT_ASSUR</th>\n",
       "      <th>MOIS_GESTION</th>\n",
       "      <th>AGE_CLI</th>\n",
       "      <th>ANCIENNETE</th>\n",
       "      <th>CIBLE</th>\n",
       "      <th>ANNEE_GESTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>19584.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19584.65</td>\n",
       "      <td>95.01</td>\n",
       "      <td>19584.63</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>563</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>16995.00</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>14872.00</td>\n",
       "      <td>312.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>19950.00</td>\n",
       "      <td>3869.0</td>\n",
       "      <td>16081.00</td>\n",
       "      <td>329.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>17500.00</td>\n",
       "      <td>7143.5</td>\n",
       "      <td>10356.50</td>\n",
       "      <td>217.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>19740.00</td>\n",
       "      <td>3789.4</td>\n",
       "      <td>15950.60</td>\n",
       "      <td>310.33</td>\n",
       "      <td>7523.04</td>\n",
       "      <td>36</td>\n",
       "      <td>150.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANC_EMPLOI STITUATION_FAM MODE_LOGT  AGE_VEH VN_VO MARQUE  PRIX_VEH  \\\n",
       "0          65              2       1.0      NaN    VN    REN  19584.65   \n",
       "1         563             11       2.0     28.0    VO    REN  16995.00   \n",
       "2         107              2       2.0     16.0    VO    REN  19950.00   \n",
       "3         143              2       2.0     10.0    VO    REN  17500.00   \n",
       "4         110              2       nan      7.0    VO    REN  19740.00   \n",
       "\n",
       "   MT_APPORT  MT_FINANCE  MT_MENS  VR_BALLON  DUREE_CONTRAT  MT_PREST  \\\n",
       "0        0.0    19584.65    95.01   19584.63              6       NaN   \n",
       "1     2123.0    14872.00   312.34        NaN             60     150.0   \n",
       "2     3869.0    16081.00   329.93        NaN             60     150.0   \n",
       "3     7143.5    10356.50   217.51        NaN             60     150.0   \n",
       "4     3789.4    15950.60   310.33    7523.04             36     150.0   \n",
       "\n",
       "   MT_ASSUR  MOIS_GESTION  AGE_CLI  ANCIENNETE  CIBLE  ANNEE_GESTION  \n",
       "0       NaN             3       28         1.0      0           2015  \n",
       "1       NaN             6       64         3.0      0           2014  \n",
       "2       NaN             8       51         3.0      0           2015  \n",
       "3       NaN             4       42         4.0      0           2015  \n",
       "4     395.0             2       34         4.0      0           2015  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STITUATION_FAM'] = df['STITUATION_FAM'].astype('str')\n",
    "df['MODE_LOGT'] = df['MODE_LOGT'].astype('str')\n",
    "df['ANNEE_GESTION'] = df['MOIS_GESTION'].str[-4:].astype('int')\n",
    "df['MOIS_GESTION'] = df['MOIS_GESTION'].str[3:5].astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANC_EMPLOI :  0\n",
      "STITUATION_FAM :  0\n",
      "MODE_LOGT :  0\n",
      "AGE_VEH :  6003\n",
      "VN_VO :  0\n",
      "MARQUE :  0\n",
      "PRIX_VEH :  0\n",
      "MT_APPORT :  0\n",
      "MT_FINANCE :  0\n",
      "MT_MENS :  0\n",
      "VR_BALLON :  5238\n",
      "DUREE_CONTRAT :  0\n",
      "MT_PREST :  1280\n",
      "MT_ASSUR :  6755\n",
      "MOIS_GESTION :  0\n",
      "AGE_CLI :  0\n",
      "ANCIENNETE :  7271\n",
      "CIBLE :  0\n",
      "ANNEE_GESTION :  0\n",
      "The following columns are to be kept:\n",
      "['ANC_EMPLOI', 'STITUATION_FAM', 'MODE_LOGT', 'VN_VO', 'MARQUE', 'PRIX_VEH', 'MT_APPORT', 'MT_FINANCE', 'MT_MENS', 'DUREE_CONTRAT', 'MT_PREST', 'MOIS_GESTION', 'AGE_CLI', 'ANNEE_GESTION']\n",
      "['MT_PREST']\n"
     ]
    }
   ],
   "source": [
    "columns_to_be_kept = []\n",
    "columns_to_review = []\n",
    "columns_with_nan_kept = []\n",
    "\n",
    "for colName in df.columns:\n",
    "    nb_of_nans = df[colName].isna().sum()\n",
    "    print(colName, \": \", nb_of_nans)\n",
    "    if nb_of_nans/N < 0.2 and colName != 'CIBLE':\n",
    "        columns_to_be_kept.append(colName)\n",
    "        if nb_of_nans > 0:\n",
    "            columns_with_nan_kept.append(colName)\n",
    "    else:\n",
    "        columns_to_review.append(colName)\n",
    "\n",
    "print('The following columns are to be kept:')\n",
    "print(columns_to_be_kept)\n",
    "print(columns_with_nan_kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MT_PREST'] = df['MT_PREST'].fillna(round(df['MT_PREST'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANC_EMPLOI</th>\n",
       "      <th>STITUATION_FAM</th>\n",
       "      <th>MODE_LOGT</th>\n",
       "      <th>VN_VO</th>\n",
       "      <th>MARQUE</th>\n",
       "      <th>PRIX_VEH</th>\n",
       "      <th>MT_APPORT</th>\n",
       "      <th>MT_FINANCE</th>\n",
       "      <th>MT_MENS</th>\n",
       "      <th>DUREE_CONTRAT</th>\n",
       "      <th>MT_PREST</th>\n",
       "      <th>MOIS_GESTION</th>\n",
       "      <th>AGE_CLI</th>\n",
       "      <th>ANNEE_GESTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>19584.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19584.65</td>\n",
       "      <td>95.01</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>563</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>16995.00</td>\n",
       "      <td>2123.00</td>\n",
       "      <td>14872.00</td>\n",
       "      <td>312.34</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>19950.00</td>\n",
       "      <td>3869.00</td>\n",
       "      <td>16081.00</td>\n",
       "      <td>329.93</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>17500.00</td>\n",
       "      <td>7143.50</td>\n",
       "      <td>10356.50</td>\n",
       "      <td>217.51</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>19740.00</td>\n",
       "      <td>3789.40</td>\n",
       "      <td>15950.60</td>\n",
       "      <td>310.33</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>DAC</td>\n",
       "      <td>14900.00</td>\n",
       "      <td>7900.00</td>\n",
       "      <td>7000.00</td>\n",
       "      <td>220.97</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>18394.00</td>\n",
       "      <td>5518.00</td>\n",
       "      <td>12876.00</td>\n",
       "      <td>228.72</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>62</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>19923.79</td>\n",
       "      <td>5116.62</td>\n",
       "      <td>14807.17</td>\n",
       "      <td>289.72</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>18500.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>8500.00</td>\n",
       "      <td>180.72</td>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>MER</td>\n",
       "      <td>14000.00</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>329.76</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>21250.00</td>\n",
       "      <td>5450.00</td>\n",
       "      <td>15800.00</td>\n",
       "      <td>309.15</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>16499.00</td>\n",
       "      <td>6499.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>282.08</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>5255.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5255.38</td>\n",
       "      <td>134.56</td>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>15000.00</td>\n",
       "      <td>293.49</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>17390.00</td>\n",
       "      <td>12390.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>227.28</td>\n",
       "      <td>24</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>68</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>23030.00</td>\n",
       "      <td>14730.00</td>\n",
       "      <td>8300.00</td>\n",
       "      <td>254.39</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>DAC</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>18000.00</td>\n",
       "      <td>443.67</td>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>23230.00</td>\n",
       "      <td>3230.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>492.97</td>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>551</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>9000.00</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>6500.00</td>\n",
       "      <td>136.51</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>17300.00</td>\n",
       "      <td>1740.00</td>\n",
       "      <td>15560.00</td>\n",
       "      <td>319.24</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>DAC</td>\n",
       "      <td>14500.00</td>\n",
       "      <td>1450.00</td>\n",
       "      <td>13050.00</td>\n",
       "      <td>267.74</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>62</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>DAC</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>18000.00</td>\n",
       "      <td>369.30</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>21595.00</td>\n",
       "      <td>7500.00</td>\n",
       "      <td>14095.00</td>\n",
       "      <td>275.78</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>410</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>FOR</td>\n",
       "      <td>16500.00</td>\n",
       "      <td>3500.00</td>\n",
       "      <td>13000.00</td>\n",
       "      <td>279.42</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>14950.00</td>\n",
       "      <td>2207.31</td>\n",
       "      <td>12742.69</td>\n",
       "      <td>332.44</td>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>20645.00</td>\n",
       "      <td>6750.00</td>\n",
       "      <td>13895.00</td>\n",
       "      <td>438.63</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>22390.00</td>\n",
       "      <td>6783.97</td>\n",
       "      <td>15606.03</td>\n",
       "      <td>440.22</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>DAC</td>\n",
       "      <td>17900.00</td>\n",
       "      <td>3000.00</td>\n",
       "      <td>14900.00</td>\n",
       "      <td>305.70</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>19995.00</td>\n",
       "      <td>5227.00</td>\n",
       "      <td>14768.00</td>\n",
       "      <td>302.99</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>NIS</td>\n",
       "      <td>27945.00</td>\n",
       "      <td>7000.00</td>\n",
       "      <td>20945.00</td>\n",
       "      <td>406.82</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8427</th>\n",
       "      <td>439</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>DAC</td>\n",
       "      <td>14975.88</td>\n",
       "      <td>2975.88</td>\n",
       "      <td>12000.00</td>\n",
       "      <td>246.20</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8428</th>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>DAC</td>\n",
       "      <td>11110.00</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>9910.00</td>\n",
       "      <td>196.65</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8429</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>DAC</td>\n",
       "      <td>16754.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>14754.00</td>\n",
       "      <td>289.17</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8430</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>27900.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>22900.00</td>\n",
       "      <td>357.27</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>14545.00</td>\n",
       "      <td>2700.00</td>\n",
       "      <td>11845.00</td>\n",
       "      <td>181.54</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>DAC</td>\n",
       "      <td>19399.00</td>\n",
       "      <td>4500.00</td>\n",
       "      <td>14899.00</td>\n",
       "      <td>290.13</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8433</th>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>14995.00</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>13495.00</td>\n",
       "      <td>276.87</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8434</th>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>11550.00</td>\n",
       "      <td>1750.00</td>\n",
       "      <td>9800.00</td>\n",
       "      <td>227.02</td>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8435</th>\n",
       "      <td>323</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>SEA</td>\n",
       "      <td>13950.00</td>\n",
       "      <td>3950.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>210.02</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8436</th>\n",
       "      <td>383</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>NIS</td>\n",
       "      <td>15750.00</td>\n",
       "      <td>3750.00</td>\n",
       "      <td>12000.00</td>\n",
       "      <td>252.02</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8437</th>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>DAC</td>\n",
       "      <td>15250.00</td>\n",
       "      <td>1525.00</td>\n",
       "      <td>13725.00</td>\n",
       "      <td>275.02</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8438</th>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>15150.00</td>\n",
       "      <td>10150.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>231.88</td>\n",
       "      <td>24</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8439</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>23250.00</td>\n",
       "      <td>6950.00</td>\n",
       "      <td>16300.00</td>\n",
       "      <td>240.18</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440</th>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>HON</td>\n",
       "      <td>14495.00</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>12995.00</td>\n",
       "      <td>279.31</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>14950.00</td>\n",
       "      <td>2950.00</td>\n",
       "      <td>12000.00</td>\n",
       "      <td>246.20</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8442</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>14500.00</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>13000.00</td>\n",
       "      <td>266.71</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8443</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>17000.00</td>\n",
       "      <td>9000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>197.19</td>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8444</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>19000.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>18000.00</td>\n",
       "      <td>360.68</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8445</th>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>BMW</td>\n",
       "      <td>20390.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>10390.00</td>\n",
       "      <td>218.21</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8446</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>17350.00</td>\n",
       "      <td>9350.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>285.31</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8447</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>NIS</td>\n",
       "      <td>18000.00</td>\n",
       "      <td>9500.00</td>\n",
       "      <td>8500.00</td>\n",
       "      <td>178.52</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>74</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8448</th>\n",
       "      <td>167</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>15000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>13000.00</td>\n",
       "      <td>273.02</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8449</th>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>16800.00</td>\n",
       "      <td>1700.00</td>\n",
       "      <td>15100.00</td>\n",
       "      <td>302.57</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>REN</td>\n",
       "      <td>19250.00</td>\n",
       "      <td>10250.00</td>\n",
       "      <td>9000.00</td>\n",
       "      <td>270.95</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8451</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VO</td>\n",
       "      <td>DAC</td>\n",
       "      <td>14115.00</td>\n",
       "      <td>2165.00</td>\n",
       "      <td>11950.00</td>\n",
       "      <td>250.97</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8452</th>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>20921.05</td>\n",
       "      <td>15921.05</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>148.51</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8453</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>16715.00</td>\n",
       "      <td>4400.00</td>\n",
       "      <td>12315.00</td>\n",
       "      <td>377.44</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8454</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>29325.00</td>\n",
       "      <td>4355.00</td>\n",
       "      <td>24970.00</td>\n",
       "      <td>438.58</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8455</th>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>DAC</td>\n",
       "      <td>10840.00</td>\n",
       "      <td>1584.00</td>\n",
       "      <td>9256.00</td>\n",
       "      <td>174.73</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8456</th>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>REN</td>\n",
       "      <td>24775.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24775.97</td>\n",
       "      <td>150.32</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8457 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ANC_EMPLOI STITUATION_FAM MODE_LOGT VN_VO MARQUE  PRIX_VEH  MT_APPORT  \\\n",
       "0             65              2       1.0    VN    REN  19584.65       0.00   \n",
       "1            563             11       2.0    VO    REN  16995.00    2123.00   \n",
       "2            107              2       2.0    VO    REN  19950.00    3869.00   \n",
       "3            143              2       2.0    VO    REN  17500.00    7143.50   \n",
       "4            110              2       nan    VO    REN  19740.00    3789.40   \n",
       "5            446              1       2.0    VN    DAC  14900.00    7900.00   \n",
       "6            143              1       2.0    VN    REN  18394.00    5518.00   \n",
       "7            108              1       2.0    VN    REN  19923.79    5116.62   \n",
       "8            323              2       2.0    VO    REN  18500.00   10000.00   \n",
       "9             48              1       2.0    VO    MER  14000.00    4000.00   \n",
       "10           155              1       2.0    VN    REN  21250.00    5450.00   \n",
       "11           151              2       2.0    VN    REN  16499.00    6499.00   \n",
       "12           302              1       2.0    VO    REN   5255.38       0.00   \n",
       "13           203              1       2.0    VN    REN  25000.00   10000.00   \n",
       "14           563              1       2.0    VN    REN  17390.00   12390.00   \n",
       "15           234              2       1.0    VN    REN  23030.00   14730.00   \n",
       "16           255              1       2.0    VN    DAC  20000.00    2000.00   \n",
       "17           255              1       2.0    VN    REN  23230.00    3230.00   \n",
       "18           551              1       2.0    VO    REN   9000.00    2500.00   \n",
       "19           287              1       2.0    VN    REN  17300.00    1740.00   \n",
       "20           477              1       2.0    VN    DAC  14500.00    1450.00   \n",
       "21           477              1       2.0    VN    DAC  20000.00    2000.00   \n",
       "22           408              1       2.0    VN    REN  21595.00    7500.00   \n",
       "23           410              1       2.0    VO    FOR  16500.00    3500.00   \n",
       "24           323              1       2.0    VO    REN  14950.00    2207.31   \n",
       "25           203              1       2.0    VN    REN  20645.00    6750.00   \n",
       "26           203              1       2.0    VN    REN  22390.00    6783.97   \n",
       "27           301              1       2.0    VN    DAC  17900.00    3000.00   \n",
       "28            83              1       2.0    VO    REN  19995.00    5227.00   \n",
       "29           102              1       2.0    VN    NIS  27945.00    7000.00   \n",
       "...          ...            ...       ...   ...    ...       ...        ...   \n",
       "8427         439              1       2.0    VN    DAC  14975.88    2975.88   \n",
       "8428         155              1       2.0    VN    DAC  11110.00    1200.00   \n",
       "8429          69              1       1.0    VO    DAC  16754.00    2000.00   \n",
       "8430          35              1       4.0    VN    REN  27900.00    5000.00   \n",
       "8431         419              1       2.0    VN    REN  14545.00    2700.00   \n",
       "8432          41              1       2.0    VN    DAC  19399.00    4500.00   \n",
       "8433          95              2       2.0    VO    REN  14995.00    1500.00   \n",
       "8434         203              3       2.0    VO    REN  11550.00    1750.00   \n",
       "8435         323             11       2.0    VO    SEA  13950.00    3950.00   \n",
       "8436         383              1       2.0    VO    NIS  15750.00    3750.00   \n",
       "8437         191              1       2.0    VO    DAC  15250.00    1525.00   \n",
       "8438         167              1       2.0    VO    REN  15150.00   10150.00   \n",
       "8439          71              1       2.0    VN    REN  23250.00    6950.00   \n",
       "8440          71             11       1.0    VO    HON  14495.00    1500.00   \n",
       "8441          59              2       4.0    VO    REN  14950.00    2950.00   \n",
       "8442         107              1       2.0    VO    REN  14500.00    1500.00   \n",
       "8443         203              1       2.0    VN    REN  17000.00    9000.00   \n",
       "8444          17              1       2.0    VO    REN  19000.00    1000.00   \n",
       "8445         130              1       2.0    VO    BMW  20390.00   10000.00   \n",
       "8446         203              1       2.0    VO    REN  17350.00    9350.00   \n",
       "8447          95              1       2.0    VN    NIS  18000.00    9500.00   \n",
       "8448         167             11       2.0    VO    REN  15000.00    2000.00   \n",
       "8449         119              2       4.0    VO    REN  16800.00    1700.00   \n",
       "8450          81              1       2.0    VO    REN  19250.00   10250.00   \n",
       "8451         203              1       2.0    VO    DAC  14115.00    2165.00   \n",
       "8452         223              1       2.0    VN    REN  20921.05   15921.05   \n",
       "8453          17              2       1.0    VN    REN  16715.00    4400.00   \n",
       "8454         200              1       2.0    VN    REN  29325.00    4355.00   \n",
       "8455         347              1       2.0    VN    DAC  10840.00    1584.00   \n",
       "8456          83             11       2.0    VN    REN  24775.97       0.00   \n",
       "\n",
       "      MT_FINANCE  MT_MENS  DUREE_CONTRAT MT_PREST  MOIS_GESTION  AGE_CLI  \\\n",
       "0       19584.65    95.01              6     None             3       28   \n",
       "1       14872.00   312.34             60     None             6       64   \n",
       "2       16081.00   329.93             60     None             8       51   \n",
       "3       10356.50   217.51             60     None             4       42   \n",
       "4       15950.60   310.33             36     None             2       34   \n",
       "5        7000.00   220.97             36     None             8       55   \n",
       "6       12876.00   228.72             36     None            11       62   \n",
       "7       14807.17   289.72             60     None            11       44   \n",
       "8        8500.00   180.72             48     None            10       44   \n",
       "9       10000.00   329.76             36     None             5       38   \n",
       "10      15800.00   309.15             60     None             9       55   \n",
       "11      10000.00   282.08             36     None            10       51   \n",
       "12       5255.38   134.56             48     None             4       49   \n",
       "13      15000.00   293.49             60     None            10       44   \n",
       "14       5000.00   227.28             24     None             9       68   \n",
       "15       8300.00   254.39             36     None             4       35   \n",
       "16      18000.00   443.67             48     None             4       44   \n",
       "17      20000.00   492.97             48     None             7       44   \n",
       "18       6500.00   136.51             60     None             8       75   \n",
       "19      15560.00   319.24             60     None             1       56   \n",
       "20      13050.00   267.74             60     None            11       62   \n",
       "21      18000.00   369.30             60     None            10       63   \n",
       "22      14095.00   275.78             60     None             4       64   \n",
       "23      13000.00   279.42             60     None            11       51   \n",
       "24      12742.69   332.44             48     None             3       60   \n",
       "25      13895.00   438.63             36     None            12       50   \n",
       "26      15606.03   440.22             36     None             9       51   \n",
       "27      14900.00   305.70             60     None             3       60   \n",
       "28      14768.00   302.99             60     None             8       61   \n",
       "29      20945.00   406.82             36     None             3       43   \n",
       "...          ...      ...            ...      ...           ...      ...   \n",
       "8427    12000.00   246.20             60     None            11       65   \n",
       "8428     9910.00   196.65             36     None            11       32   \n",
       "8429    14754.00   289.17             36     None             1       44   \n",
       "8430    22900.00   357.27             36     None            11       31   \n",
       "8431    11845.00   181.54             36     None            11       53   \n",
       "8432    14899.00   290.13             36     None            11       42   \n",
       "8433    13495.00   276.87             60     None            11       29   \n",
       "8434     9800.00   227.02             48     None            11       45   \n",
       "8435    10000.00   210.02             60     None            11       55   \n",
       "8436    12000.00   252.02             60     None            11       59   \n",
       "8437    13725.00   275.02             60     None            11       64   \n",
       "8438     5000.00   231.88             24     None            11       36   \n",
       "8439    16300.00   240.18             36     None            11       36   \n",
       "8440    12995.00   279.31             60     None            11       55   \n",
       "8441    12000.00   246.20             60     None            11       23   \n",
       "8442    13000.00   266.71             60     None            11       46   \n",
       "8443     8000.00   197.19             48     None            11       44   \n",
       "8444    18000.00   360.68             60     None            11       30   \n",
       "8445    10390.00   218.21             60     None            11       59   \n",
       "8446     8000.00   285.31             30     None            11       49   \n",
       "8447     8500.00   178.52             60     None            11       74   \n",
       "8448    13000.00   273.02             60     None            11       44   \n",
       "8449    15100.00   302.57             60     None            11       33   \n",
       "8450     9000.00   270.95             36     None            11       44   \n",
       "8451    11950.00   250.97             60     None            11       70   \n",
       "8452     5000.00   148.51             36     None            11       45   \n",
       "8453    12315.00   377.44             36     None             1       26   \n",
       "8454    24970.00   438.58             36     None             1       41   \n",
       "8455     9256.00   174.73             36     None             5       49   \n",
       "8456    24775.97   150.32              6     None             8       29   \n",
       "\n",
       "      ANNEE_GESTION  \n",
       "0              2015  \n",
       "1              2014  \n",
       "2              2015  \n",
       "3              2015  \n",
       "4              2015  \n",
       "5              2015  \n",
       "6              2014  \n",
       "7              2014  \n",
       "8              2015  \n",
       "9              2014  \n",
       "10             2014  \n",
       "11             2015  \n",
       "12             2015  \n",
       "13             2014  \n",
       "14             2014  \n",
       "15             2014  \n",
       "16             2015  \n",
       "17             2015  \n",
       "18             2014  \n",
       "19             2015  \n",
       "20             2014  \n",
       "21             2015  \n",
       "22             2015  \n",
       "23             2014  \n",
       "24             2014  \n",
       "25             2014  \n",
       "26             2015  \n",
       "27             2015  \n",
       "28             2015  \n",
       "29             2015  \n",
       "...             ...  \n",
       "8427           2015  \n",
       "8428           2015  \n",
       "8429           2015  \n",
       "8430           2015  \n",
       "8431           2015  \n",
       "8432           2015  \n",
       "8433           2015  \n",
       "8434           2015  \n",
       "8435           2015  \n",
       "8436           2015  \n",
       "8437           2015  \n",
       "8438           2015  \n",
       "8439           2015  \n",
       "8440           2015  \n",
       "8441           2015  \n",
       "8442           2015  \n",
       "8443           2015  \n",
       "8444           2015  \n",
       "8445           2015  \n",
       "8446           2015  \n",
       "8447           2015  \n",
       "8448           2015  \n",
       "8449           2015  \n",
       "8450           2015  \n",
       "8451           2015  \n",
       "8452           2015  \n",
       "8453           2015  \n",
       "8454           2015  \n",
       "8455           2015  \n",
       "8456           2014  \n",
       "\n",
       "[8457 rows x 14 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: add another columns\n",
    "X_raw = df.loc[:, columns_to_be_kept]\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'MT_APPORT', 'DUREE_CONTRAT', 'MOIS_GESTION', 'MT_FINANCE', 'ANC_EMPLOI', 'PRIX_VEH', 'MT_MENS', 'AGE_CLI', 'ANNEE_GESTION'})\n",
      "frozenset({'MT_PREST', 'MODE_LOGT', 'VN_VO', 'STITUATION_FAM', 'MARQUE'})\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = frozenset(X_raw.describe().columns)\n",
    "categorical_columns = frozenset(X_raw.columns).difference(numerical_columns)\n",
    "print(numerical_columns)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8457, 53)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANC_EMPLOI</th>\n",
       "      <th>PRIX_VEH</th>\n",
       "      <th>MT_APPORT</th>\n",
       "      <th>MT_FINANCE</th>\n",
       "      <th>MT_MENS</th>\n",
       "      <th>DUREE_CONTRAT</th>\n",
       "      <th>MOIS_GESTION</th>\n",
       "      <th>AGE_CLI</th>\n",
       "      <th>ANNEE_GESTION</th>\n",
       "      <th>MODE_LOGT_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>MARQUE_REN</th>\n",
       "      <th>MARQUE_SAA</th>\n",
       "      <th>MARQUE_SEA</th>\n",
       "      <th>MARQUE_SKO</th>\n",
       "      <th>MARQUE_SUB</th>\n",
       "      <th>MARQUE_SUZ</th>\n",
       "      <th>MARQUE_TOY</th>\n",
       "      <th>MARQUE_VAU</th>\n",
       "      <th>MARQUE_VOL</th>\n",
       "      <th>MARQUE_VOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>19584.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19584.65</td>\n",
       "      <td>95.01</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>563</td>\n",
       "      <td>16995.00</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>14872.00</td>\n",
       "      <td>312.34</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107</td>\n",
       "      <td>19950.00</td>\n",
       "      <td>3869.0</td>\n",
       "      <td>16081.00</td>\n",
       "      <td>329.93</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>17500.00</td>\n",
       "      <td>7143.5</td>\n",
       "      <td>10356.50</td>\n",
       "      <td>217.51</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>19740.00</td>\n",
       "      <td>3789.4</td>\n",
       "      <td>15950.60</td>\n",
       "      <td>310.33</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANC_EMPLOI  PRIX_VEH  MT_APPORT  MT_FINANCE  MT_MENS  DUREE_CONTRAT  \\\n",
       "0          65  19584.65        0.0    19584.65    95.01              6   \n",
       "1         563  16995.00     2123.0    14872.00   312.34             60   \n",
       "2         107  19950.00     3869.0    16081.00   329.93             60   \n",
       "3         143  17500.00     7143.5    10356.50   217.51             60   \n",
       "4         110  19740.00     3789.4    15950.60   310.33             36   \n",
       "\n",
       "   MOIS_GESTION  AGE_CLI  ANNEE_GESTION  MODE_LOGT_1.0     ...      \\\n",
       "0             3       28           2015              1     ...       \n",
       "1             6       64           2014              0     ...       \n",
       "2             8       51           2015              0     ...       \n",
       "3             4       42           2015              0     ...       \n",
       "4             2       34           2015              0     ...       \n",
       "\n",
       "   MARQUE_REN  MARQUE_SAA  MARQUE_SEA  MARQUE_SKO  MARQUE_SUB  MARQUE_SUZ  \\\n",
       "0           1           0           0           0           0           0   \n",
       "1           1           0           0           0           0           0   \n",
       "2           1           0           0           0           0           0   \n",
       "3           1           0           0           0           0           0   \n",
       "4           1           0           0           0           0           0   \n",
       "\n",
       "   MARQUE_TOY  MARQUE_VAU  MARQUE_VOL  MARQUE_VOV  \n",
       "0           0           0           0           0  \n",
       "1           0           0           0           0  \n",
       "2           0           0           0           0  \n",
       "3           0           0           0           0  \n",
       "4           0           0           0           0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw_2 = pd.get_dummies(X_raw, columns = list(categorical_columns))\n",
    "print(X_raw_2.shape)\n",
    "X_raw_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw_2, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1], dtype=int64), array([5011,   63], dtype=int64)),\n",
       " (array([0, 1], dtype=int64), array([3348,   35], dtype=int64)))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "np.unique(y_train, return_counts=True), np.unique(y_test, return_counts=True), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done  43 out of  50 | elapsed:    2.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight={0: 1, 1: 1}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'penalty': ['l2', 'l1'], 'C': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_1 = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2', 'l1']\n",
    "}\n",
    "\n",
    "CLASS_WEIGHT = {0:1, 1:1}\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "model_1 = LogisticRegression(class_weight=CLASS_WEIGHT)\n",
    "clf_1 = GridSearchCV(model_1, parameters_1, cv=5, verbose=5, n_jobs=4, scoring = 'roc_auc', return_train_score = True)\n",
    "\n",
    "clf_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty</th>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean on train</th>\n",
       "      <td>0.77695</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.80229</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.814783</td>\n",
       "      <td>0.76539</td>\n",
       "      <td>0.82121</td>\n",
       "      <td>0.818277</td>\n",
       "      <td>0.821878</td>\n",
       "      <td>0.821817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean on test</th>\n",
       "      <td>0.696131</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.704721</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.706717</td>\n",
       "      <td>0.71592</td>\n",
       "      <td>0.696664</td>\n",
       "      <td>0.715855</td>\n",
       "      <td>0.671368</td>\n",
       "      <td>0.681929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0      1         2     3         4        5         6  \\\n",
       "C                 0.001  0.001      0.01  0.01       0.1      0.1         1   \n",
       "penalty              l2     l1        l2    l1        l2       l1        l2   \n",
       "mean on train   0.77695    0.5   0.80229   0.5  0.814783  0.76539   0.82121   \n",
       "mean on test   0.696131    0.5  0.704721   0.5  0.706717  0.71592  0.696664   \n",
       "\n",
       "                      7         8         9  \n",
       "C                     1        10        10  \n",
       "penalty              l1        l2        l1  \n",
       "mean on train  0.818277  0.821878  0.821817  \n",
       "mean on test   0.715855  0.671368  0.681929  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1 = clf_1.cv_results_ \n",
    "\n",
    "pd.DataFrame([result_1['param_C'], result_1['param_penalty'], result_1['mean_train_score'], result_1['mean_test_score']], index=['C', 'penalty', 'mean on train', 'mean on test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight={0: 1, 1: 1}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_1 = clf_1.best_params_\n",
    "print(best_params_1)\n",
    "\n",
    "model_1_best = LogisticRegression(C = best_params_1['C'], penalty = best_params_1['penalty'], class_weight=CLASS_WEIGHT)\n",
    "model_1_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_1 = model_1_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr_1, tpr_1, thresholds_1 = roc_curve(y_test, y_pred_1)\n",
    "\n",
    "roc_auc_1 = auc(fpr_1, tpr_1)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_1, tpr_1, 'b',label='AUC = %0.3f'% roc_auc_1)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ANC_EMPLOI', 0.0), ('PRIX_VEH', -0.3072115504615047), ('MT_APPORT', -0.11504044811302738), ('MT_FINANCE', 0.0), ('MT_MENS', 0.0), ('DUREE_CONTRAT', 0.1645165895469306), ('MOIS_GESTION', -0.00014084201987955562), ('AGE_CLI', -0.05876504686068565), ('ANNEE_GESTION', -0.0007468442559800299), ('MODE_LOGT_1.0', 0.0), ('MODE_LOGT_2.0', -0.13454986260229185), ('MODE_LOGT_3.0', 0.0), ('MODE_LOGT_4.0', 0.0), ('MODE_LOGT_nan', 0.16821147563495586), ('VN_VO_VN', -0.001710208479383917), ('VN_VO_VO', 0.0), ('STITUATION_FAM_1', 0.0), ('STITUATION_FAM_11', 0.0), ('STITUATION_FAM_2', 0.09334800366563503), ('STITUATION_FAM_3', 0.0), ('STITUATION_FAM_4', 0.0), ('STITUATION_FAM_5', 0.0), ('MARQUE_AUD', 0.0), ('MARQUE_BMW', 0.0713710555834973), ('MARQUE_CHV', 0.05973264089327443), ('MARQUE_CIT', 0.030751402763200902), ('MARQUE_DAC', 0.0), ('MARQUE_DAI', 0.0), ('MARQUE_FIA', 0.0), ('MARQUE_FOR', -0.0041154164708599944), ('MARQUE_GWA', 0.0), ('MARQUE_HON', 0.0), ('MARQUE_HYU', 0.0), ('MARQUE_JAG', 0.0), ('MARQUE_KIA', 0.0), ('MARQUE_LAO', 0.0), ('MARQUE_MAZ', 0.04221800017444792), ('MARQUE_MER', 0.0), ('MARQUE_MIN', 0.0), ('MARQUE_MIT', 0.0), ('MARQUE_NIS', 0.0), ('MARQUE_OPE', 0.0), ('MARQUE_PEU', 0.0), ('MARQUE_REN', 0.0), ('MARQUE_SAA', 0.0), ('MARQUE_SEA', 0.061543716889114246), ('MARQUE_SKO', 0.0), ('MARQUE_SUB', 0.0), ('MARQUE_SUZ', 0.0), ('MARQUE_TOY', 0.0), ('MARQUE_VAU', 0.07143888130741476), ('MARQUE_VOL', 0.0), ('MARQUE_VOV', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "L_1 = list(zip(X_raw_2.columns, list(model_1_best.coef_[0])))\n",
    "print(L_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['PRIX_VEH', '-0.3072115504615047'],\n",
       "       ['MT_APPORT', '-0.11504044811302738'],\n",
       "       ['DUREE_CONTRAT', '0.1645165895469306'],\n",
       "       ['AGE_CLI', '-0.05876504686068565'],\n",
       "       ['MODE_LOGT_2.0', '-0.13454986260229185'],\n",
       "       ['MODE_LOGT_nan', '0.16821147563495586'],\n",
       "       ['STITUATION_FAM_2', '0.09334800366563503'],\n",
       "       ['MARQUE_BMW', '0.0713710555834973'],\n",
       "       ['MARQUE_CHV', '0.05973264089327443'],\n",
       "       ['MARQUE_CIT', '0.030751402763200902'],\n",
       "       ['MARQUE_MAZ', '0.04221800017444792'],\n",
       "       ['MARQUE_SEA', '0.061543716889114246'],\n",
       "       ['MARQUE_VAU', '0.07143888130741476']], dtype='<U20')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_columns_1 = np.array(list(filter(lambda x : abs(x[1]) > 0.01, L_1)))\n",
    "best_columns_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw_3 = X_raw_2[best_columns_1[:,0]]\n",
    "X_train_raw_red, X_test_raw_red, y_train, y_test = train_test_split(X_raw_3, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_red = scaler.fit_transform(X_train_raw_red)\n",
    "X_test_red = scaler.transform(X_test_raw_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done  70 out of  70 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'penalty': ['l2', 'l1'], 'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_2 = {\n",
    "    'C': [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "    'penalty': ['l2', 'l1']\n",
    "}\n",
    "\n",
    "model_2 = LogisticRegression()\n",
    "clf_2 = GridSearchCV(model_2, parameters_2, cv=5, verbose=5, n_jobs=4, scoring = 'roc_auc', return_train_score=True)\n",
    "\n",
    "clf_2.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty</th>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean on train</th>\n",
       "      <td>0.758059</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.766883</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.766193</td>\n",
       "      <td>0.778219</td>\n",
       "      <td>0.77773</td>\n",
       "      <td>0.778596</td>\n",
       "      <td>0.778533</td>\n",
       "      <td>0.778587</td>\n",
       "      <td>0.778597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean on test</th>\n",
       "      <td>0.748743</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.74519</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.733158</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.717935</td>\n",
       "      <td>0.720197</td>\n",
       "      <td>0.699942</td>\n",
       "      <td>0.724911</td>\n",
       "      <td>0.680687</td>\n",
       "      <td>0.689145</td>\n",
       "      <td>0.67791</td>\n",
       "      <td>0.677733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0       1         2      3         4     5         6   \\\n",
       "C                0.0001  0.0001     0.001  0.001      0.01  0.01       0.1   \n",
       "penalty              l2      l1        l2     l1        l2    l1        l2   \n",
       "mean on train  0.758059     0.5  0.766883    0.5  0.772841   0.5    0.7763   \n",
       "mean on test   0.748743     0.5   0.74519    0.5  0.733158   0.5  0.717935   \n",
       "\n",
       "                     7         8         9         10        11        12  \\\n",
       "C                   0.1         1         1        10        10       100   \n",
       "penalty              l1        l2        l1        l2        l1        l2   \n",
       "mean on train  0.766193  0.778219   0.77773  0.778596  0.778533  0.778587   \n",
       "mean on test   0.720197  0.699942  0.724911  0.680687  0.689145   0.67791   \n",
       "\n",
       "                     13  \n",
       "C                   100  \n",
       "penalty              l1  \n",
       "mean on train  0.778597  \n",
       "mean on test   0.677733  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2 = clf_2.cv_results_ \n",
    "\n",
    "pd.DataFrame([result_2['param_C'], result_2['param_penalty'], result_2['mean_train_score'], result_2['mean_test_score']], index=['C', 'penalty', 'mean on train', 'mean on test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 0.0001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_2 = clf_2.best_params_\n",
    "print(best_params_2)\n",
    "\n",
    "model_2_best = LogisticRegression(C = best_params_2['C'], penalty = best_params_2['penalty'])\n",
    "model_2_best.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_2 = model_2_best.predict_proba(X_test_red)[:, 1]\n",
    "\n",
    "fpr_2, tpr_2, thresholds_2 = roc_curve(y_test, y_pred_2)\n",
    "\n",
    "roc_auc_2 = auc(fpr_2, tpr_2)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_2, tpr_2, 'b',label='AUC = %0.3f'% roc_auc_2)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "auc_metric = as_keras_metric(tf.metrics.auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for FNN with regularizer 0\n",
      "auc:  0.5959345326690316 . val_auc:  0.5956306403493646\n",
      "Test for FNN with regularizer 1\n",
      "auc:  0.5949923982905707 . val_auc:  0.5947926218873761\n",
      "Test for FNN with regularizer 2\n",
      "auc:  0.5808907205701961 . val_auc:  0.5799033995919627\n",
      "Test for FNN with regularizer 3\n",
      "auc:  0.5249613800287305 . val_auc:  0.5253221868294213\n",
      "Test for FNN with regularizer 4\n",
      "auc:  0.5959593871450977 . val_auc:  0.5957196439428283\n",
      "Test for FNN with regularizer 5\n",
      "auc:  0.5963850774533586 . val_auc:  0.596109356492611\n",
      "Test for FNN with regularizer 6\n",
      "auc:  0.5965669557184209 . val_auc:  0.5963108102676317\n",
      "Test for FNN with regularizer 7\n",
      "auc:  0.5860743664056393 . val_auc:  0.58592325854184\n"
     ]
    }
   ],
   "source": [
    "from keras import Model\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Concatenate\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import regularizers\n",
    "\n",
    "N_COLUMNS = len(X_raw_2.columns)\n",
    "penalties = [regularizers.l1(1e-4), regularizers.l1(1e-3), regularizers.l1(1e-2), regularizers.l1(1e-1), \n",
    "           regularizers.l2(1e-4), regularizers.l2(1e-3), regularizers.l2(1e-2), regularizers.l2(1e-1)]\n",
    "\n",
    "test_results = []\n",
    "best_test_result = 0\n",
    "best_test_index = 0\n",
    "\n",
    "for i, penalty in enumerate(penalties):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    Tensor_X_input = Input(shape = (N_COLUMNS,), name = 'input')\n",
    "    Tensor_X = Dense(units = 1, name = 'Dense', kernel_regularizer=penalty) (Tensor_X_input)\n",
    "    Tensor_X = Activation('sigmoid') (Tensor_X)\n",
    "    model_3 = Model(inputs = Tensor_X_input, outputs = Tensor_X)\n",
    "    print('Test for FNN with regularizer', i)\n",
    "    adam = Adam()\n",
    "    model_3.compile(loss=\"binary_crossentropy\", optimizer = adam, metrics=[auc_metric])\n",
    "    history_3 = model_3.fit(X_train, y_train, batch_size=128, epochs=20, verbose=0, validation_split=0.2)\n",
    "    print('auc: ', history_3.history['auc'][-1], '. val_auc: ', history_3.history['val_auc'][-1])\n",
    "    if history_3.history['val_auc'][-1] > best_test_result:\n",
    "        best_test_result = history_3.history['val_auc'][-1]\n",
    "        best_test_index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 0.5963108102676317)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_test_index, best_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4059 samples, validate on 1015 samples\n",
      "Epoch 1/1000\n",
      " - 1s - loss: 0.8607 - auc: 0.5284 - val_loss: 0.8530 - val_auc: 0.4994\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 0.8126 - auc: 0.5147 - val_loss: 0.8105 - val_auc: 0.5081\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 0.7705 - auc: 0.5132 - val_loss: 0.7756 - val_auc: 0.5118\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 0.7341 - auc: 0.5100 - val_loss: 0.7443 - val_auc: 0.5144\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 0.7018 - auc: 0.5163 - val_loss: 0.7165 - val_auc: 0.5171\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 0.6733 - auc: 0.5136 - val_loss: 0.6929 - val_auc: 0.5189\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.6479 - auc: 0.5211 - val_loss: 0.6713 - val_auc: 0.5204\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 0.6254 - auc: 0.5209 - val_loss: 0.6514 - val_auc: 0.5220\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 0.6050 - auc: 0.5219 - val_loss: 0.6339 - val_auc: 0.5235\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 0.5865 - auc: 0.5227 - val_loss: 0.6173 - val_auc: 0.5252\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 0.5694 - auc: 0.5262 - val_loss: 0.6030 - val_auc: 0.5269\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 0.5539 - auc: 0.5275 - val_loss: 0.5888 - val_auc: 0.5286\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 0.5394 - auc: 0.5297 - val_loss: 0.5752 - val_auc: 0.5305\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 0.5258 - auc: 0.5322 - val_loss: 0.5627 - val_auc: 0.5321\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 0.5128 - auc: 0.5329 - val_loss: 0.5509 - val_auc: 0.5341\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 0.5007 - auc: 0.5343 - val_loss: 0.5385 - val_auc: 0.5361\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 0.4889 - auc: 0.5368 - val_loss: 0.5270 - val_auc: 0.5385\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 0.4777 - auc: 0.5386 - val_loss: 0.5159 - val_auc: 0.5405\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.4668 - auc: 0.5410 - val_loss: 0.5053 - val_auc: 0.5425\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.4564 - auc: 0.5432 - val_loss: 0.4949 - val_auc: 0.5445\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 0.4465 - auc: 0.5446 - val_loss: 0.4852 - val_auc: 0.5461\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 0.4368 - auc: 0.5465 - val_loss: 0.4755 - val_auc: 0.5477\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 0.4273 - auc: 0.5487 - val_loss: 0.4665 - val_auc: 0.5491\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.4182 - auc: 0.5488 - val_loss: 0.4574 - val_auc: 0.5504\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 0.4094 - auc: 0.5504 - val_loss: 0.4480 - val_auc: 0.5516\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 0.4009 - auc: 0.5512 - val_loss: 0.4387 - val_auc: 0.5529\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 0.3926 - auc: 0.5529 - val_loss: 0.4301 - val_auc: 0.5541\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 0.3845 - auc: 0.5535 - val_loss: 0.4216 - val_auc: 0.5549\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 0.3767 - auc: 0.5545 - val_loss: 0.4133 - val_auc: 0.5554\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 0.3690 - auc: 0.5551 - val_loss: 0.4052 - val_auc: 0.5558\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 0.3617 - auc: 0.5550 - val_loss: 0.3974 - val_auc: 0.5560\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 0.3545 - auc: 0.5558 - val_loss: 0.3898 - val_auc: 0.5563\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 0.3475 - auc: 0.5547 - val_loss: 0.3824 - val_auc: 0.5564\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 0.3407 - auc: 0.5556 - val_loss: 0.3752 - val_auc: 0.5564\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 0.3340 - auc: 0.5555 - val_loss: 0.3680 - val_auc: 0.5564\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 0.3275 - auc: 0.5558 - val_loss: 0.3610 - val_auc: 0.5564\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 0.3212 - auc: 0.5551 - val_loss: 0.3542 - val_auc: 0.5566\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 0.3151 - auc: 0.5561 - val_loss: 0.3477 - val_auc: 0.5567\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 0.3091 - auc: 0.5561 - val_loss: 0.3415 - val_auc: 0.5566\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 0.3032 - auc: 0.5562 - val_loss: 0.3352 - val_auc: 0.5565\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 0.2976 - auc: 0.5561 - val_loss: 0.3291 - val_auc: 0.5566\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 0.2921 - auc: 0.5564 - val_loss: 0.3234 - val_auc: 0.5565\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 0.2866 - auc: 0.5559 - val_loss: 0.3174 - val_auc: 0.5564\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 0.2814 - auc: 0.5565 - val_loss: 0.3119 - val_auc: 0.5565\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 0.2763 - auc: 0.5556 - val_loss: 0.3065 - val_auc: 0.5564\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 0.2713 - auc: 0.5558 - val_loss: 0.3012 - val_auc: 0.5563\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 0.2664 - auc: 0.5558 - val_loss: 0.2961 - val_auc: 0.5563\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 0.2617 - auc: 0.5559 - val_loss: 0.2912 - val_auc: 0.5562\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 0.2571 - auc: 0.5554 - val_loss: 0.2864 - val_auc: 0.5561\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 0.2525 - auc: 0.5559 - val_loss: 0.2815 - val_auc: 0.5561\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 0.2482 - auc: 0.5553 - val_loss: 0.2770 - val_auc: 0.5559\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 0.2440 - auc: 0.5556 - val_loss: 0.2726 - val_auc: 0.5558\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 0.2398 - auc: 0.5556 - val_loss: 0.2682 - val_auc: 0.5557\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 0.2357 - auc: 0.5552 - val_loss: 0.2640 - val_auc: 0.5556\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 0.2317 - auc: 0.5548 - val_loss: 0.2598 - val_auc: 0.5555\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 0.2279 - auc: 0.5553 - val_loss: 0.2558 - val_auc: 0.5555\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 0.2242 - auc: 0.5551 - val_loss: 0.2518 - val_auc: 0.5553\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.2204 - auc: 0.5551 - val_loss: 0.2481 - val_auc: 0.5553\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 0.2169 - auc: 0.5549 - val_loss: 0.2442 - val_auc: 0.5552\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 0.2133 - auc: 0.5543 - val_loss: 0.2406 - val_auc: 0.5552\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 0.2100 - auc: 0.5547 - val_loss: 0.2372 - val_auc: 0.5551\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.2066 - auc: 0.5546 - val_loss: 0.2335 - val_auc: 0.5551\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.2034 - auc: 0.5549 - val_loss: 0.2303 - val_auc: 0.5550\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.2001 - auc: 0.5547 - val_loss: 0.2270 - val_auc: 0.5550\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.1970 - auc: 0.5548 - val_loss: 0.2237 - val_auc: 0.5549\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.1940 - auc: 0.5543 - val_loss: 0.2206 - val_auc: 0.5549\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.1910 - auc: 0.5544 - val_loss: 0.2176 - val_auc: 0.5549\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.1881 - auc: 0.5547 - val_loss: 0.2144 - val_auc: 0.5548\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.1853 - auc: 0.5543 - val_loss: 0.2116 - val_auc: 0.5547\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.1825 - auc: 0.5542 - val_loss: 0.2087 - val_auc: 0.5547\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.1798 - auc: 0.5543 - val_loss: 0.2059 - val_auc: 0.5546\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.1772 - auc: 0.5542 - val_loss: 0.2031 - val_auc: 0.5546\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.1746 - auc: 0.5545 - val_loss: 0.2007 - val_auc: 0.5546\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.1721 - auc: 0.5539 - val_loss: 0.1979 - val_auc: 0.5546\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.1696 - auc: 0.5544 - val_loss: 0.1956 - val_auc: 0.5546\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.1672 - auc: 0.5541 - val_loss: 0.1930 - val_auc: 0.5545\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.1648 - auc: 0.5542 - val_loss: 0.1905 - val_auc: 0.5546\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.1625 - auc: 0.5542 - val_loss: 0.1882 - val_auc: 0.5546\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.1602 - auc: 0.5545 - val_loss: 0.1859 - val_auc: 0.5546\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.1580 - auc: 0.5542 - val_loss: 0.1836 - val_auc: 0.5546\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.1559 - auc: 0.5544 - val_loss: 0.1814 - val_auc: 0.5546\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.1537 - auc: 0.5541 - val_loss: 0.1792 - val_auc: 0.5546\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.1517 - auc: 0.5545 - val_loss: 0.1772 - val_auc: 0.5546\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.1496 - auc: 0.5542 - val_loss: 0.1750 - val_auc: 0.5546\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.1477 - auc: 0.5545 - val_loss: 0.1731 - val_auc: 0.5546\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.1458 - auc: 0.5541 - val_loss: 0.1711 - val_auc: 0.5547\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.1439 - auc: 0.5545 - val_loss: 0.1692 - val_auc: 0.5547\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.1420 - auc: 0.5546 - val_loss: 0.1672 - val_auc: 0.5547\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 0.1402 - auc: 0.5545 - val_loss: 0.1655 - val_auc: 0.5548\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.1384 - auc: 0.5543 - val_loss: 0.1636 - val_auc: 0.5548\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.1367 - auc: 0.5548 - val_loss: 0.1619 - val_auc: 0.5549\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.1350 - auc: 0.5545 - val_loss: 0.1602 - val_auc: 0.5549\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.1333 - auc: 0.5547 - val_loss: 0.1585 - val_auc: 0.5550\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.1317 - auc: 0.5548 - val_loss: 0.1569 - val_auc: 0.5551\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.1301 - auc: 0.5548 - val_loss: 0.1553 - val_auc: 0.5551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000\n",
      " - 0s - loss: 0.1285 - auc: 0.5548 - val_loss: 0.1537 - val_auc: 0.5551\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.1270 - auc: 0.5548 - val_loss: 0.1522 - val_auc: 0.5552\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.1255 - auc: 0.5550 - val_loss: 0.1507 - val_auc: 0.5553\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.1240 - auc: 0.5550 - val_loss: 0.1492 - val_auc: 0.5553\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.1225 - auc: 0.5553 - val_loss: 0.1478 - val_auc: 0.5554\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 0.1212 - auc: 0.5552 - val_loss: 0.1465 - val_auc: 0.5555\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 0.1198 - auc: 0.5553 - val_loss: 0.1450 - val_auc: 0.5555\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.1185 - auc: 0.5550 - val_loss: 0.1437 - val_auc: 0.5556\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.1171 - auc: 0.5552 - val_loss: 0.1425 - val_auc: 0.5557\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.1158 - auc: 0.5553 - val_loss: 0.1413 - val_auc: 0.5557\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.1145 - auc: 0.5554 - val_loss: 0.1400 - val_auc: 0.5558\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 0.1133 - auc: 0.5555 - val_loss: 0.1388 - val_auc: 0.5558\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 0.1121 - auc: 0.5556 - val_loss: 0.1376 - val_auc: 0.5559\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 0.1109 - auc: 0.5558 - val_loss: 0.1365 - val_auc: 0.5560\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 0.1097 - auc: 0.5557 - val_loss: 0.1353 - val_auc: 0.5561\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 0.1085 - auc: 0.5560 - val_loss: 0.1343 - val_auc: 0.5561\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 0.1074 - auc: 0.5558 - val_loss: 0.1331 - val_auc: 0.5562\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 0.1063 - auc: 0.5561 - val_loss: 0.1321 - val_auc: 0.5563\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 0.1052 - auc: 0.5562 - val_loss: 0.1312 - val_auc: 0.5564\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 0.1041 - auc: 0.5564 - val_loss: 0.1301 - val_auc: 0.5565\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 0.1031 - auc: 0.5564 - val_loss: 0.1291 - val_auc: 0.5567\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 0.1021 - auc: 0.5563 - val_loss: 0.1282 - val_auc: 0.5568\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 0.1011 - auc: 0.5566 - val_loss: 0.1274 - val_auc: 0.5569\n",
      "Epoch 119/1000\n",
      " - 0s - loss: 0.1001 - auc: 0.5567 - val_loss: 0.1265 - val_auc: 0.5570\n",
      "Epoch 120/1000\n",
      " - 0s - loss: 0.0991 - auc: 0.5569 - val_loss: 0.1255 - val_auc: 0.5570\n",
      "Epoch 121/1000\n",
      " - 0s - loss: 0.0982 - auc: 0.5569 - val_loss: 0.1246 - val_auc: 0.5571\n",
      "Epoch 122/1000\n",
      " - 0s - loss: 0.0973 - auc: 0.5570 - val_loss: 0.1238 - val_auc: 0.5572\n",
      "Epoch 123/1000\n",
      " - 0s - loss: 0.0964 - auc: 0.5571 - val_loss: 0.1230 - val_auc: 0.5573\n",
      "Epoch 124/1000\n",
      " - 0s - loss: 0.0955 - auc: 0.5574 - val_loss: 0.1224 - val_auc: 0.5574\n",
      "Epoch 125/1000\n",
      " - 0s - loss: 0.0946 - auc: 0.5573 - val_loss: 0.1214 - val_auc: 0.5575\n",
      "Epoch 126/1000\n",
      " - 0s - loss: 0.0938 - auc: 0.5573 - val_loss: 0.1206 - val_auc: 0.5576\n",
      "Epoch 127/1000\n",
      " - 0s - loss: 0.0929 - auc: 0.5575 - val_loss: 0.1201 - val_auc: 0.5577\n",
      "Epoch 128/1000\n",
      " - 0s - loss: 0.0921 - auc: 0.5576 - val_loss: 0.1192 - val_auc: 0.5578\n",
      "Epoch 129/1000\n",
      " - 0s - loss: 0.0913 - auc: 0.5579 - val_loss: 0.1186 - val_auc: 0.5579\n",
      "Epoch 130/1000\n",
      " - 0s - loss: 0.0905 - auc: 0.5577 - val_loss: 0.1179 - val_auc: 0.5581\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.0897 - auc: 0.5580 - val_loss: 0.1173 - val_auc: 0.5581\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.0890 - auc: 0.5578 - val_loss: 0.1165 - val_auc: 0.5583\n",
      "Epoch 133/1000\n",
      " - 0s - loss: 0.0882 - auc: 0.5581 - val_loss: 0.1160 - val_auc: 0.5584\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.0875 - auc: 0.5584 - val_loss: 0.1154 - val_auc: 0.5585\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.0868 - auc: 0.5585 - val_loss: 0.1147 - val_auc: 0.5586\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.0860 - auc: 0.5586 - val_loss: 0.1142 - val_auc: 0.5587\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.0854 - auc: 0.5586 - val_loss: 0.1136 - val_auc: 0.5588\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.0847 - auc: 0.5587 - val_loss: 0.1130 - val_auc: 0.5589\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.0840 - auc: 0.5587 - val_loss: 0.1125 - val_auc: 0.5591\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.0834 - auc: 0.5588 - val_loss: 0.1120 - val_auc: 0.5592\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.0827 - auc: 0.5590 - val_loss: 0.1115 - val_auc: 0.5593\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.0821 - auc: 0.5592 - val_loss: 0.1110 - val_auc: 0.5594\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.0815 - auc: 0.5592 - val_loss: 0.1105 - val_auc: 0.5595\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.0809 - auc: 0.5595 - val_loss: 0.1101 - val_auc: 0.5596\n",
      "Epoch 145/1000\n",
      " - 0s - loss: 0.0803 - auc: 0.5593 - val_loss: 0.1095 - val_auc: 0.5597\n",
      "Epoch 146/1000\n",
      " - 0s - loss: 0.0797 - auc: 0.5597 - val_loss: 0.1092 - val_auc: 0.5598\n",
      "Epoch 147/1000\n",
      " - 0s - loss: 0.0792 - auc: 0.5597 - val_loss: 0.1087 - val_auc: 0.5599\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.0786 - auc: 0.5598 - val_loss: 0.1084 - val_auc: 0.5600\n",
      "Epoch 149/1000\n",
      " - 0s - loss: 0.0780 - auc: 0.5599 - val_loss: 0.1078 - val_auc: 0.5602\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.0775 - auc: 0.5601 - val_loss: 0.1075 - val_auc: 0.5603\n",
      "Epoch 151/1000\n",
      " - 0s - loss: 0.0770 - auc: 0.5603 - val_loss: 0.1071 - val_auc: 0.5604\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.0765 - auc: 0.5603 - val_loss: 0.1066 - val_auc: 0.5605\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.0760 - auc: 0.5605 - val_loss: 0.1064 - val_auc: 0.5606\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.0755 - auc: 0.5604 - val_loss: 0.1059 - val_auc: 0.5607\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.0750 - auc: 0.5607 - val_loss: 0.1057 - val_auc: 0.5608\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.0745 - auc: 0.5607 - val_loss: 0.1053 - val_auc: 0.5609\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.0740 - auc: 0.5609 - val_loss: 0.1050 - val_auc: 0.5610\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.0735 - auc: 0.5611 - val_loss: 0.1046 - val_auc: 0.5611\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.0731 - auc: 0.5610 - val_loss: 0.1042 - val_auc: 0.5613\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.0727 - auc: 0.5613 - val_loss: 0.1041 - val_auc: 0.5614\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.0722 - auc: 0.5612 - val_loss: 0.1036 - val_auc: 0.5615\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.0718 - auc: 0.5613 - val_loss: 0.1034 - val_auc: 0.5616\n",
      "Epoch 163/1000\n",
      " - 0s - loss: 0.0714 - auc: 0.5615 - val_loss: 0.1032 - val_auc: 0.5617\n",
      "Epoch 164/1000\n",
      " - 0s - loss: 0.0710 - auc: 0.5617 - val_loss: 0.1029 - val_auc: 0.5618\n",
      "Epoch 165/1000\n",
      " - 0s - loss: 0.0706 - auc: 0.5618 - val_loss: 0.1027 - val_auc: 0.5619\n",
      "Epoch 166/1000\n",
      " - 0s - loss: 0.0702 - auc: 0.5619 - val_loss: 0.1024 - val_auc: 0.5620\n",
      "Epoch 167/1000\n",
      " - 0s - loss: 0.0698 - auc: 0.5620 - val_loss: 0.1021 - val_auc: 0.5622\n",
      "Epoch 168/1000\n",
      " - 0s - loss: 0.0695 - auc: 0.5622 - val_loss: 0.1020 - val_auc: 0.5623\n",
      "Epoch 169/1000\n",
      " - 0s - loss: 0.0690 - auc: 0.5622 - val_loss: 0.1015 - val_auc: 0.5624\n",
      "Epoch 170/1000\n",
      " - 0s - loss: 0.0687 - auc: 0.5622 - val_loss: 0.1013 - val_auc: 0.5625\n",
      "Epoch 171/1000\n",
      " - 0s - loss: 0.0683 - auc: 0.5625 - val_loss: 0.1013 - val_auc: 0.5626\n",
      "Epoch 172/1000\n",
      " - 0s - loss: 0.0680 - auc: 0.5625 - val_loss: 0.1008 - val_auc: 0.5628\n",
      "Epoch 173/1000\n",
      " - 0s - loss: 0.0676 - auc: 0.5627 - val_loss: 0.1008 - val_auc: 0.5629\n",
      "Epoch 174/1000\n",
      " - 0s - loss: 0.0673 - auc: 0.5628 - val_loss: 0.1006 - val_auc: 0.5630\n",
      "Epoch 175/1000\n",
      " - 0s - loss: 0.0669 - auc: 0.5629 - val_loss: 0.1003 - val_auc: 0.5631\n",
      "Epoch 176/1000\n",
      " - 0s - loss: 0.0666 - auc: 0.5630 - val_loss: 0.1001 - val_auc: 0.5633\n",
      "Epoch 177/1000\n",
      " - 0s - loss: 0.0663 - auc: 0.5631 - val_loss: 0.1000 - val_auc: 0.5634\n",
      "Epoch 178/1000\n",
      " - 0s - loss: 0.0660 - auc: 0.5634 - val_loss: 0.0998 - val_auc: 0.5635\n",
      "Epoch 179/1000\n",
      " - 0s - loss: 0.0657 - auc: 0.5633 - val_loss: 0.0995 - val_auc: 0.5636\n",
      "Epoch 180/1000\n",
      " - 0s - loss: 0.0654 - auc: 0.5637 - val_loss: 0.0997 - val_auc: 0.5637\n",
      "Epoch 181/1000\n",
      " - 0s - loss: 0.0651 - auc: 0.5637 - val_loss: 0.0991 - val_auc: 0.5638\n",
      "Epoch 182/1000\n",
      " - 0s - loss: 0.0648 - auc: 0.5638 - val_loss: 0.0992 - val_auc: 0.5640\n",
      "Epoch 183/1000\n",
      " - 0s - loss: 0.0645 - auc: 0.5639 - val_loss: 0.0989 - val_auc: 0.5641\n",
      "Epoch 184/1000\n",
      " - 0s - loss: 0.0642 - auc: 0.5640 - val_loss: 0.0989 - val_auc: 0.5642\n",
      "Epoch 185/1000\n",
      " - 0s - loss: 0.0639 - auc: 0.5641 - val_loss: 0.0986 - val_auc: 0.5643\n",
      "Epoch 186/1000\n",
      " - 0s - loss: 0.0637 - auc: 0.5643 - val_loss: 0.0986 - val_auc: 0.5644\n",
      "Epoch 187/1000\n",
      " - 0s - loss: 0.0634 - auc: 0.5644 - val_loss: 0.0985 - val_auc: 0.5646\n",
      "Epoch 188/1000\n",
      " - 0s - loss: 0.0631 - auc: 0.5646 - val_loss: 0.0985 - val_auc: 0.5647\n",
      "Epoch 189/1000\n",
      " - 0s - loss: 0.0629 - auc: 0.5646 - val_loss: 0.0981 - val_auc: 0.5648\n",
      "Epoch 190/1000\n",
      " - 0s - loss: 0.0627 - auc: 0.5647 - val_loss: 0.0980 - val_auc: 0.5649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/1000\n",
      " - 0s - loss: 0.0624 - auc: 0.5649 - val_loss: 0.0979 - val_auc: 0.5651\n",
      "Epoch 192/1000\n",
      " - 0s - loss: 0.0622 - auc: 0.5650 - val_loss: 0.0979 - val_auc: 0.5652\n",
      "Epoch 193/1000\n",
      " - 0s - loss: 0.0619 - auc: 0.5651 - val_loss: 0.0979 - val_auc: 0.5653\n",
      "Epoch 194/1000\n",
      " - 0s - loss: 0.0617 - auc: 0.5652 - val_loss: 0.0976 - val_auc: 0.5654\n",
      "Epoch 195/1000\n",
      " - 0s - loss: 0.0615 - auc: 0.5653 - val_loss: 0.0976 - val_auc: 0.5656\n",
      "Epoch 196/1000\n",
      " - 0s - loss: 0.0613 - auc: 0.5655 - val_loss: 0.0973 - val_auc: 0.5657\n",
      "Epoch 197/1000\n",
      " - 0s - loss: 0.0611 - auc: 0.5657 - val_loss: 0.0975 - val_auc: 0.5658\n",
      "Epoch 198/1000\n",
      " - 0s - loss: 0.0609 - auc: 0.5658 - val_loss: 0.0973 - val_auc: 0.5660\n",
      "Epoch 199/1000\n",
      " - 0s - loss: 0.0606 - auc: 0.5658 - val_loss: 0.0971 - val_auc: 0.5661\n",
      "Epoch 200/1000\n",
      " - 0s - loss: 0.0605 - auc: 0.5660 - val_loss: 0.0973 - val_auc: 0.5662\n",
      "Epoch 201/1000\n",
      " - 0s - loss: 0.0602 - auc: 0.5661 - val_loss: 0.0970 - val_auc: 0.5663\n",
      "Epoch 202/1000\n",
      " - 0s - loss: 0.0600 - auc: 0.5663 - val_loss: 0.0972 - val_auc: 0.5664\n",
      "Epoch 203/1000\n",
      " - 0s - loss: 0.0598 - auc: 0.5664 - val_loss: 0.0970 - val_auc: 0.5666\n",
      "Epoch 204/1000\n",
      " - 0s - loss: 0.0597 - auc: 0.5666 - val_loss: 0.0969 - val_auc: 0.5667\n",
      "Epoch 205/1000\n",
      " - 0s - loss: 0.0595 - auc: 0.5666 - val_loss: 0.0967 - val_auc: 0.5669\n",
      "Epoch 206/1000\n",
      " - 0s - loss: 0.0593 - auc: 0.5669 - val_loss: 0.0970 - val_auc: 0.5670\n",
      "Epoch 207/1000\n",
      " - 0s - loss: 0.0591 - auc: 0.5669 - val_loss: 0.0967 - val_auc: 0.5671\n",
      "Epoch 208/1000\n",
      " - 0s - loss: 0.0590 - auc: 0.5671 - val_loss: 0.0966 - val_auc: 0.5673\n",
      "Epoch 209/1000\n",
      " - 0s - loss: 0.0588 - auc: 0.5672 - val_loss: 0.0967 - val_auc: 0.5674\n",
      "Epoch 210/1000\n",
      " - 0s - loss: 0.0586 - auc: 0.5672 - val_loss: 0.0964 - val_auc: 0.5675\n",
      "Epoch 211/1000\n",
      " - 0s - loss: 0.0585 - auc: 0.5676 - val_loss: 0.0968 - val_auc: 0.5676\n",
      "Epoch 212/1000\n",
      " - 0s - loss: 0.0583 - auc: 0.5677 - val_loss: 0.0965 - val_auc: 0.5678\n",
      "Epoch 213/1000\n",
      " - 0s - loss: 0.0582 - auc: 0.5677 - val_loss: 0.0965 - val_auc: 0.5679\n",
      "Epoch 214/1000\n",
      " - 0s - loss: 0.0580 - auc: 0.5678 - val_loss: 0.0963 - val_auc: 0.5680\n",
      "Epoch 215/1000\n",
      " - 0s - loss: 0.0578 - auc: 0.5679 - val_loss: 0.0964 - val_auc: 0.5681\n",
      "Epoch 216/1000\n",
      " - 0s - loss: 0.0577 - auc: 0.5681 - val_loss: 0.0963 - val_auc: 0.5683\n",
      "Epoch 217/1000\n",
      " - 0s - loss: 0.0576 - auc: 0.5682 - val_loss: 0.0964 - val_auc: 0.5684\n",
      "Epoch 218/1000\n",
      " - 0s - loss: 0.0575 - auc: 0.5684 - val_loss: 0.0963 - val_auc: 0.5685\n",
      "Epoch 219/1000\n",
      " - 0s - loss: 0.0573 - auc: 0.5685 - val_loss: 0.0964 - val_auc: 0.5687\n",
      "Epoch 220/1000\n",
      " - 0s - loss: 0.0572 - auc: 0.5686 - val_loss: 0.0962 - val_auc: 0.5688\n",
      "Epoch 221/1000\n",
      " - 0s - loss: 0.0570 - auc: 0.5688 - val_loss: 0.0963 - val_auc: 0.5690\n",
      "Epoch 222/1000\n",
      " - 0s - loss: 0.0569 - auc: 0.5689 - val_loss: 0.0963 - val_auc: 0.5691\n",
      "Epoch 223/1000\n",
      " - 0s - loss: 0.0568 - auc: 0.5690 - val_loss: 0.0963 - val_auc: 0.5692\n",
      "Epoch 224/1000\n",
      " - 0s - loss: 0.0567 - auc: 0.5692 - val_loss: 0.0963 - val_auc: 0.5694\n",
      "Epoch 225/1000\n",
      " - 0s - loss: 0.0566 - auc: 0.5693 - val_loss: 0.0962 - val_auc: 0.5695\n",
      "Epoch 226/1000\n",
      " - 0s - loss: 0.0564 - auc: 0.5696 - val_loss: 0.0963 - val_auc: 0.5697\n",
      "Epoch 227/1000\n",
      " - 0s - loss: 0.0563 - auc: 0.5696 - val_loss: 0.0961 - val_auc: 0.5698\n",
      "Epoch 228/1000\n",
      " - 0s - loss: 0.0562 - auc: 0.5698 - val_loss: 0.0962 - val_auc: 0.5699\n",
      "Epoch 229/1000\n",
      " - 0s - loss: 0.0562 - auc: 0.5699 - val_loss: 0.0960 - val_auc: 0.5701\n",
      "Epoch 230/1000\n",
      " - 0s - loss: 0.0560 - auc: 0.5701 - val_loss: 0.0963 - val_auc: 0.5702\n",
      "Epoch 231/1000\n",
      " - 0s - loss: 0.0559 - auc: 0.5702 - val_loss: 0.0961 - val_auc: 0.5703\n",
      "Epoch 232/1000\n",
      " - 0s - loss: 0.0558 - auc: 0.5704 - val_loss: 0.0965 - val_auc: 0.5705\n",
      "Epoch 233/1000\n",
      " - 0s - loss: 0.0557 - auc: 0.5705 - val_loss: 0.0962 - val_auc: 0.5706\n",
      "Epoch 234/1000\n",
      " - 0s - loss: 0.0556 - auc: 0.5705 - val_loss: 0.0963 - val_auc: 0.5707\n",
      "Epoch 235/1000\n",
      " - 0s - loss: 0.0555 - auc: 0.5707 - val_loss: 0.0963 - val_auc: 0.5708\n",
      "Epoch 236/1000\n",
      " - 0s - loss: 0.0554 - auc: 0.5708 - val_loss: 0.0961 - val_auc: 0.5710\n",
      "Epoch 237/1000\n",
      " - 0s - loss: 0.0553 - auc: 0.5710 - val_loss: 0.0963 - val_auc: 0.5711\n",
      "Epoch 238/1000\n",
      " - 0s - loss: 0.0552 - auc: 0.5711 - val_loss: 0.0964 - val_auc: 0.5712\n",
      "Epoch 239/1000\n",
      " - 0s - loss: 0.0552 - auc: 0.5713 - val_loss: 0.0963 - val_auc: 0.5714\n",
      "Epoch 240/1000\n",
      " - 0s - loss: 0.0551 - auc: 0.5713 - val_loss: 0.0963 - val_auc: 0.5715\n",
      "Epoch 241/1000\n",
      " - 0s - loss: 0.0550 - auc: 0.5715 - val_loss: 0.0965 - val_auc: 0.5716\n",
      "Epoch 242/1000\n",
      " - 0s - loss: 0.0550 - auc: 0.5715 - val_loss: 0.0961 - val_auc: 0.5718\n",
      "Epoch 243/1000\n",
      " - 0s - loss: 0.0548 - auc: 0.5718 - val_loss: 0.0965 - val_auc: 0.5719\n",
      "Epoch 244/1000\n",
      " - 0s - loss: 0.0547 - auc: 0.5719 - val_loss: 0.0965 - val_auc: 0.5721\n",
      "Epoch 245/1000\n",
      " - 0s - loss: 0.0547 - auc: 0.5721 - val_loss: 0.0964 - val_auc: 0.5722\n",
      "Epoch 246/1000\n",
      " - 0s - loss: 0.0546 - auc: 0.5723 - val_loss: 0.0965 - val_auc: 0.5724\n",
      "Epoch 247/1000\n",
      " - 0s - loss: 0.0546 - auc: 0.5724 - val_loss: 0.0965 - val_auc: 0.5725\n",
      "Epoch 248/1000\n",
      " - 0s - loss: 0.0545 - auc: 0.5725 - val_loss: 0.0965 - val_auc: 0.5727\n",
      "Epoch 249/1000\n",
      " - 0s - loss: 0.0544 - auc: 0.5726 - val_loss: 0.0965 - val_auc: 0.5728\n",
      "Epoch 250/1000\n",
      " - 0s - loss: 0.0544 - auc: 0.5729 - val_loss: 0.0967 - val_auc: 0.5730\n",
      "Epoch 251/1000\n",
      " - 0s - loss: 0.0543 - auc: 0.5730 - val_loss: 0.0967 - val_auc: 0.5731\n",
      "Epoch 252/1000\n",
      " - 0s - loss: 0.0543 - auc: 0.5730 - val_loss: 0.0964 - val_auc: 0.5733\n",
      "Epoch 253/1000\n",
      " - 0s - loss: 0.0542 - auc: 0.5733 - val_loss: 0.0967 - val_auc: 0.5734\n",
      "Epoch 254/1000\n",
      " - 0s - loss: 0.0541 - auc: 0.5734 - val_loss: 0.0967 - val_auc: 0.5735\n",
      "Epoch 255/1000\n",
      " - 0s - loss: 0.0541 - auc: 0.5735 - val_loss: 0.0968 - val_auc: 0.5737\n",
      "Epoch 256/1000\n",
      " - 0s - loss: 0.0540 - auc: 0.5737 - val_loss: 0.0966 - val_auc: 0.5738\n",
      "Epoch 257/1000\n",
      " - 0s - loss: 0.0539 - auc: 0.5739 - val_loss: 0.0968 - val_auc: 0.5740\n",
      "Epoch 258/1000\n",
      " - 0s - loss: 0.0539 - auc: 0.5740 - val_loss: 0.0967 - val_auc: 0.5741\n",
      "Epoch 259/1000\n",
      " - 0s - loss: 0.0539 - auc: 0.5742 - val_loss: 0.0972 - val_auc: 0.5743\n",
      "Epoch 260/1000\n",
      " - 0s - loss: 0.0538 - auc: 0.5743 - val_loss: 0.0969 - val_auc: 0.5744\n",
      "Epoch 261/1000\n",
      " - 0s - loss: 0.0538 - auc: 0.5744 - val_loss: 0.0967 - val_auc: 0.5746\n",
      "Epoch 262/1000\n",
      " - 0s - loss: 0.0538 - auc: 0.5745 - val_loss: 0.0970 - val_auc: 0.5747\n",
      "Epoch 263/1000\n",
      " - 0s - loss: 0.0537 - auc: 0.5746 - val_loss: 0.0968 - val_auc: 0.5748\n",
      "Epoch 264/1000\n",
      " - 0s - loss: 0.0536 - auc: 0.5748 - val_loss: 0.0970 - val_auc: 0.5750\n",
      "Epoch 265/1000\n",
      " - 0s - loss: 0.0536 - auc: 0.5749 - val_loss: 0.0969 - val_auc: 0.5751\n",
      "Epoch 266/1000\n",
      " - 0s - loss: 0.0535 - auc: 0.5751 - val_loss: 0.0972 - val_auc: 0.5752\n",
      "Epoch 267/1000\n",
      " - 0s - loss: 0.0535 - auc: 0.5751 - val_loss: 0.0970 - val_auc: 0.5754\n",
      "Epoch 268/1000\n",
      " - 0s - loss: 0.0535 - auc: 0.5753 - val_loss: 0.0973 - val_auc: 0.5755\n",
      "Epoch 269/1000\n",
      " - 0s - loss: 0.0534 - auc: 0.5755 - val_loss: 0.0972 - val_auc: 0.5756\n",
      "Epoch 270/1000\n",
      " - 0s - loss: 0.0534 - auc: 0.5757 - val_loss: 0.0975 - val_auc: 0.5758\n",
      "Epoch 271/1000\n",
      " - 0s - loss: 0.0533 - auc: 0.5757 - val_loss: 0.0971 - val_auc: 0.5759\n",
      "Epoch 272/1000\n",
      " - 0s - loss: 0.0533 - auc: 0.5760 - val_loss: 0.0974 - val_auc: 0.5761\n",
      "Epoch 273/1000\n",
      " - 0s - loss: 0.0533 - auc: 0.5760 - val_loss: 0.0973 - val_auc: 0.5762\n",
      "Epoch 274/1000\n",
      " - 0s - loss: 0.0532 - auc: 0.5762 - val_loss: 0.0976 - val_auc: 0.5763\n",
      "Epoch 275/1000\n",
      " - 0s - loss: 0.0532 - auc: 0.5763 - val_loss: 0.0974 - val_auc: 0.5765\n",
      "Epoch 276/1000\n",
      " - 0s - loss: 0.0532 - auc: 0.5764 - val_loss: 0.0976 - val_auc: 0.5766\n",
      "Epoch 277/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.5766 - val_loss: 0.0976 - val_auc: 0.5768\n",
      "Epoch 278/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.5768 - val_loss: 0.0975 - val_auc: 0.5769\n",
      "Epoch 279/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.5770 - val_loss: 0.0978 - val_auc: 0.5771\n",
      "Epoch 280/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.5771 - val_loss: 0.0977 - val_auc: 0.5772\n",
      "Epoch 281/1000\n",
      " - 0s - loss: 0.0530 - auc: 0.5773 - val_loss: 0.0977 - val_auc: 0.5774\n",
      "Epoch 282/1000\n",
      " - 0s - loss: 0.0530 - auc: 0.5774 - val_loss: 0.0978 - val_auc: 0.5775\n",
      "Epoch 283/1000\n",
      " - 0s - loss: 0.0530 - auc: 0.5775 - val_loss: 0.0979 - val_auc: 0.5777\n",
      "Epoch 284/1000\n",
      " - 0s - loss: 0.0530 - auc: 0.5778 - val_loss: 0.0978 - val_auc: 0.5778\n",
      "Epoch 285/1000\n",
      " - 0s - loss: 0.0530 - auc: 0.5779 - val_loss: 0.0980 - val_auc: 0.5780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      " - 0s - loss: 0.0530 - auc: 0.5780 - val_loss: 0.0979 - val_auc: 0.5782\n",
      "Epoch 287/1000\n",
      " - 0s - loss: 0.0529 - auc: 0.5782 - val_loss: 0.0980 - val_auc: 0.5783\n",
      "Epoch 288/1000\n",
      " - 0s - loss: 0.0529 - auc: 0.5784 - val_loss: 0.0981 - val_auc: 0.5785\n",
      "Epoch 289/1000\n",
      " - 0s - loss: 0.0529 - auc: 0.5785 - val_loss: 0.0979 - val_auc: 0.5786\n",
      "Epoch 290/1000\n",
      " - 0s - loss: 0.0528 - auc: 0.5786 - val_loss: 0.0980 - val_auc: 0.5788\n",
      "Epoch 291/1000\n",
      " - 0s - loss: 0.0528 - auc: 0.5789 - val_loss: 0.0983 - val_auc: 0.5790\n",
      "Epoch 292/1000\n",
      " - 0s - loss: 0.0528 - auc: 0.5790 - val_loss: 0.0981 - val_auc: 0.5791\n",
      "Epoch 293/1000\n",
      " - 0s - loss: 0.0528 - auc: 0.5792 - val_loss: 0.0982 - val_auc: 0.5793\n",
      "Epoch 294/1000\n",
      " - 0s - loss: 0.0528 - auc: 0.5794 - val_loss: 0.0983 - val_auc: 0.5795\n",
      "Epoch 295/1000\n",
      " - 0s - loss: 0.0528 - auc: 0.5794 - val_loss: 0.0982 - val_auc: 0.5796\n",
      "Epoch 296/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.5797 - val_loss: 0.0985 - val_auc: 0.5798\n",
      "Epoch 297/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.5798 - val_loss: 0.0983 - val_auc: 0.5799\n",
      "Epoch 298/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.5799 - val_loss: 0.0984 - val_auc: 0.5801\n",
      "Epoch 299/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.5801 - val_loss: 0.0984 - val_auc: 0.5803\n",
      "Epoch 300/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.5803 - val_loss: 0.0985 - val_auc: 0.5804\n",
      "Epoch 301/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.5804 - val_loss: 0.0985 - val_auc: 0.5806\n",
      "Epoch 302/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.5805 - val_loss: 0.0986 - val_auc: 0.5807\n",
      "Epoch 303/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5808 - val_loss: 0.0986 - val_auc: 0.5809\n",
      "Epoch 304/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.5810 - val_loss: 0.0987 - val_auc: 0.5810\n",
      "Epoch 305/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.5810 - val_loss: 0.0988 - val_auc: 0.5812\n",
      "Epoch 306/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5812 - val_loss: 0.0990 - val_auc: 0.5813\n",
      "Epoch 307/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5813 - val_loss: 0.0987 - val_auc: 0.5815\n",
      "Epoch 308/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5815 - val_loss: 0.0988 - val_auc: 0.5817\n",
      "Epoch 309/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5817 - val_loss: 0.0990 - val_auc: 0.5818\n",
      "Epoch 310/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5818 - val_loss: 0.0988 - val_auc: 0.5820\n",
      "Epoch 311/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5820 - val_loss: 0.0989 - val_auc: 0.5821\n",
      "Epoch 312/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5821 - val_loss: 0.0989 - val_auc: 0.5823\n",
      "Epoch 313/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5823 - val_loss: 0.0989 - val_auc: 0.5824\n",
      "Epoch 314/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5825 - val_loss: 0.0988 - val_auc: 0.5826\n",
      "Epoch 315/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5827 - val_loss: 0.0990 - val_auc: 0.5828\n",
      "Epoch 316/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5828 - val_loss: 0.0991 - val_auc: 0.5829\n",
      "Epoch 317/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5830 - val_loss: 0.0991 - val_auc: 0.5831\n",
      "Epoch 318/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5831 - val_loss: 0.0992 - val_auc: 0.5833\n",
      "Epoch 319/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.5833 - val_loss: 0.0990 - val_auc: 0.5834\n",
      "Epoch 320/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5835 - val_loss: 0.0992 - val_auc: 0.5836\n",
      "Epoch 321/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5836 - val_loss: 0.0991 - val_auc: 0.5838\n",
      "Epoch 322/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5838 - val_loss: 0.0992 - val_auc: 0.5839\n",
      "Epoch 323/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5840 - val_loss: 0.0993 - val_auc: 0.5841\n",
      "Epoch 324/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5841 - val_loss: 0.0992 - val_auc: 0.5843\n",
      "Epoch 325/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5843 - val_loss: 0.0994 - val_auc: 0.5844\n",
      "Epoch 326/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5845 - val_loss: 0.0994 - val_auc: 0.5846\n",
      "Epoch 327/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5846 - val_loss: 0.0996 - val_auc: 0.5847\n",
      "Epoch 328/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5847 - val_loss: 0.0995 - val_auc: 0.5849\n",
      "Epoch 329/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5849 - val_loss: 0.0993 - val_auc: 0.5851\n",
      "Epoch 330/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5851 - val_loss: 0.0995 - val_auc: 0.5852\n",
      "Epoch 331/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5852 - val_loss: 0.0994 - val_auc: 0.5854\n",
      "Epoch 332/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5855 - val_loss: 0.0995 - val_auc: 0.5856\n",
      "Epoch 333/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5857 - val_loss: 0.0997 - val_auc: 0.5857\n",
      "Epoch 334/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5858 - val_loss: 0.0997 - val_auc: 0.5859\n",
      "Epoch 335/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5859 - val_loss: 0.0997 - val_auc: 0.5861\n",
      "Epoch 336/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5861 - val_loss: 0.0998 - val_auc: 0.5862\n",
      "Epoch 337/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5862 - val_loss: 0.0996 - val_auc: 0.5864\n",
      "Epoch 338/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5865 - val_loss: 0.0998 - val_auc: 0.5866\n",
      "Epoch 339/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5866 - val_loss: 0.0996 - val_auc: 0.5867\n",
      "Epoch 340/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5868 - val_loss: 0.0999 - val_auc: 0.5869\n",
      "Epoch 341/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5869 - val_loss: 0.0997 - val_auc: 0.5871\n",
      "Epoch 342/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5871 - val_loss: 0.0999 - val_auc: 0.5872\n",
      "Epoch 343/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5872 - val_loss: 0.0998 - val_auc: 0.5874\n",
      "Epoch 344/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5874 - val_loss: 0.0997 - val_auc: 0.5876\n",
      "Epoch 345/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5876 - val_loss: 0.1000 - val_auc: 0.5877\n",
      "Epoch 346/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5877 - val_loss: 0.0996 - val_auc: 0.5879\n",
      "Epoch 347/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.5879 - val_loss: 0.0998 - val_auc: 0.5880\n",
      "Epoch 348/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5881 - val_loss: 0.0999 - val_auc: 0.5882\n",
      "Epoch 349/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5882 - val_loss: 0.1000 - val_auc: 0.5884\n",
      "Epoch 350/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5884 - val_loss: 0.1000 - val_auc: 0.5885\n",
      "Epoch 351/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5886 - val_loss: 0.0999 - val_auc: 0.5887\n",
      "Epoch 352/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5887 - val_loss: 0.0999 - val_auc: 0.5888\n",
      "Epoch 353/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5889 - val_loss: 0.1002 - val_auc: 0.5890\n",
      "Epoch 354/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5890 - val_loss: 0.1000 - val_auc: 0.5892\n",
      "Epoch 355/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5891 - val_loss: 0.1001 - val_auc: 0.5893\n",
      "Epoch 356/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5893 - val_loss: 0.1001 - val_auc: 0.5895\n",
      "Epoch 357/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5895 - val_loss: 0.0999 - val_auc: 0.5896\n",
      "Epoch 358/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5897 - val_loss: 0.1001 - val_auc: 0.5898\n",
      "Epoch 359/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5898 - val_loss: 0.1000 - val_auc: 0.5899\n",
      "Epoch 360/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5900 - val_loss: 0.1001 - val_auc: 0.5901\n",
      "Epoch 361/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5901 - val_loss: 0.1001 - val_auc: 0.5902\n",
      "Epoch 362/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5902 - val_loss: 0.1001 - val_auc: 0.5904\n",
      "Epoch 363/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5905 - val_loss: 0.1001 - val_auc: 0.5906\n",
      "Epoch 364/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5906 - val_loss: 0.1003 - val_auc: 0.5907\n",
      "Epoch 365/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5907 - val_loss: 0.1001 - val_auc: 0.5909\n",
      "Epoch 366/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5909 - val_loss: 0.1002 - val_auc: 0.5910\n",
      "Epoch 367/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5910 - val_loss: 0.1001 - val_auc: 0.5912\n",
      "Epoch 368/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5913 - val_loss: 0.1002 - val_auc: 0.5914\n",
      "Epoch 369/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5914 - val_loss: 0.1001 - val_auc: 0.5915\n",
      "Epoch 370/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5915 - val_loss: 0.1002 - val_auc: 0.5917\n",
      "Epoch 371/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5917 - val_loss: 0.1003 - val_auc: 0.5918\n",
      "Epoch 372/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5919 - val_loss: 0.1003 - val_auc: 0.5920\n",
      "Epoch 373/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5920 - val_loss: 0.1003 - val_auc: 0.5922\n",
      "Epoch 374/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5922 - val_loss: 0.1004 - val_auc: 0.5923\n",
      "Epoch 375/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5923 - val_loss: 0.1002 - val_auc: 0.5925\n",
      "Epoch 376/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5925 - val_loss: 0.1002 - val_auc: 0.5927\n",
      "Epoch 377/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5927 - val_loss: 0.1003 - val_auc: 0.5928\n",
      "Epoch 378/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5928 - val_loss: 0.1003 - val_auc: 0.5930\n",
      "Epoch 379/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5930 - val_loss: 0.1003 - val_auc: 0.5932\n",
      "Epoch 380/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0524 - auc: 0.5932 - val_loss: 0.1003 - val_auc: 0.5933\n",
      "Epoch 381/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5934 - val_loss: 0.1004 - val_auc: 0.5935\n",
      "Epoch 382/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5936 - val_loss: 0.1004 - val_auc: 0.5937\n",
      "Epoch 383/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5936 - val_loss: 0.1003 - val_auc: 0.5938\n",
      "Epoch 384/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5938 - val_loss: 0.1005 - val_auc: 0.5940\n",
      "Epoch 385/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5940 - val_loss: 0.1004 - val_auc: 0.5942\n",
      "Epoch 386/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5942 - val_loss: 0.1005 - val_auc: 0.5943\n",
      "Epoch 387/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5943 - val_loss: 0.1002 - val_auc: 0.5945\n",
      "Epoch 388/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5945 - val_loss: 0.1004 - val_auc: 0.5947\n",
      "Epoch 389/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5947 - val_loss: 0.1005 - val_auc: 0.5948\n",
      "Epoch 390/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5949 - val_loss: 0.1003 - val_auc: 0.5950\n",
      "Epoch 391/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5951 - val_loss: 0.1006 - val_auc: 0.5952\n",
      "Epoch 392/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5952 - val_loss: 0.1005 - val_auc: 0.5953\n",
      "Epoch 393/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5954 - val_loss: 0.1004 - val_auc: 0.5955\n",
      "Epoch 394/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5956 - val_loss: 0.1005 - val_auc: 0.5957\n",
      "Epoch 395/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5957 - val_loss: 0.1006 - val_auc: 0.5959\n",
      "Epoch 396/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5959 - val_loss: 0.1006 - val_auc: 0.5960\n",
      "Epoch 397/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5961 - val_loss: 0.1004 - val_auc: 0.5962\n",
      "Epoch 398/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5962 - val_loss: 0.1004 - val_auc: 0.5964\n",
      "Epoch 399/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5964 - val_loss: 0.1005 - val_auc: 0.5966\n",
      "Epoch 400/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5966 - val_loss: 0.1005 - val_auc: 0.5967\n",
      "Epoch 401/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5968 - val_loss: 0.1005 - val_auc: 0.5969\n",
      "Epoch 402/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5970 - val_loss: 0.1006 - val_auc: 0.5971\n",
      "Epoch 403/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5972 - val_loss: 0.1006 - val_auc: 0.5973\n",
      "Epoch 404/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5973 - val_loss: 0.1007 - val_auc: 0.5974\n",
      "Epoch 405/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5975 - val_loss: 0.1005 - val_auc: 0.5976\n",
      "Epoch 406/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5977 - val_loss: 0.1007 - val_auc: 0.5978\n",
      "Epoch 407/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5979 - val_loss: 0.1004 - val_auc: 0.5980\n",
      "Epoch 408/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5980 - val_loss: 0.1006 - val_auc: 0.5981\n",
      "Epoch 409/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5982 - val_loss: 0.1006 - val_auc: 0.5983\n",
      "Epoch 410/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5984 - val_loss: 0.1005 - val_auc: 0.5985\n",
      "Epoch 411/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5986 - val_loss: 0.1006 - val_auc: 0.5987\n",
      "Epoch 412/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5987 - val_loss: 0.1006 - val_auc: 0.5988\n",
      "Epoch 413/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5989 - val_loss: 0.1006 - val_auc: 0.5990\n",
      "Epoch 414/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5991 - val_loss: 0.1004 - val_auc: 0.5992\n",
      "Epoch 415/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5992 - val_loss: 0.1005 - val_auc: 0.5994\n",
      "Epoch 416/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5994 - val_loss: 0.1006 - val_auc: 0.5995\n",
      "Epoch 417/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5997 - val_loss: 0.1006 - val_auc: 0.5997\n",
      "Epoch 418/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.5997 - val_loss: 0.1006 - val_auc: 0.5999\n",
      "Epoch 419/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6000 - val_loss: 0.1005 - val_auc: 0.6001\n",
      "Epoch 420/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6001 - val_loss: 0.1004 - val_auc: 0.6002\n",
      "Epoch 421/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6003 - val_loss: 0.1005 - val_auc: 0.6004\n",
      "Epoch 422/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6005 - val_loss: 0.1006 - val_auc: 0.6006\n",
      "Epoch 423/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6006 - val_loss: 0.1006 - val_auc: 0.6008\n",
      "Epoch 424/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6008 - val_loss: 0.1005 - val_auc: 0.6009\n",
      "Epoch 425/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6010 - val_loss: 0.1004 - val_auc: 0.6011\n",
      "Epoch 426/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6011 - val_loss: 0.1004 - val_auc: 0.6013\n",
      "Epoch 427/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6013 - val_loss: 0.1006 - val_auc: 0.6015\n",
      "Epoch 428/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6015 - val_loss: 0.1006 - val_auc: 0.6016\n",
      "Epoch 429/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6017 - val_loss: 0.1005 - val_auc: 0.6018\n",
      "Epoch 430/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6019 - val_loss: 0.1005 - val_auc: 0.6020\n",
      "Epoch 431/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6021 - val_loss: 0.1007 - val_auc: 0.6022\n",
      "Epoch 432/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6022 - val_loss: 0.1003 - val_auc: 0.6024\n",
      "Epoch 433/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6024 - val_loss: 0.1006 - val_auc: 0.6025\n",
      "Epoch 434/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6026 - val_loss: 0.1005 - val_auc: 0.6027\n",
      "Epoch 435/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6028 - val_loss: 0.1005 - val_auc: 0.6029\n",
      "Epoch 436/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6030 - val_loss: 0.1006 - val_auc: 0.6031\n",
      "Epoch 437/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6031 - val_loss: 0.1004 - val_auc: 0.6033\n",
      "Epoch 438/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6033 - val_loss: 0.1007 - val_auc: 0.6034\n",
      "Epoch 439/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6035 - val_loss: 0.1006 - val_auc: 0.6036\n",
      "Epoch 440/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6037 - val_loss: 0.1006 - val_auc: 0.6038\n",
      "Epoch 441/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6038 - val_loss: 0.1006 - val_auc: 0.6040\n",
      "Epoch 442/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6040 - val_loss: 0.1006 - val_auc: 0.6041\n",
      "Epoch 443/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6042 - val_loss: 0.1005 - val_auc: 0.6043\n",
      "Epoch 444/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6044 - val_loss: 0.1007 - val_auc: 0.6045\n",
      "Epoch 445/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6046 - val_loss: 0.1006 - val_auc: 0.6047\n",
      "Epoch 446/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6047 - val_loss: 0.1004 - val_auc: 0.6048\n",
      "Epoch 447/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6049 - val_loss: 0.1007 - val_auc: 0.6050\n",
      "Epoch 448/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6051 - val_loss: 0.1006 - val_auc: 0.6052\n",
      "Epoch 449/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6053 - val_loss: 0.1007 - val_auc: 0.6054\n",
      "Epoch 450/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6054 - val_loss: 0.1005 - val_auc: 0.6055\n",
      "Epoch 451/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6056 - val_loss: 0.1006 - val_auc: 0.6057\n",
      "Epoch 452/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6058 - val_loss: 0.1006 - val_auc: 0.6059\n",
      "Epoch 453/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6060 - val_loss: 0.1004 - val_auc: 0.6061\n",
      "Epoch 454/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6061 - val_loss: 0.1006 - val_auc: 0.6062\n",
      "Epoch 455/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6063 - val_loss: 0.1006 - val_auc: 0.6064\n",
      "Epoch 456/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6065 - val_loss: 0.1005 - val_auc: 0.6066\n",
      "Epoch 457/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6066 - val_loss: 0.1005 - val_auc: 0.6068\n",
      "Epoch 458/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6068 - val_loss: 0.1007 - val_auc: 0.6069\n",
      "Epoch 459/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6069 - val_loss: 0.1004 - val_auc: 0.6071\n",
      "Epoch 460/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6072 - val_loss: 0.1008 - val_auc: 0.6073\n",
      "Epoch 461/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6073 - val_loss: 0.1006 - val_auc: 0.6074\n",
      "Epoch 462/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6075 - val_loss: 0.1007 - val_auc: 0.6076\n",
      "Epoch 463/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6077 - val_loss: 0.1007 - val_auc: 0.6078\n",
      "Epoch 464/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6078 - val_loss: 0.1006 - val_auc: 0.6080\n",
      "Epoch 465/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6080 - val_loss: 0.1007 - val_auc: 0.6081\n",
      "Epoch 466/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6082 - val_loss: 0.1007 - val_auc: 0.6083\n",
      "Epoch 467/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6084 - val_loss: 0.1005 - val_auc: 0.6085\n",
      "Epoch 468/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6086 - val_loss: 0.1006 - val_auc: 0.6086\n",
      "Epoch 469/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6087 - val_loss: 0.1006 - val_auc: 0.6088\n",
      "Epoch 470/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6089 - val_loss: 0.1007 - val_auc: 0.6090\n",
      "Epoch 471/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6091 - val_loss: 0.1006 - val_auc: 0.6092\n",
      "Epoch 472/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6092 - val_loss: 0.1006 - val_auc: 0.6093\n",
      "Epoch 473/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6094 - val_loss: 0.1006 - val_auc: 0.6095\n",
      "Epoch 474/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6096 - val_loss: 0.1006 - val_auc: 0.6097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6097 - val_loss: 0.1007 - val_auc: 0.6098\n",
      "Epoch 476/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6099 - val_loss: 0.1006 - val_auc: 0.6100\n",
      "Epoch 477/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6101 - val_loss: 0.1009 - val_auc: 0.6102\n",
      "Epoch 478/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6102 - val_loss: 0.1006 - val_auc: 0.6103\n",
      "Epoch 479/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6104 - val_loss: 0.1008 - val_auc: 0.6105\n",
      "Epoch 480/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6106 - val_loss: 0.1005 - val_auc: 0.6107\n",
      "Epoch 481/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6107 - val_loss: 0.1007 - val_auc: 0.6108\n",
      "Epoch 482/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6109 - val_loss: 0.1008 - val_auc: 0.6110\n",
      "Epoch 483/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6111 - val_loss: 0.1006 - val_auc: 0.6112\n",
      "Epoch 484/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6113 - val_loss: 0.1008 - val_auc: 0.6114\n",
      "Epoch 485/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6114 - val_loss: 0.1007 - val_auc: 0.6115\n",
      "Epoch 486/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6116 - val_loss: 0.1008 - val_auc: 0.6117\n",
      "Epoch 487/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6117 - val_loss: 0.1007 - val_auc: 0.6119\n",
      "Epoch 488/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6119 - val_loss: 0.1004 - val_auc: 0.6120\n",
      "Epoch 489/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6121 - val_loss: 0.1007 - val_auc: 0.6122\n",
      "Epoch 490/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6123 - val_loss: 0.1008 - val_auc: 0.6124\n",
      "Epoch 491/1000\n",
      " - 0s - loss: 0.0523 - auc: 0.6124 - val_loss: 0.1006 - val_auc: 0.6125\n",
      "Epoch 492/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6126 - val_loss: 0.1008 - val_auc: 0.6127\n",
      "Epoch 493/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6127 - val_loss: 0.1005 - val_auc: 0.6129\n",
      "Epoch 494/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6129 - val_loss: 0.1007 - val_auc: 0.6131\n",
      "Epoch 495/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.6131 - val_loss: 0.1004 - val_auc: 0.6132\n",
      "Epoch 496/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6133 - val_loss: 0.1007 - val_auc: 0.6134\n",
      "Epoch 497/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6135 - val_loss: 0.1007 - val_auc: 0.6136\n",
      "Epoch 498/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6136 - val_loss: 0.1007 - val_auc: 0.6137\n",
      "Epoch 499/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6138 - val_loss: 0.1007 - val_auc: 0.6139\n",
      "Epoch 500/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6139 - val_loss: 0.1007 - val_auc: 0.6141\n",
      "Epoch 501/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6141 - val_loss: 0.1006 - val_auc: 0.6142\n",
      "Epoch 502/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6143 - val_loss: 0.1008 - val_auc: 0.6144\n",
      "Epoch 503/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6144 - val_loss: 0.1005 - val_auc: 0.6145\n",
      "Epoch 504/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6146 - val_loss: 0.1005 - val_auc: 0.6147\n",
      "Epoch 505/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6148 - val_loss: 0.1009 - val_auc: 0.6149\n",
      "Epoch 506/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6149 - val_loss: 0.1008 - val_auc: 0.6150\n",
      "Epoch 507/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6151 - val_loss: 0.1009 - val_auc: 0.6152\n",
      "Epoch 508/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6153 - val_loss: 0.1006 - val_auc: 0.6154\n",
      "Epoch 509/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6154 - val_loss: 0.1005 - val_auc: 0.6155\n",
      "Epoch 510/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6156 - val_loss: 0.1006 - val_auc: 0.6157\n",
      "Epoch 511/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6157 - val_loss: 0.1007 - val_auc: 0.6159\n",
      "Epoch 512/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6159 - val_loss: 0.1008 - val_auc: 0.6160\n",
      "Epoch 513/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6161 - val_loss: 0.1008 - val_auc: 0.6162\n",
      "Epoch 514/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6163 - val_loss: 0.1007 - val_auc: 0.6163\n",
      "Epoch 515/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6164 - val_loss: 0.1010 - val_auc: 0.6165\n",
      "Epoch 516/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6166 - val_loss: 0.1008 - val_auc: 0.6167\n",
      "Epoch 517/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6167 - val_loss: 0.1005 - val_auc: 0.6168\n",
      "Epoch 518/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6168 - val_loss: 0.1005 - val_auc: 0.6170\n",
      "Epoch 519/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6171 - val_loss: 0.1007 - val_auc: 0.6171\n",
      "Epoch 520/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6172 - val_loss: 0.1006 - val_auc: 0.6173\n",
      "Epoch 521/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6174 - val_loss: 0.1006 - val_auc: 0.6175\n",
      "Epoch 522/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6175 - val_loss: 0.1007 - val_auc: 0.6176\n",
      "Epoch 523/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6177 - val_loss: 0.1007 - val_auc: 0.6178\n",
      "Epoch 524/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6179 - val_loss: 0.1007 - val_auc: 0.6180\n",
      "Epoch 525/1000\n",
      " - 0s - loss: 0.0523 - auc: 0.6180 - val_loss: 0.1008 - val_auc: 0.6181\n",
      "Epoch 526/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6182 - val_loss: 0.1005 - val_auc: 0.6183\n",
      "Epoch 527/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6183 - val_loss: 0.1007 - val_auc: 0.6184\n",
      "Epoch 528/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6185 - val_loss: 0.1007 - val_auc: 0.6186\n",
      "Epoch 529/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6187 - val_loss: 0.1007 - val_auc: 0.6187\n",
      "Epoch 530/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6188 - val_loss: 0.1010 - val_auc: 0.6189\n",
      "Epoch 531/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6189 - val_loss: 0.1007 - val_auc: 0.6191\n",
      "Epoch 532/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6191 - val_loss: 0.1005 - val_auc: 0.6192\n",
      "Epoch 533/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6193 - val_loss: 0.1006 - val_auc: 0.6194\n",
      "Epoch 534/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6194 - val_loss: 0.1007 - val_auc: 0.6195\n",
      "Epoch 535/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6196 - val_loss: 0.1006 - val_auc: 0.6197\n",
      "Epoch 536/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6197 - val_loss: 0.1007 - val_auc: 0.6198\n",
      "Epoch 537/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6199 - val_loss: 0.1006 - val_auc: 0.6200\n",
      "Epoch 538/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6201 - val_loss: 0.1008 - val_auc: 0.6202\n",
      "Epoch 539/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6202 - val_loss: 0.1005 - val_auc: 0.6203\n",
      "Epoch 540/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6204 - val_loss: 0.1008 - val_auc: 0.6205\n",
      "Epoch 541/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6205 - val_loss: 0.1007 - val_auc: 0.6206\n",
      "Epoch 542/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6207 - val_loss: 0.1006 - val_auc: 0.6208\n",
      "Epoch 543/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6208 - val_loss: 0.1006 - val_auc: 0.6209\n",
      "Epoch 544/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.6210 - val_loss: 0.1004 - val_auc: 0.6211\n",
      "Epoch 545/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6211 - val_loss: 0.1009 - val_auc: 0.6212\n",
      "Epoch 546/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6213 - val_loss: 0.1005 - val_auc: 0.6214\n",
      "Epoch 547/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6215 - val_loss: 0.1010 - val_auc: 0.6216\n",
      "Epoch 548/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6216 - val_loss: 0.1005 - val_auc: 0.6217\n",
      "Epoch 549/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6218 - val_loss: 0.1009 - val_auc: 0.6219\n",
      "Epoch 550/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6219 - val_loss: 0.1007 - val_auc: 0.6220\n",
      "Epoch 551/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6221 - val_loss: 0.1008 - val_auc: 0.6222\n",
      "Epoch 552/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6222 - val_loss: 0.1006 - val_auc: 0.6223\n",
      "Epoch 553/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6224 - val_loss: 0.1006 - val_auc: 0.6225\n",
      "Epoch 554/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6226 - val_loss: 0.1007 - val_auc: 0.6226\n",
      "Epoch 555/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6227 - val_loss: 0.1006 - val_auc: 0.6228\n",
      "Epoch 556/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6229 - val_loss: 0.1007 - val_auc: 0.6230\n",
      "Epoch 557/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6230 - val_loss: 0.1008 - val_auc: 0.6231\n",
      "Epoch 558/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6232 - val_loss: 0.1006 - val_auc: 0.6233\n",
      "Epoch 559/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6233 - val_loss: 0.1007 - val_auc: 0.6234\n",
      "Epoch 560/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6235 - val_loss: 0.1006 - val_auc: 0.6236\n",
      "Epoch 561/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6236 - val_loss: 0.1006 - val_auc: 0.6237\n",
      "Epoch 562/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6238 - val_loss: 0.1005 - val_auc: 0.6239\n",
      "Epoch 563/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6239 - val_loss: 0.1009 - val_auc: 0.6240\n",
      "Epoch 564/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6241 - val_loss: 0.1007 - val_auc: 0.6242\n",
      "Epoch 565/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6242 - val_loss: 0.1007 - val_auc: 0.6243\n",
      "Epoch 566/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6244 - val_loss: 0.1008 - val_auc: 0.6245\n",
      "Epoch 567/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6245 - val_loss: 0.1006 - val_auc: 0.6246\n",
      "Epoch 568/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6246 - val_loss: 0.1007 - val_auc: 0.6248\n",
      "Epoch 569/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0524 - auc: 0.6248 - val_loss: 0.1008 - val_auc: 0.6249\n",
      "Epoch 570/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6249 - val_loss: 0.1006 - val_auc: 0.6250\n",
      "Epoch 571/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6251 - val_loss: 0.1007 - val_auc: 0.6252\n",
      "Epoch 572/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6253 - val_loss: 0.1006 - val_auc: 0.6253\n",
      "Epoch 573/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6254 - val_loss: 0.1007 - val_auc: 0.6255\n",
      "Epoch 574/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6255 - val_loss: 0.1006 - val_auc: 0.6256\n",
      "Epoch 575/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6257 - val_loss: 0.1007 - val_auc: 0.6258\n",
      "Epoch 576/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6258 - val_loss: 0.1005 - val_auc: 0.6259\n",
      "Epoch 577/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6260 - val_loss: 0.1007 - val_auc: 0.6261\n",
      "Epoch 578/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6261 - val_loss: 0.1007 - val_auc: 0.6262\n",
      "Epoch 579/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6263 - val_loss: 0.1006 - val_auc: 0.6264\n",
      "Epoch 580/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6264 - val_loss: 0.1005 - val_auc: 0.6265\n",
      "Epoch 581/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6266 - val_loss: 0.1007 - val_auc: 0.6267\n",
      "Epoch 582/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6267 - val_loss: 0.1005 - val_auc: 0.6268\n",
      "Epoch 583/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6269 - val_loss: 0.1007 - val_auc: 0.6269\n",
      "Epoch 584/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6270 - val_loss: 0.1008 - val_auc: 0.6271\n",
      "Epoch 585/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6271 - val_loss: 0.1004 - val_auc: 0.6272\n",
      "Epoch 586/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6273 - val_loss: 0.1007 - val_auc: 0.6274\n",
      "Epoch 587/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6274 - val_loss: 0.1008 - val_auc: 0.6275\n",
      "Epoch 588/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6276 - val_loss: 0.1008 - val_auc: 0.6276\n",
      "Epoch 589/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6277 - val_loss: 0.1007 - val_auc: 0.6278\n",
      "Epoch 590/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6278 - val_loss: 0.1006 - val_auc: 0.6279\n",
      "Epoch 591/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6280 - val_loss: 0.1006 - val_auc: 0.6281\n",
      "Epoch 592/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6281 - val_loss: 0.1006 - val_auc: 0.6282\n",
      "Epoch 593/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6283 - val_loss: 0.1007 - val_auc: 0.6284\n",
      "Epoch 594/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6284 - val_loss: 0.1006 - val_auc: 0.6285\n",
      "Epoch 595/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6285 - val_loss: 0.1008 - val_auc: 0.6286\n",
      "Epoch 596/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6287 - val_loss: 0.1007 - val_auc: 0.6288\n",
      "Epoch 597/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6288 - val_loss: 0.1008 - val_auc: 0.6289\n",
      "Epoch 598/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6290 - val_loss: 0.1008 - val_auc: 0.6291\n",
      "Epoch 599/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6291 - val_loss: 0.1006 - val_auc: 0.6292\n",
      "Epoch 600/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6293 - val_loss: 0.1008 - val_auc: 0.6294\n",
      "Epoch 601/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6294 - val_loss: 0.1008 - val_auc: 0.6295\n",
      "Epoch 602/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6295 - val_loss: 0.1008 - val_auc: 0.6296\n",
      "Epoch 603/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6297 - val_loss: 0.1007 - val_auc: 0.6298\n",
      "Epoch 604/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6298 - val_loss: 0.1005 - val_auc: 0.6299\n",
      "Epoch 605/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6300 - val_loss: 0.1008 - val_auc: 0.6301\n",
      "Epoch 606/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6301 - val_loss: 0.1005 - val_auc: 0.6302\n",
      "Epoch 607/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6302 - val_loss: 0.1006 - val_auc: 0.6303\n",
      "Epoch 608/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6304 - val_loss: 0.1006 - val_auc: 0.6305\n",
      "Epoch 609/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6305 - val_loss: 0.1007 - val_auc: 0.6306\n",
      "Epoch 610/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6306 - val_loss: 0.1006 - val_auc: 0.6307\n",
      "Epoch 611/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6308 - val_loss: 0.1008 - val_auc: 0.6309\n",
      "Epoch 612/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6309 - val_loss: 0.1006 - val_auc: 0.6310\n",
      "Epoch 613/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6310 - val_loss: 0.1007 - val_auc: 0.6311\n",
      "Epoch 614/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6312 - val_loss: 0.1007 - val_auc: 0.6313\n",
      "Epoch 615/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6313 - val_loss: 0.1008 - val_auc: 0.6314\n",
      "Epoch 616/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6315 - val_loss: 0.1005 - val_auc: 0.6315\n",
      "Epoch 617/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6316 - val_loss: 0.1008 - val_auc: 0.6317\n",
      "Epoch 618/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6317 - val_loss: 0.1007 - val_auc: 0.6318\n",
      "Epoch 619/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6319 - val_loss: 0.1005 - val_auc: 0.6320\n",
      "Epoch 620/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6320 - val_loss: 0.1005 - val_auc: 0.6321\n",
      "Epoch 621/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6321 - val_loss: 0.1008 - val_auc: 0.6322\n",
      "Epoch 622/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6323 - val_loss: 0.1006 - val_auc: 0.6324\n",
      "Epoch 623/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6324 - val_loss: 0.1007 - val_auc: 0.6325\n",
      "Epoch 624/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6326 - val_loss: 0.1007 - val_auc: 0.6326\n",
      "Epoch 625/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6327 - val_loss: 0.1009 - val_auc: 0.6328\n",
      "Epoch 626/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6328 - val_loss: 0.1007 - val_auc: 0.6329\n",
      "Epoch 627/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6329 - val_loss: 0.1006 - val_auc: 0.6330\n",
      "Epoch 628/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6331 - val_loss: 0.1006 - val_auc: 0.6332\n",
      "Epoch 629/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6332 - val_loss: 0.1004 - val_auc: 0.6333\n",
      "Epoch 630/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6333 - val_loss: 0.1008 - val_auc: 0.6334\n",
      "Epoch 631/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6335 - val_loss: 0.1006 - val_auc: 0.6336\n",
      "Epoch 632/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6336 - val_loss: 0.1006 - val_auc: 0.6337\n",
      "Epoch 633/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6337 - val_loss: 0.1007 - val_auc: 0.6338\n",
      "Epoch 634/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6339 - val_loss: 0.1007 - val_auc: 0.6339\n",
      "Epoch 635/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6340 - val_loss: 0.1009 - val_auc: 0.6341\n",
      "Epoch 636/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6341 - val_loss: 0.1007 - val_auc: 0.6342\n",
      "Epoch 637/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6343 - val_loss: 0.1007 - val_auc: 0.6343\n",
      "Epoch 638/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6344 - val_loss: 0.1008 - val_auc: 0.6345\n",
      "Epoch 639/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6345 - val_loss: 0.1006 - val_auc: 0.6346\n",
      "Epoch 640/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6346 - val_loss: 0.1007 - val_auc: 0.6347\n",
      "Epoch 641/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6348 - val_loss: 0.1007 - val_auc: 0.6348\n",
      "Epoch 642/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6349 - val_loss: 0.1008 - val_auc: 0.6350\n",
      "Epoch 643/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6350 - val_loss: 0.1007 - val_auc: 0.6351\n",
      "Epoch 644/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6351 - val_loss: 0.1004 - val_auc: 0.6352\n",
      "Epoch 645/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.6353 - val_loss: 0.1008 - val_auc: 0.6354\n",
      "Epoch 646/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6354 - val_loss: 0.1004 - val_auc: 0.6355\n",
      "Epoch 647/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6355 - val_loss: 0.1007 - val_auc: 0.6356\n",
      "Epoch 648/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6356 - val_loss: 0.1004 - val_auc: 0.6358\n",
      "Epoch 649/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6358 - val_loss: 0.1007 - val_auc: 0.6359\n",
      "Epoch 650/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6359 - val_loss: 0.1006 - val_auc: 0.6360\n",
      "Epoch 651/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6361 - val_loss: 0.1006 - val_auc: 0.6361\n",
      "Epoch 652/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6362 - val_loss: 0.1008 - val_auc: 0.6363\n",
      "Epoch 653/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6363 - val_loss: 0.1005 - val_auc: 0.6364\n",
      "Epoch 654/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6364 - val_loss: 0.1008 - val_auc: 0.6365\n",
      "Epoch 655/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6366 - val_loss: 0.1008 - val_auc: 0.6366\n",
      "Epoch 656/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6367 - val_loss: 0.1006 - val_auc: 0.6368\n",
      "Epoch 657/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6368 - val_loss: 0.1009 - val_auc: 0.6369\n",
      "Epoch 658/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6370 - val_loss: 0.1005 - val_auc: 0.6370\n",
      "Epoch 659/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6371 - val_loss: 0.1007 - val_auc: 0.6371\n",
      "Epoch 660/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6372 - val_loss: 0.1007 - val_auc: 0.6373\n",
      "Epoch 661/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6373 - val_loss: 0.1006 - val_auc: 0.6374\n",
      "Epoch 662/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6375 - val_loss: 0.1008 - val_auc: 0.6375\n",
      "Epoch 663/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6376 - val_loss: 0.1007 - val_auc: 0.6376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 664/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6377 - val_loss: 0.1008 - val_auc: 0.6378\n",
      "Epoch 665/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6378 - val_loss: 0.1007 - val_auc: 0.6379\n",
      "Epoch 666/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6379 - val_loss: 0.1006 - val_auc: 0.6380\n",
      "Epoch 667/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6381 - val_loss: 0.1007 - val_auc: 0.6381\n",
      "Epoch 668/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6382 - val_loss: 0.1006 - val_auc: 0.6383\n",
      "Epoch 669/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6383 - val_loss: 0.1006 - val_auc: 0.6384\n",
      "Epoch 670/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6384 - val_loss: 0.1006 - val_auc: 0.6385\n",
      "Epoch 671/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6386 - val_loss: 0.1007 - val_auc: 0.6386\n",
      "Epoch 672/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6387 - val_loss: 0.1006 - val_auc: 0.6388\n",
      "Epoch 673/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6388 - val_loss: 0.1008 - val_auc: 0.6389\n",
      "Epoch 674/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6389 - val_loss: 0.1007 - val_auc: 0.6390\n",
      "Epoch 675/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6391 - val_loss: 0.1009 - val_auc: 0.6391\n",
      "Epoch 676/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6392 - val_loss: 0.1007 - val_auc: 0.6392\n",
      "Epoch 677/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6393 - val_loss: 0.1007 - val_auc: 0.6394\n",
      "Epoch 678/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6394 - val_loss: 0.1007 - val_auc: 0.6395\n",
      "Epoch 679/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6395 - val_loss: 0.1007 - val_auc: 0.6396\n",
      "Epoch 680/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6397 - val_loss: 0.1007 - val_auc: 0.6397\n",
      "Epoch 681/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6398 - val_loss: 0.1006 - val_auc: 0.6398\n",
      "Epoch 682/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6399 - val_loss: 0.1009 - val_auc: 0.6400\n",
      "Epoch 683/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6400 - val_loss: 0.1008 - val_auc: 0.6401\n",
      "Epoch 684/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6401 - val_loss: 0.1007 - val_auc: 0.6402\n",
      "Epoch 685/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6403 - val_loss: 0.1007 - val_auc: 0.6403\n",
      "Epoch 686/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6404 - val_loss: 0.1006 - val_auc: 0.6405\n",
      "Epoch 687/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6405 - val_loss: 0.1008 - val_auc: 0.6406\n",
      "Epoch 688/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6406 - val_loss: 0.1007 - val_auc: 0.6407\n",
      "Epoch 689/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6407 - val_loss: 0.1007 - val_auc: 0.6408\n",
      "Epoch 690/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6409 - val_loss: 0.1006 - val_auc: 0.6409\n",
      "Epoch 691/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6410 - val_loss: 0.1004 - val_auc: 0.6411\n",
      "Epoch 692/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6411 - val_loss: 0.1009 - val_auc: 0.6412\n",
      "Epoch 693/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6412 - val_loss: 0.1008 - val_auc: 0.6413\n",
      "Epoch 694/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6413 - val_loss: 0.1006 - val_auc: 0.6414\n",
      "Epoch 695/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6415 - val_loss: 0.1005 - val_auc: 0.6415\n",
      "Epoch 696/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6416 - val_loss: 0.1007 - val_auc: 0.6416\n",
      "Epoch 697/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6417 - val_loss: 0.1006 - val_auc: 0.6417\n",
      "Epoch 698/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6418 - val_loss: 0.1007 - val_auc: 0.6419\n",
      "Epoch 699/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6419 - val_loss: 0.1007 - val_auc: 0.6420\n",
      "Epoch 700/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6420 - val_loss: 0.1006 - val_auc: 0.6421\n",
      "Epoch 701/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6422 - val_loss: 0.1007 - val_auc: 0.6422\n",
      "Epoch 702/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6423 - val_loss: 0.1006 - val_auc: 0.6423\n",
      "Epoch 703/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6424 - val_loss: 0.1008 - val_auc: 0.6425\n",
      "Epoch 704/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6425 - val_loss: 0.1008 - val_auc: 0.6426\n",
      "Epoch 705/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6426 - val_loss: 0.1006 - val_auc: 0.6427\n",
      "Epoch 706/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6427 - val_loss: 0.1007 - val_auc: 0.6428\n",
      "Epoch 707/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6428 - val_loss: 0.1007 - val_auc: 0.6429\n",
      "Epoch 708/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6430 - val_loss: 0.1006 - val_auc: 0.6430\n",
      "Epoch 709/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6431 - val_loss: 0.1005 - val_auc: 0.6431\n",
      "Epoch 710/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6432 - val_loss: 0.1006 - val_auc: 0.6433\n",
      "Epoch 711/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6433 - val_loss: 0.1007 - val_auc: 0.6434\n",
      "Epoch 712/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6434 - val_loss: 0.1004 - val_auc: 0.6435\n",
      "Epoch 713/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6435 - val_loss: 0.1007 - val_auc: 0.6436\n",
      "Epoch 714/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6436 - val_loss: 0.1005 - val_auc: 0.6437\n",
      "Epoch 715/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6438 - val_loss: 0.1004 - val_auc: 0.6438\n",
      "Epoch 716/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6439 - val_loss: 0.1007 - val_auc: 0.6439\n",
      "Epoch 717/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6440 - val_loss: 0.1005 - val_auc: 0.6441\n",
      "Epoch 718/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6441 - val_loss: 0.1005 - val_auc: 0.6442\n",
      "Epoch 719/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6442 - val_loss: 0.1007 - val_auc: 0.6443\n",
      "Epoch 720/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6443 - val_loss: 0.1006 - val_auc: 0.6444\n",
      "Epoch 721/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6444 - val_loss: 0.1005 - val_auc: 0.6445\n",
      "Epoch 722/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6446 - val_loss: 0.1009 - val_auc: 0.6446\n",
      "Epoch 723/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6447 - val_loss: 0.1008 - val_auc: 0.6447\n",
      "Epoch 724/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6447 - val_loss: 0.1006 - val_auc: 0.6448\n",
      "Epoch 725/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6449 - val_loss: 0.1007 - val_auc: 0.6449\n",
      "Epoch 726/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6450 - val_loss: 0.1007 - val_auc: 0.6450\n",
      "Epoch 727/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6451 - val_loss: 0.1006 - val_auc: 0.6452\n",
      "Epoch 728/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6452 - val_loss: 0.1005 - val_auc: 0.6453\n",
      "Epoch 729/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6453 - val_loss: 0.1006 - val_auc: 0.6454\n",
      "Epoch 730/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6454 - val_loss: 0.1005 - val_auc: 0.6455\n",
      "Epoch 731/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6455 - val_loss: 0.1006 - val_auc: 0.6456\n",
      "Epoch 732/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6456 - val_loss: 0.1007 - val_auc: 0.6457\n",
      "Epoch 733/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6457 - val_loss: 0.1006 - val_auc: 0.6458\n",
      "Epoch 734/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6459 - val_loss: 0.1008 - val_auc: 0.6459\n",
      "Epoch 735/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6460 - val_loss: 0.1005 - val_auc: 0.6460\n",
      "Epoch 736/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6461 - val_loss: 0.1007 - val_auc: 0.6461\n",
      "Epoch 737/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6462 - val_loss: 0.1008 - val_auc: 0.6462\n",
      "Epoch 738/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6463 - val_loss: 0.1005 - val_auc: 0.6464\n",
      "Epoch 739/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6464 - val_loss: 0.1006 - val_auc: 0.6465\n",
      "Epoch 740/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6465 - val_loss: 0.1005 - val_auc: 0.6466\n",
      "Epoch 741/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6466 - val_loss: 0.1007 - val_auc: 0.6467\n",
      "Epoch 742/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6467 - val_loss: 0.1005 - val_auc: 0.6468\n",
      "Epoch 743/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6468 - val_loss: 0.1009 - val_auc: 0.6469\n",
      "Epoch 744/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6469 - val_loss: 0.1006 - val_auc: 0.6470\n",
      "Epoch 745/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6471 - val_loss: 0.1006 - val_auc: 0.6471\n",
      "Epoch 746/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6472 - val_loss: 0.1009 - val_auc: 0.6472\n",
      "Epoch 747/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6473 - val_loss: 0.1007 - val_auc: 0.6473\n",
      "Epoch 748/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6474 - val_loss: 0.1006 - val_auc: 0.6474\n",
      "Epoch 749/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6475 - val_loss: 0.1006 - val_auc: 0.6475\n",
      "Epoch 750/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6476 - val_loss: 0.1009 - val_auc: 0.6476\n",
      "Epoch 751/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6477 - val_loss: 0.1006 - val_auc: 0.6478\n",
      "Epoch 752/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6478 - val_loss: 0.1005 - val_auc: 0.6479\n",
      "Epoch 753/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6479 - val_loss: 0.1008 - val_auc: 0.6480\n",
      "Epoch 754/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6480 - val_loss: 0.1008 - val_auc: 0.6481\n",
      "Epoch 755/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6481 - val_loss: 0.1006 - val_auc: 0.6482\n",
      "Epoch 756/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6482 - val_loss: 0.1007 - val_auc: 0.6483\n",
      "Epoch 757/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6483 - val_loss: 0.1008 - val_auc: 0.6484\n",
      "Epoch 758/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0524 - auc: 0.6484 - val_loss: 0.1006 - val_auc: 0.6485\n",
      "Epoch 759/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6485 - val_loss: 0.1008 - val_auc: 0.6486\n",
      "Epoch 760/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6486 - val_loss: 0.1006 - val_auc: 0.6487\n",
      "Epoch 761/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6487 - val_loss: 0.1008 - val_auc: 0.6488\n",
      "Epoch 762/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6488 - val_loss: 0.1006 - val_auc: 0.6489\n",
      "Epoch 763/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6489 - val_loss: 0.1006 - val_auc: 0.6490\n",
      "Epoch 764/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6491 - val_loss: 0.1006 - val_auc: 0.6491\n",
      "Epoch 765/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6492 - val_loss: 0.1008 - val_auc: 0.6492\n",
      "Epoch 766/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6493 - val_loss: 0.1008 - val_auc: 0.6493\n",
      "Epoch 767/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6494 - val_loss: 0.1006 - val_auc: 0.6494\n",
      "Epoch 768/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6495 - val_loss: 0.1005 - val_auc: 0.6495\n",
      "Epoch 769/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6496 - val_loss: 0.1006 - val_auc: 0.6496\n",
      "Epoch 770/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6497 - val_loss: 0.1007 - val_auc: 0.6497\n",
      "Epoch 771/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6498 - val_loss: 0.1006 - val_auc: 0.6498\n",
      "Epoch 772/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6499 - val_loss: 0.1007 - val_auc: 0.6499\n",
      "Epoch 773/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6500 - val_loss: 0.1006 - val_auc: 0.6500\n",
      "Epoch 774/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6501 - val_loss: 0.1007 - val_auc: 0.6501\n",
      "Epoch 775/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6501 - val_loss: 0.1006 - val_auc: 0.6502\n",
      "Epoch 776/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6503 - val_loss: 0.1005 - val_auc: 0.6503\n",
      "Epoch 777/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6504 - val_loss: 0.1006 - val_auc: 0.6504\n",
      "Epoch 778/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6505 - val_loss: 0.1006 - val_auc: 0.6505\n",
      "Epoch 779/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6506 - val_loss: 0.1007 - val_auc: 0.6506\n",
      "Epoch 780/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6507 - val_loss: 0.1007 - val_auc: 0.6507\n",
      "Epoch 781/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6508 - val_loss: 0.1008 - val_auc: 0.6508\n",
      "Epoch 782/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6509 - val_loss: 0.1008 - val_auc: 0.6509\n",
      "Epoch 783/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6510 - val_loss: 0.1007 - val_auc: 0.6510\n",
      "Epoch 784/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6511 - val_loss: 0.1008 - val_auc: 0.6511\n",
      "Epoch 785/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6512 - val_loss: 0.1006 - val_auc: 0.6512\n",
      "Epoch 786/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6513 - val_loss: 0.1006 - val_auc: 0.6513\n",
      "Epoch 787/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6514 - val_loss: 0.1006 - val_auc: 0.6514\n",
      "Epoch 788/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6515 - val_loss: 0.1006 - val_auc: 0.6515\n",
      "Epoch 789/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6516 - val_loss: 0.1008 - val_auc: 0.6516\n",
      "Epoch 790/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6517 - val_loss: 0.1007 - val_auc: 0.6517\n",
      "Epoch 791/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6517 - val_loss: 0.1005 - val_auc: 0.6518\n",
      "Epoch 792/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6518 - val_loss: 0.1008 - val_auc: 0.6519\n",
      "Epoch 793/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6519 - val_loss: 0.1008 - val_auc: 0.6520\n",
      "Epoch 794/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6520 - val_loss: 0.1008 - val_auc: 0.6521\n",
      "Epoch 795/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6521 - val_loss: 0.1006 - val_auc: 0.6522\n",
      "Epoch 796/1000\n",
      " - 0s - loss: 0.0523 - auc: 0.6522 - val_loss: 0.1007 - val_auc: 0.6523\n",
      "Epoch 797/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6523 - val_loss: 0.1007 - val_auc: 0.6524\n",
      "Epoch 798/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6524 - val_loss: 0.1008 - val_auc: 0.6525\n",
      "Epoch 799/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6525 - val_loss: 0.1006 - val_auc: 0.6526\n",
      "Epoch 800/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6526 - val_loss: 0.1006 - val_auc: 0.6527\n",
      "Epoch 801/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6527 - val_loss: 0.1005 - val_auc: 0.6528\n",
      "Epoch 802/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6528 - val_loss: 0.1005 - val_auc: 0.6529\n",
      "Epoch 803/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6529 - val_loss: 0.1008 - val_auc: 0.6530\n",
      "Epoch 804/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6530 - val_loss: 0.1005 - val_auc: 0.6531\n",
      "Epoch 805/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6531 - val_loss: 0.1007 - val_auc: 0.6532\n",
      "Epoch 806/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6532 - val_loss: 0.1006 - val_auc: 0.6533\n",
      "Epoch 807/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6533 - val_loss: 0.1007 - val_auc: 0.6534\n",
      "Epoch 808/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6534 - val_loss: 0.1006 - val_auc: 0.6535\n",
      "Epoch 809/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6535 - val_loss: 0.1006 - val_auc: 0.6535\n",
      "Epoch 810/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6536 - val_loss: 0.1006 - val_auc: 0.6536\n",
      "Epoch 811/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6537 - val_loss: 0.1007 - val_auc: 0.6537\n",
      "Epoch 812/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6538 - val_loss: 0.1006 - val_auc: 0.6538\n",
      "Epoch 813/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6539 - val_loss: 0.1009 - val_auc: 0.6539\n",
      "Epoch 814/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6540 - val_loss: 0.1006 - val_auc: 0.6540\n",
      "Epoch 815/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6541 - val_loss: 0.1006 - val_auc: 0.6541\n",
      "Epoch 816/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6542 - val_loss: 0.1008 - val_auc: 0.6542\n",
      "Epoch 817/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6543 - val_loss: 0.1007 - val_auc: 0.6543\n",
      "Epoch 818/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6544 - val_loss: 0.1004 - val_auc: 0.6544\n",
      "Epoch 819/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6545 - val_loss: 0.1008 - val_auc: 0.6545\n",
      "Epoch 820/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6545 - val_loss: 0.1005 - val_auc: 0.6546\n",
      "Epoch 821/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6546 - val_loss: 0.1009 - val_auc: 0.6547\n",
      "Epoch 822/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6547 - val_loss: 0.1007 - val_auc: 0.6548\n",
      "Epoch 823/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6548 - val_loss: 0.1007 - val_auc: 0.6549\n",
      "Epoch 824/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6549 - val_loss: 0.1008 - val_auc: 0.6550\n",
      "Epoch 825/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6550 - val_loss: 0.1006 - val_auc: 0.6551\n",
      "Epoch 826/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6551 - val_loss: 0.1006 - val_auc: 0.6551\n",
      "Epoch 827/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6552 - val_loss: 0.1007 - val_auc: 0.6552\n",
      "Epoch 828/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6553 - val_loss: 0.1007 - val_auc: 0.6553\n",
      "Epoch 829/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6554 - val_loss: 0.1008 - val_auc: 0.6554\n",
      "Epoch 830/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6555 - val_loss: 0.1007 - val_auc: 0.6555\n",
      "Epoch 831/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6555 - val_loss: 0.1008 - val_auc: 0.6556\n",
      "Epoch 832/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6556 - val_loss: 0.1006 - val_auc: 0.6557\n",
      "Epoch 833/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6557 - val_loss: 0.1005 - val_auc: 0.6558\n",
      "Epoch 834/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6558 - val_loss: 0.1006 - val_auc: 0.6559\n",
      "Epoch 835/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6559 - val_loss: 0.1006 - val_auc: 0.6560\n",
      "Epoch 836/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6560 - val_loss: 0.1006 - val_auc: 0.6561\n",
      "Epoch 837/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6561 - val_loss: 0.1006 - val_auc: 0.6561\n",
      "Epoch 838/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6562 - val_loss: 0.1006 - val_auc: 0.6562\n",
      "Epoch 839/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6563 - val_loss: 0.1006 - val_auc: 0.6563\n",
      "Epoch 840/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6563 - val_loss: 0.1006 - val_auc: 0.6564\n",
      "Epoch 841/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6565 - val_loss: 0.1006 - val_auc: 0.6565\n",
      "Epoch 842/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6565 - val_loss: 0.1005 - val_auc: 0.6566\n",
      "Epoch 843/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6566 - val_loss: 0.1007 - val_auc: 0.6567\n",
      "Epoch 844/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6567 - val_loss: 0.1007 - val_auc: 0.6568\n",
      "Epoch 845/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6568 - val_loss: 0.1007 - val_auc: 0.6569\n",
      "Epoch 846/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6569 - val_loss: 0.1005 - val_auc: 0.6570\n",
      "Epoch 847/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6570 - val_loss: 0.1005 - val_auc: 0.6570\n",
      "Epoch 848/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6571 - val_loss: 0.1009 - val_auc: 0.6571\n",
      "Epoch 849/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6572 - val_loss: 0.1007 - val_auc: 0.6572\n",
      "Epoch 850/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6573 - val_loss: 0.1008 - val_auc: 0.6573\n",
      "Epoch 851/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6573 - val_loss: 0.1006 - val_auc: 0.6574\n",
      "Epoch 852/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6574 - val_loss: 0.1007 - val_auc: 0.6575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6575 - val_loss: 0.1006 - val_auc: 0.6576\n",
      "Epoch 854/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6576 - val_loss: 0.1007 - val_auc: 0.6577\n",
      "Epoch 855/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6577 - val_loss: 0.1008 - val_auc: 0.6577\n",
      "Epoch 856/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6578 - val_loss: 0.1008 - val_auc: 0.6578\n",
      "Epoch 857/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6579 - val_loss: 0.1007 - val_auc: 0.6579\n",
      "Epoch 858/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6580 - val_loss: 0.1006 - val_auc: 0.6580\n",
      "Epoch 859/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6580 - val_loss: 0.1005 - val_auc: 0.6581\n",
      "Epoch 860/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6581 - val_loss: 0.1006 - val_auc: 0.6582\n",
      "Epoch 861/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6582 - val_loss: 0.1009 - val_auc: 0.6583\n",
      "Epoch 862/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6583 - val_loss: 0.1007 - val_auc: 0.6583\n",
      "Epoch 863/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6584 - val_loss: 0.1006 - val_auc: 0.6584\n",
      "Epoch 864/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6585 - val_loss: 0.1007 - val_auc: 0.6585\n",
      "Epoch 865/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6586 - val_loss: 0.1006 - val_auc: 0.6586\n",
      "Epoch 866/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6586 - val_loss: 0.1007 - val_auc: 0.6587\n",
      "Epoch 867/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6587 - val_loss: 0.1006 - val_auc: 0.6588\n",
      "Epoch 868/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6588 - val_loss: 0.1007 - val_auc: 0.6589\n",
      "Epoch 869/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6589 - val_loss: 0.1006 - val_auc: 0.6590\n",
      "Epoch 870/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6590 - val_loss: 0.1006 - val_auc: 0.6590\n",
      "Epoch 871/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6590 - val_loss: 0.1005 - val_auc: 0.6591\n",
      "Epoch 872/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6592 - val_loss: 0.1007 - val_auc: 0.6592\n",
      "Epoch 873/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6592 - val_loss: 0.1005 - val_auc: 0.6593\n",
      "Epoch 874/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6593 - val_loss: 0.1005 - val_auc: 0.6594\n",
      "Epoch 875/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6594 - val_loss: 0.1007 - val_auc: 0.6594\n",
      "Epoch 876/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6595 - val_loss: 0.1005 - val_auc: 0.6595\n",
      "Epoch 877/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6596 - val_loss: 0.1005 - val_auc: 0.6596\n",
      "Epoch 878/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6596 - val_loss: 0.1005 - val_auc: 0.6597\n",
      "Epoch 879/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6597 - val_loss: 0.1007 - val_auc: 0.6598\n",
      "Epoch 880/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6598 - val_loss: 0.1008 - val_auc: 0.6599\n",
      "Epoch 881/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6599 - val_loss: 0.1006 - val_auc: 0.6599\n",
      "Epoch 882/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6600 - val_loss: 0.1007 - val_auc: 0.6600\n",
      "Epoch 883/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6601 - val_loss: 0.1007 - val_auc: 0.6601\n",
      "Epoch 884/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6602 - val_loss: 0.1007 - val_auc: 0.6602\n",
      "Epoch 885/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6602 - val_loss: 0.1007 - val_auc: 0.6603\n",
      "Epoch 886/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6603 - val_loss: 0.1005 - val_auc: 0.6604\n",
      "Epoch 887/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6604 - val_loss: 0.1005 - val_auc: 0.6604\n",
      "Epoch 888/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6605 - val_loss: 0.1006 - val_auc: 0.6605\n",
      "Epoch 889/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6606 - val_loss: 0.1006 - val_auc: 0.6606\n",
      "Epoch 890/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6607 - val_loss: 0.1007 - val_auc: 0.6607\n",
      "Epoch 891/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6607 - val_loss: 0.1007 - val_auc: 0.6608\n",
      "Epoch 892/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6608 - val_loss: 0.1006 - val_auc: 0.6609\n",
      "Epoch 893/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6609 - val_loss: 0.1008 - val_auc: 0.6609\n",
      "Epoch 894/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6610 - val_loss: 0.1006 - val_auc: 0.6610\n",
      "Epoch 895/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6611 - val_loss: 0.1006 - val_auc: 0.6611\n",
      "Epoch 896/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6611 - val_loss: 0.1006 - val_auc: 0.6612\n",
      "Epoch 897/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6612 - val_loss: 0.1007 - val_auc: 0.6613\n",
      "Epoch 898/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6613 - val_loss: 0.1007 - val_auc: 0.6614\n",
      "Epoch 899/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6614 - val_loss: 0.1006 - val_auc: 0.6614\n",
      "Epoch 900/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6615 - val_loss: 0.1006 - val_auc: 0.6615\n",
      "Epoch 901/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6615 - val_loss: 0.1004 - val_auc: 0.6616\n",
      "Epoch 902/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6616 - val_loss: 0.1007 - val_auc: 0.6617\n",
      "Epoch 903/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6617 - val_loss: 0.1006 - val_auc: 0.6618\n",
      "Epoch 904/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6618 - val_loss: 0.1006 - val_auc: 0.6618\n",
      "Epoch 905/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6619 - val_loss: 0.1008 - val_auc: 0.6619\n",
      "Epoch 906/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6619 - val_loss: 0.1006 - val_auc: 0.6620\n",
      "Epoch 907/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6620 - val_loss: 0.1007 - val_auc: 0.6621\n",
      "Epoch 908/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6621 - val_loss: 0.1005 - val_auc: 0.6622\n",
      "Epoch 909/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6622 - val_loss: 0.1008 - val_auc: 0.6622\n",
      "Epoch 910/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6623 - val_loss: 0.1004 - val_auc: 0.6623\n",
      "Epoch 911/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6624 - val_loss: 0.1007 - val_auc: 0.6624\n",
      "Epoch 912/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6624 - val_loss: 0.1007 - val_auc: 0.6625\n",
      "Epoch 913/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6625 - val_loss: 0.1007 - val_auc: 0.6626\n",
      "Epoch 914/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6626 - val_loss: 0.1008 - val_auc: 0.6626\n",
      "Epoch 915/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6627 - val_loss: 0.1006 - val_auc: 0.6627\n",
      "Epoch 916/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6628 - val_loss: 0.1007 - val_auc: 0.6628\n",
      "Epoch 917/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6628 - val_loss: 0.1006 - val_auc: 0.6629\n",
      "Epoch 918/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6629 - val_loss: 0.1007 - val_auc: 0.6630\n",
      "Epoch 919/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6630 - val_loss: 0.1006 - val_auc: 0.6630\n",
      "Epoch 920/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6631 - val_loss: 0.1005 - val_auc: 0.6631\n",
      "Epoch 921/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6631 - val_loss: 0.1007 - val_auc: 0.6632\n",
      "Epoch 922/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6632 - val_loss: 0.1005 - val_auc: 0.6633\n",
      "Epoch 923/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6633 - val_loss: 0.1007 - val_auc: 0.6634\n",
      "Epoch 924/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6634 - val_loss: 0.1008 - val_auc: 0.6634\n",
      "Epoch 925/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6635 - val_loss: 0.1007 - val_auc: 0.6635\n",
      "Epoch 926/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6635 - val_loss: 0.1008 - val_auc: 0.6636\n",
      "Epoch 927/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6636 - val_loss: 0.1006 - val_auc: 0.6637\n",
      "Epoch 928/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6637 - val_loss: 0.1007 - val_auc: 0.6637\n",
      "Epoch 929/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6638 - val_loss: 0.1006 - val_auc: 0.6638\n",
      "Epoch 930/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6639 - val_loss: 0.1006 - val_auc: 0.6639\n",
      "Epoch 931/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6639 - val_loss: 0.1007 - val_auc: 0.6640\n",
      "Epoch 932/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6640 - val_loss: 0.1007 - val_auc: 0.6641\n",
      "Epoch 933/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6641 - val_loss: 0.1006 - val_auc: 0.6641\n",
      "Epoch 934/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6642 - val_loss: 0.1008 - val_auc: 0.6642\n",
      "Epoch 935/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6642 - val_loss: 0.1008 - val_auc: 0.6643\n",
      "Epoch 936/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6643 - val_loss: 0.1007 - val_auc: 0.6644\n",
      "Epoch 937/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6644 - val_loss: 0.1007 - val_auc: 0.6644\n",
      "Epoch 938/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6645 - val_loss: 0.1007 - val_auc: 0.6645\n",
      "Epoch 939/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6646 - val_loss: 0.1007 - val_auc: 0.6646\n",
      "Epoch 940/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6646 - val_loss: 0.1007 - val_auc: 0.6647\n",
      "Epoch 941/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6647 - val_loss: 0.1006 - val_auc: 0.6648\n",
      "Epoch 942/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6648 - val_loss: 0.1008 - val_auc: 0.6648\n",
      "Epoch 943/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6649 - val_loss: 0.1005 - val_auc: 0.6649\n",
      "Epoch 944/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6649 - val_loss: 0.1007 - val_auc: 0.6650\n",
      "Epoch 945/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6650 - val_loss: 0.1007 - val_auc: 0.6651\n",
      "Epoch 946/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6651 - val_loss: 0.1008 - val_auc: 0.6651\n",
      "Epoch 947/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6652 - val_loss: 0.1008 - val_auc: 0.6652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 948/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6652 - val_loss: 0.1007 - val_auc: 0.6653\n",
      "Epoch 949/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6653 - val_loss: 0.1006 - val_auc: 0.6654\n",
      "Epoch 950/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6654 - val_loss: 0.1007 - val_auc: 0.6654\n",
      "Epoch 951/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6655 - val_loss: 0.1006 - val_auc: 0.6655\n",
      "Epoch 952/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6655 - val_loss: 0.1007 - val_auc: 0.6656\n",
      "Epoch 953/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6656 - val_loss: 0.1007 - val_auc: 0.6657\n",
      "Epoch 954/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6657 - val_loss: 0.1006 - val_auc: 0.6657\n",
      "Epoch 955/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6658 - val_loss: 0.1006 - val_auc: 0.6658\n",
      "Epoch 956/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6658 - val_loss: 0.1005 - val_auc: 0.6659\n",
      "Epoch 957/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6659 - val_loss: 0.1007 - val_auc: 0.6659\n",
      "Epoch 958/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6660 - val_loss: 0.1005 - val_auc: 0.6660\n",
      "Epoch 959/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6660 - val_loss: 0.1009 - val_auc: 0.6661\n",
      "Epoch 960/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6661 - val_loss: 0.1007 - val_auc: 0.6662\n",
      "Epoch 961/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6662 - val_loss: 0.1004 - val_auc: 0.6662\n",
      "Epoch 962/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6663 - val_loss: 0.1008 - val_auc: 0.6663\n",
      "Epoch 963/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6663 - val_loss: 0.1007 - val_auc: 0.6664\n",
      "Epoch 964/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6664 - val_loss: 0.1006 - val_auc: 0.6665\n",
      "Epoch 965/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6665 - val_loss: 0.1009 - val_auc: 0.6665\n",
      "Epoch 966/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6666 - val_loss: 0.1005 - val_auc: 0.6666\n",
      "Epoch 967/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6666 - val_loss: 0.1008 - val_auc: 0.6667\n",
      "Epoch 968/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6667 - val_loss: 0.1008 - val_auc: 0.6667\n",
      "Epoch 969/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6668 - val_loss: 0.1006 - val_auc: 0.6668\n",
      "Epoch 970/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6668 - val_loss: 0.1008 - val_auc: 0.6669\n",
      "Epoch 971/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6669 - val_loss: 0.1005 - val_auc: 0.6670\n",
      "Epoch 972/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6670 - val_loss: 0.1008 - val_auc: 0.6670\n",
      "Epoch 973/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6671 - val_loss: 0.1004 - val_auc: 0.6671\n",
      "Epoch 974/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6671 - val_loss: 0.1007 - val_auc: 0.6672\n",
      "Epoch 975/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6672 - val_loss: 0.1007 - val_auc: 0.6672\n",
      "Epoch 976/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6673 - val_loss: 0.1006 - val_auc: 0.6673\n",
      "Epoch 977/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6673 - val_loss: 0.1008 - val_auc: 0.6674\n",
      "Epoch 978/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6674 - val_loss: 0.1007 - val_auc: 0.6674\n",
      "Epoch 979/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6675 - val_loss: 0.1008 - val_auc: 0.6675\n",
      "Epoch 980/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6675 - val_loss: 0.1005 - val_auc: 0.6676\n",
      "Epoch 981/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6676 - val_loss: 0.1008 - val_auc: 0.6677\n",
      "Epoch 982/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6677 - val_loss: 0.1007 - val_auc: 0.6677\n",
      "Epoch 983/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6677 - val_loss: 0.1005 - val_auc: 0.6678\n",
      "Epoch 984/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6678 - val_loss: 0.1004 - val_auc: 0.6679\n",
      "Epoch 985/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6679 - val_loss: 0.1008 - val_auc: 0.6679\n",
      "Epoch 986/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6680 - val_loss: 0.1006 - val_auc: 0.6680\n",
      "Epoch 987/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6680 - val_loss: 0.1008 - val_auc: 0.6681\n",
      "Epoch 988/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6681 - val_loss: 0.1007 - val_auc: 0.6681\n",
      "Epoch 989/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6682 - val_loss: 0.1007 - val_auc: 0.6682\n",
      "Epoch 990/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6682 - val_loss: 0.1006 - val_auc: 0.6683\n",
      "Epoch 991/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6683 - val_loss: 0.1008 - val_auc: 0.6683\n",
      "Epoch 992/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6684 - val_loss: 0.1007 - val_auc: 0.6684\n",
      "Epoch 993/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6684 - val_loss: 0.1007 - val_auc: 0.6685\n",
      "Epoch 994/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6685 - val_loss: 0.1006 - val_auc: 0.6686\n",
      "Epoch 995/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6686 - val_loss: 0.1006 - val_auc: 0.6686\n",
      "Epoch 996/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6687 - val_loss: 0.1005 - val_auc: 0.6687\n",
      "Epoch 997/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6687 - val_loss: 0.1007 - val_auc: 0.6688\n",
      "Epoch 998/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6688 - val_loss: 0.1007 - val_auc: 0.6688\n",
      "Epoch 999/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6689 - val_loss: 0.1007 - val_auc: 0.6689\n",
      "Epoch 1000/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6689 - val_loss: 0.1007 - val_auc: 0.6690\n"
     ]
    }
   ],
   "source": [
    "Tensor_X_input = Input(shape = (N_COLUMNS,), name = 'input')\n",
    "Tensor_X = Dense(units = 1, name = 'Dense', kernel_regularizer=penalties[best_test_index]) (Tensor_X_input)\n",
    "Tensor_X = Activation('sigmoid') (Tensor_X)\n",
    "model_3 = Model(inputs = Tensor_X_input, outputs = Tensor_X)\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "adam = Adam()\n",
    "model_3.compile(loss=\"binary_crossentropy\", optimizer = adam, metrics=[auc_metric])\n",
    "history_3 = model_3.fit(X_train, y_train, batch_size=128, epochs=1000, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_3 = model_3.predict(X_test)[:, 0]\n",
    "fpr_3, tpr_3, thresholds_3 = roc_curve(y_test, y_pred_3)\n",
    "\n",
    "roc_auc_3 = auc(fpr_3, tpr_3)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_3, tpr_3, 'b',label='AUC = %0.3f'% roc_auc_3)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.save('model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multibranches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05260037, -0.02808834, -0.03973859, -0.05068197, -0.03140681,\n",
       "        -0.01404001],\n",
       "       [-0.05260037, -0.02808834, -0.03973859, -0.05068197, -0.03140681,\n",
       "        -0.01404001],\n",
       "       [-0.05260037, -0.02808834, -0.03973859, -0.05068197, -0.03140681,\n",
       "        -0.01404001],\n",
       "       ...,\n",
       "       [-0.05260037, -0.02808834, -0.03973859, -0.05068197, -0.03140681,\n",
       "        -0.01404001],\n",
       "       [-0.05260037, -0.02808834, -0.03973859, -0.05068197, -0.03140681,\n",
       "        -0.01404001],\n",
       "       [-0.05260037, -0.02808834, -0.03973859, -0.05068197, -0.03140681,\n",
       "        -0.01404001]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TYPE_1 = ['MARQUE_BMW', 'MARQUE_CHV', 'MARQUE_CIT', 'MARQUE_MAZ', 'MARQUE_SEA', 'MARQUE_VAU']\n",
    "TYPE_2 = ['MODE_LOGT_2.0', 'MODE_LOGT_nan']\n",
    "TYPE_3 = ['PRIX_VEH', 'MT_APPORT', 'AGE_CLI']\n",
    "TYPE_4 = ['DUREE_CONTRAT']\n",
    "\n",
    "X_trains = [None, None, None, None]\n",
    "X_tests = [None, None, None, None]\n",
    "col_groups = [TYPE_1, TYPE_2, TYPE_3, TYPE_4]\n",
    "\n",
    "for i, col_group in enumerate(col_groups):\n",
    "    X_trains[i] = scaler.fit_transform(X_train_raw.loc[:, col_group])\n",
    "    X_tests[i] = scaler.transform(X_test_raw.loc[:, col_group])\n",
    "    \n",
    "X_trains[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularizer 0 , dropout ratio 0.25 :\n",
      "auc:  0.573170376986992 . val_auc:  0.5754068677061297\n",
      "Regularizer 0 , dropout ratio 0.33 :\n",
      "auc:  0.5667396201292086 . val_auc:  0.5686850558360809\n",
      "Regularizer 0 , dropout ratio 0.4 :\n",
      "auc:  0.5609954633011434 . val_auc:  0.5631080204630133\n",
      "Regularizer 1 , dropout ratio 0.25 :\n",
      "auc:  0.5714333069151215 . val_auc:  0.5736043194831886\n",
      "Regularizer 1 , dropout ratio 0.33 :\n",
      "auc:  0.5651918809441517 . val_auc:  0.5669335899094643\n",
      "Regularizer 1 , dropout ratio 0.4 :\n",
      "auc:  0.5612635199411011 . val_auc:  0.5633209308967214\n",
      "Regularizer 2 , dropout ratio 0.25 :\n",
      "auc:  0.562918818695964 . val_auc:  0.5652521431739694\n",
      "Regularizer 2 , dropout ratio 0.33 :\n",
      "auc:  0.5562334539826265 . val_auc:  0.5577799741270507\n",
      "Regularizer 2 , dropout ratio 0.4 :\n",
      "auc:  0.5496052202845947 . val_auc:  0.5512252139927718\n",
      "Regularizer 3 , dropout ratio 0.25 :\n",
      "auc:  0.5512576478547901 . val_auc:  0.5529583659665338\n",
      "Regularizer 3 , dropout ratio 0.33 :\n",
      "auc:  0.5503228306770325 . val_auc:  0.551473727191023\n",
      "Regularizer 3 , dropout ratio 0.4 :\n",
      "auc:  0.5477844859232718 . val_auc:  0.5489533548871872\n"
     ]
    }
   ],
   "source": [
    "penalties = [regularizers.l1(1e-5), regularizers.l1(1e-4), regularizers.l1(1e-3), regularizers.l1(1e-2)]\n",
    "dropout_ratio = [0.25, 0.33, 0.4]\n",
    "\n",
    "test_results = []\n",
    "best_test_result = 0\n",
    "best_test_index = 0\n",
    "best_dropout_ratio = 0.25\n",
    "\n",
    "for i, p in enumerate(penalties):\n",
    "    for d in dropout_ratio:\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "        \n",
    "        print('Regularizer', i, ', dropout ratio', d, ':')\n",
    "\n",
    "        Tensor_X_1_I = Input(shape = (len(TYPE_1),))\n",
    "        Tensor_X_1 = Dense(units = 8, kernel_initializer = glorot_uniform(seed=RANDOM_SEED)) (Tensor_X_1_I)\n",
    "\n",
    "        Tensor_X_2_I = Input(shape = (len(TYPE_2),))\n",
    "        Tensor_X_2 = Dense(units = 8, kernel_initializer = glorot_uniform(seed=RANDOM_SEED)) (Tensor_X_2_I)\n",
    "\n",
    "        Tensor_X_3_I = Input(shape = (len(TYPE_3),))\n",
    "        Tensor_X_3 = Dense(units = 8, kernel_initializer = glorot_uniform(seed=RANDOM_SEED)) (Tensor_X_3_I)\n",
    "\n",
    "        Tensor_X_4_I = Input(shape = (len(TYPE_4),))\n",
    "        Tensor_X_4 = Dense(units = 8, kernel_initializer = glorot_uniform(seed=RANDOM_SEED)) (Tensor_X_4_I)\n",
    "\n",
    "        Tensor_X = Concatenate(name = 'concat') ([Tensor_X_1, Tensor_X_2, Tensor_X_3, Tensor_X_4])\n",
    "        Tensor_X = Dense(units = 32, kernel_initializer = glorot_uniform(seed=RANDOM_SEED), kernel_regularizer=p) (Tensor_X)\n",
    "        Tensor_X = Activation('relu') (Tensor_X)\n",
    "        Tensor_X = Dropout(d, seed = RANDOM_SEED) (Tensor_X)\n",
    "        Tensor_X = Dense(units = 1, kernel_initializer = glorot_uniform(seed=RANDOM_SEED), kernel_regularizer=p) (Tensor_X)\n",
    "        Tensor_X = Activation('sigmoid') (Tensor_X)\n",
    "\n",
    "        model_4 = Model(inputs = [Tensor_X_1_I, Tensor_X_2_I, Tensor_X_3_I, Tensor_X_4_I], outputs = Tensor_X)\n",
    "        \n",
    "        adam = Adam()\n",
    "        model_4.compile(loss=\"binary_crossentropy\", optimizer = adam, metrics=[auc_metric])\n",
    "        history_4 = model_4.fit(X_trains, y_train, batch_size=128, epochs=20, verbose=0, validation_split=0.2)\n",
    "        print('auc: ', history_4.history['auc'][-1], '. val_auc: ', history_4.history['val_auc'][-1])\n",
    "        if history_4.history['val_auc'][-1] > best_test_result:\n",
    "            best_test_result = history_4.history['val_auc'][-1]\n",
    "            best_test_index = i\n",
    "            best_dropout_ratio = d\n",
    "\n",
    "# 4 4 8 4 32 0.4 256 -> 0.822\n",
    "# 8 8 8 8 32 0.33 256 -> 0.819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4059 samples, validate on 1015 samples\n",
      "Epoch 1/1000\n",
      " - 9s - loss: 0.5392 - auc: 0.4137 - val_loss: 0.4795 - val_auc: 0.4701\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 0.3894 - auc: 0.4649 - val_loss: 0.3535 - val_auc: 0.4876\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 0.2824 - auc: 0.4763 - val_loss: 0.2662 - val_auc: 0.4812\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 0.2101 - auc: 0.4807 - val_loss: 0.2073 - val_auc: 0.4812\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 0.1592 - auc: 0.4762 - val_loss: 0.1711 - val_auc: 0.4842\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 0.1234 - auc: 0.4819 - val_loss: 0.1479 - val_auc: 0.4893\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.1067 - auc: 0.4881 - val_loss: 0.1348 - val_auc: 0.4895\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 0.0925 - auc: 0.4886 - val_loss: 0.1275 - val_auc: 0.4917\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 0.0810 - auc: 0.4896 - val_loss: 0.1233 - val_auc: 0.4949\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 0.0787 - auc: 0.4929 - val_loss: 0.1209 - val_auc: 0.4960\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 0.0758 - auc: 0.4968 - val_loss: 0.1197 - val_auc: 0.4983\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 0.0703 - auc: 0.4992 - val_loss: 0.1193 - val_auc: 0.5011\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 0.0658 - auc: 0.5029 - val_loss: 0.1192 - val_auc: 0.5060\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 0.0690 - auc: 0.5078 - val_loss: 0.1199 - val_auc: 0.5089\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 0.0691 - auc: 0.5099 - val_loss: 0.1193 - val_auc: 0.5108\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 0.0656 - auc: 0.5112 - val_loss: 0.1190 - val_auc: 0.5135\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 0.0630 - auc: 0.5149 - val_loss: 0.1188 - val_auc: 0.5176\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 0.0647 - auc: 0.5185 - val_loss: 0.1194 - val_auc: 0.5212\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.0649 - auc: 0.5224 - val_loss: 0.1193 - val_auc: 0.5244\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.0612 - auc: 0.5263 - val_loss: 0.1194 - val_auc: 0.5291\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 0.0585 - auc: 0.5303 - val_loss: 0.1197 - val_auc: 0.5334\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 0.0638 - auc: 0.5337 - val_loss: 0.1198 - val_auc: 0.5347\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 0.0645 - auc: 0.5372 - val_loss: 0.1198 - val_auc: 0.5387\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.0627 - auc: 0.5388 - val_loss: 0.1194 - val_auc: 0.5408\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 0.0627 - auc: 0.5414 - val_loss: 0.1196 - val_auc: 0.5435\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 0.0609 - auc: 0.5440 - val_loss: 0.1192 - val_auc: 0.5457\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 0.0613 - auc: 0.5471 - val_loss: 0.1191 - val_auc: 0.5486\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 0.0604 - auc: 0.5488 - val_loss: 0.1193 - val_auc: 0.5508\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 0.0616 - auc: 0.5514 - val_loss: 0.1191 - val_auc: 0.5524\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 0.0594 - auc: 0.5537 - val_loss: 0.1191 - val_auc: 0.5559\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 0.0576 - auc: 0.5569 - val_loss: 0.1191 - val_auc: 0.5589\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 0.0621 - auc: 0.5592 - val_loss: 0.1187 - val_auc: 0.5602\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 0.0564 - auc: 0.5613 - val_loss: 0.1184 - val_auc: 0.5634\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 0.0595 - auc: 0.5638 - val_loss: 0.1189 - val_auc: 0.5655\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 0.0580 - auc: 0.5663 - val_loss: 0.1190 - val_auc: 0.5676\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 0.0613 - auc: 0.5685 - val_loss: 0.1189 - val_auc: 0.5693\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 0.0591 - auc: 0.5700 - val_loss: 0.1188 - val_auc: 0.5715\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 0.0583 - auc: 0.5723 - val_loss: 0.1191 - val_auc: 0.5735\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 0.0575 - auc: 0.5744 - val_loss: 0.1192 - val_auc: 0.5757\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 0.0559 - auc: 0.5765 - val_loss: 0.1192 - val_auc: 0.5779\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 0.0575 - auc: 0.5783 - val_loss: 0.1191 - val_auc: 0.5798\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 0.0555 - auc: 0.5803 - val_loss: 0.1192 - val_auc: 0.5818\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 0.0594 - auc: 0.5825 - val_loss: 0.1188 - val_auc: 0.5835\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 0.0534 - auc: 0.5847 - val_loss: 0.1191 - val_auc: 0.5861\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 0.0557 - auc: 0.5871 - val_loss: 0.1188 - val_auc: 0.5882\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 0.0580 - auc: 0.5888 - val_loss: 0.1188 - val_auc: 0.5898\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 0.0567 - auc: 0.5907 - val_loss: 0.1192 - val_auc: 0.5911\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 0.0562 - auc: 0.5919 - val_loss: 0.1193 - val_auc: 0.5925\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 0.0572 - auc: 0.5929 - val_loss: 0.1189 - val_auc: 0.5936\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 0.0543 - auc: 0.5946 - val_loss: 0.1188 - val_auc: 0.5957\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 0.0551 - auc: 0.5963 - val_loss: 0.1186 - val_auc: 0.5977\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 0.0563 - auc: 0.5986 - val_loss: 0.1187 - val_auc: 0.5992\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 0.0577 - auc: 0.6002 - val_loss: 0.1193 - val_auc: 0.6008\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 0.0574 - auc: 0.6015 - val_loss: 0.1195 - val_auc: 0.6021\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 0.0573 - auc: 0.6024 - val_loss: 0.1189 - val_auc: 0.6031\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 0.0538 - auc: 0.6040 - val_loss: 0.1196 - val_auc: 0.6048\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 0.0562 - auc: 0.6054 - val_loss: 0.1197 - val_auc: 0.6062\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.0590 - auc: 0.6065 - val_loss: 0.1194 - val_auc: 0.6071\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 0.0558 - auc: 0.6075 - val_loss: 0.1194 - val_auc: 0.6080\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 0.0603 - auc: 0.6083 - val_loss: 0.1189 - val_auc: 0.6088\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 0.0570 - auc: 0.6092 - val_loss: 0.1191 - val_auc: 0.6099\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.0547 - auc: 0.6105 - val_loss: 0.1191 - val_auc: 0.6113\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.0556 - auc: 0.6118 - val_loss: 0.1193 - val_auc: 0.6121\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.0544 - auc: 0.6127 - val_loss: 0.1195 - val_auc: 0.6135\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.0572 - auc: 0.6141 - val_loss: 0.1196 - val_auc: 0.6144\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.0559 - auc: 0.6147 - val_loss: 0.1192 - val_auc: 0.6152\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.0556 - auc: 0.6156 - val_loss: 0.1193 - val_auc: 0.6163\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.0544 - auc: 0.6168 - val_loss: 0.1197 - val_auc: 0.6174\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.0558 - auc: 0.6176 - val_loss: 0.1195 - val_auc: 0.6182\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.0556 - auc: 0.6186 - val_loss: 0.1192 - val_auc: 0.6192\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.0530 - auc: 0.6197 - val_loss: 0.1197 - val_auc: 0.6202\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.0566 - auc: 0.6204 - val_loss: 0.1194 - val_auc: 0.6208\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.0556 - auc: 0.6210 - val_loss: 0.1198 - val_auc: 0.6215\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.0567 - auc: 0.6217 - val_loss: 0.1188 - val_auc: 0.6220\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.0558 - auc: 0.6222 - val_loss: 0.1196 - val_auc: 0.6228\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.0580 - auc: 0.6230 - val_loss: 0.1194 - val_auc: 0.6232\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.0543 - auc: 0.6237 - val_loss: 0.1195 - val_auc: 0.6241\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.0548 - auc: 0.6246 - val_loss: 0.1191 - val_auc: 0.6248\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.0551 - auc: 0.6250 - val_loss: 0.1198 - val_auc: 0.6255\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.0553 - auc: 0.6259 - val_loss: 0.1197 - val_auc: 0.6263\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.0542 - auc: 0.6265 - val_loss: 0.1202 - val_auc: 0.6274\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.0561 - auc: 0.6274 - val_loss: 0.1199 - val_auc: 0.6278\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.0520 - auc: 0.6283 - val_loss: 0.1208 - val_auc: 0.6291\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.0532 - auc: 0.6293 - val_loss: 0.1207 - val_auc: 0.6299\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.0562 - auc: 0.6301 - val_loss: 0.1211 - val_auc: 0.6303\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.6303 - val_loss: 0.1203 - val_auc: 0.6311\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.0533 - auc: 0.6315 - val_loss: 0.1207 - val_auc: 0.6320\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.0554 - auc: 0.6323 - val_loss: 0.1211 - val_auc: 0.6323\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 0.0532 - auc: 0.6327 - val_loss: 0.1204 - val_auc: 0.6331\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6335 - val_loss: 0.1202 - val_auc: 0.6340\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.0537 - auc: 0.6343 - val_loss: 0.1210 - val_auc: 0.6347\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.0541 - auc: 0.6350 - val_loss: 0.1207 - val_auc: 0.6354\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.0556 - auc: 0.6357 - val_loss: 0.1203 - val_auc: 0.6358\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.0544 - auc: 0.6363 - val_loss: 0.1202 - val_auc: 0.6364\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.0548 - auc: 0.6365 - val_loss: 0.1204 - val_auc: 0.6367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000\n",
      " - 0s - loss: 0.0550 - auc: 0.6368 - val_loss: 0.1202 - val_auc: 0.6370\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.0535 - auc: 0.6373 - val_loss: 0.1205 - val_auc: 0.6377\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.0556 - auc: 0.6379 - val_loss: 0.1212 - val_auc: 0.6380\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.0533 - auc: 0.6382 - val_loss: 0.1214 - val_auc: 0.6385\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.0542 - auc: 0.6388 - val_loss: 0.1216 - val_auc: 0.6392\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.6396 - val_loss: 0.1218 - val_auc: 0.6398\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 0.0558 - auc: 0.6400 - val_loss: 0.1214 - val_auc: 0.6400\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.0534 - auc: 0.6403 - val_loss: 0.1207 - val_auc: 0.6404\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.0516 - auc: 0.6408 - val_loss: 0.1215 - val_auc: 0.6412\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.0536 - auc: 0.6414 - val_loss: 0.1217 - val_auc: 0.6417\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.0556 - auc: 0.6417 - val_loss: 0.1212 - val_auc: 0.6418\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 0.0532 - auc: 0.6421 - val_loss: 0.1217 - val_auc: 0.6425\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 0.0565 - auc: 0.6428 - val_loss: 0.1216 - val_auc: 0.6427\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.6429 - val_loss: 0.1220 - val_auc: 0.6432\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 0.0535 - auc: 0.6434 - val_loss: 0.1218 - val_auc: 0.6436\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 0.0506 - auc: 0.6439 - val_loss: 0.1222 - val_auc: 0.6444\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 0.0554 - auc: 0.6444 - val_loss: 0.1221 - val_auc: 0.6444\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 0.0512 - auc: 0.6448 - val_loss: 0.1221 - val_auc: 0.6451\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 0.0554 - auc: 0.6451 - val_loss: 0.1227 - val_auc: 0.6452\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 0.0537 - auc: 0.6453 - val_loss: 0.1228 - val_auc: 0.6456\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.6457 - val_loss: 0.1223 - val_auc: 0.6458\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 0.0556 - auc: 0.6459 - val_loss: 0.1220 - val_auc: 0.6460\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 0.0546 - auc: 0.6462 - val_loss: 0.1223 - val_auc: 0.6462\n",
      "Epoch 119/1000\n",
      " - 0s - loss: 0.0521 - auc: 0.6464 - val_loss: 0.1226 - val_auc: 0.6467\n",
      "Epoch 120/1000\n",
      " - 0s - loss: 0.0521 - auc: 0.6469 - val_loss: 0.1225 - val_auc: 0.6472\n",
      "Epoch 121/1000\n",
      " - 0s - loss: 0.0537 - auc: 0.6474 - val_loss: 0.1224 - val_auc: 0.6476\n",
      "Epoch 122/1000\n",
      " - 0s - loss: 0.0546 - auc: 0.6477 - val_loss: 0.1222 - val_auc: 0.6479\n",
      "Epoch 123/1000\n",
      " - 0s - loss: 0.0534 - auc: 0.6479 - val_loss: 0.1222 - val_auc: 0.6481\n",
      "Epoch 124/1000\n",
      " - 0s - loss: 0.0506 - auc: 0.6482 - val_loss: 0.1228 - val_auc: 0.6486\n",
      "Epoch 125/1000\n",
      " - 0s - loss: 0.0537 - auc: 0.6487 - val_loss: 0.1225 - val_auc: 0.6489\n",
      "Epoch 126/1000\n",
      " - 0s - loss: 0.0528 - auc: 0.6490 - val_loss: 0.1227 - val_auc: 0.6491\n",
      "Epoch 127/1000\n",
      " - 0s - loss: 0.0569 - auc: 0.6490 - val_loss: 0.1232 - val_auc: 0.6491\n",
      "Epoch 128/1000\n",
      " - 0s - loss: 0.0535 - auc: 0.6492 - val_loss: 0.1231 - val_auc: 0.6493\n",
      "Epoch 129/1000\n",
      " - 0s - loss: 0.0542 - auc: 0.6493 - val_loss: 0.1234 - val_auc: 0.6495\n",
      "Epoch 130/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.6496 - val_loss: 0.1229 - val_auc: 0.6498\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.0537 - auc: 0.6499 - val_loss: 0.1233 - val_auc: 0.6501\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.0522 - auc: 0.6503 - val_loss: 0.1232 - val_auc: 0.6505\n",
      "Epoch 133/1000\n",
      " - 0s - loss: 0.0516 - auc: 0.6507 - val_loss: 0.1240 - val_auc: 0.6509\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.0508 - auc: 0.6510 - val_loss: 0.1244 - val_auc: 0.6513\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.0532 - auc: 0.6514 - val_loss: 0.1238 - val_auc: 0.6515\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.0541 - auc: 0.6516 - val_loss: 0.1235 - val_auc: 0.6516\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.6517 - val_loss: 0.1233 - val_auc: 0.6519\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.6520 - val_loss: 0.1231 - val_auc: 0.6521\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.6521 - val_loss: 0.1233 - val_auc: 0.6522\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.0515 - auc: 0.6524 - val_loss: 0.1240 - val_auc: 0.6526\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.0548 - auc: 0.6525 - val_loss: 0.1233 - val_auc: 0.6526\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.0534 - auc: 0.6527 - val_loss: 0.1234 - val_auc: 0.6527\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.0519 - auc: 0.6529 - val_loss: 0.1231 - val_auc: 0.6531\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.6532 - val_loss: 0.1242 - val_auc: 0.6533\n",
      "Epoch 145/1000\n",
      " - 0s - loss: 0.0515 - auc: 0.6534 - val_loss: 0.1234 - val_auc: 0.6536\n",
      "Epoch 146/1000\n",
      " - 0s - loss: 0.0519 - auc: 0.6538 - val_loss: 0.1239 - val_auc: 0.6539\n",
      "Epoch 147/1000\n",
      " - 0s - loss: 0.0535 - auc: 0.6539 - val_loss: 0.1234 - val_auc: 0.6541\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.0529 - auc: 0.6541 - val_loss: 0.1236 - val_auc: 0.6542\n",
      "Epoch 149/1000\n",
      " - 0s - loss: 0.0543 - auc: 0.6542 - val_loss: 0.1232 - val_auc: 0.6543\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.6545 - val_loss: 0.1239 - val_auc: 0.6546\n",
      "Epoch 151/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.6548 - val_loss: 0.1239 - val_auc: 0.6551\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.0529 - auc: 0.6551 - val_loss: 0.1234 - val_auc: 0.6552\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.6552 - val_loss: 0.1237 - val_auc: 0.6555\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.0530 - auc: 0.6557 - val_loss: 0.1232 - val_auc: 0.6557\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.0536 - auc: 0.6558 - val_loss: 0.1236 - val_auc: 0.6557\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.0546 - auc: 0.6557 - val_loss: 0.1234 - val_auc: 0.6558\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.0521 - auc: 0.6559 - val_loss: 0.1236 - val_auc: 0.6560\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.0522 - auc: 0.6562 - val_loss: 0.1245 - val_auc: 0.6564\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.0521 - auc: 0.6565 - val_loss: 0.1237 - val_auc: 0.6566\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.0539 - auc: 0.6567 - val_loss: 0.1238 - val_auc: 0.6569\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.0521 - auc: 0.6569 - val_loss: 0.1235 - val_auc: 0.6570\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.0516 - auc: 0.6573 - val_loss: 0.1243 - val_auc: 0.6573\n",
      "Epoch 163/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.6573 - val_loss: 0.1243 - val_auc: 0.6576\n",
      "Epoch 164/1000\n",
      " - 0s - loss: 0.0537 - auc: 0.6576 - val_loss: 0.1245 - val_auc: 0.6576\n",
      "Epoch 165/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6577 - val_loss: 0.1242 - val_auc: 0.6579\n",
      "Epoch 166/1000\n",
      " - 0s - loss: 0.0535 - auc: 0.6580 - val_loss: 0.1245 - val_auc: 0.6582\n",
      "Epoch 167/1000\n",
      " - 0s - loss: 0.0539 - auc: 0.6582 - val_loss: 0.1245 - val_auc: 0.6583\n",
      "Epoch 168/1000\n",
      " - 0s - loss: 0.0532 - auc: 0.6585 - val_loss: 0.1249 - val_auc: 0.6586\n",
      "Epoch 169/1000\n",
      " - 0s - loss: 0.0533 - auc: 0.6585 - val_loss: 0.1235 - val_auc: 0.6586\n",
      "Epoch 170/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6588 - val_loss: 0.1232 - val_auc: 0.6591\n",
      "Epoch 171/1000\n",
      " - 0s - loss: 0.0532 - auc: 0.6590 - val_loss: 0.1234 - val_auc: 0.6591\n",
      "Epoch 172/1000\n",
      " - 0s - loss: 0.0519 - auc: 0.6594 - val_loss: 0.1231 - val_auc: 0.6595\n",
      "Epoch 173/1000\n",
      " - 0s - loss: 0.0511 - auc: 0.6596 - val_loss: 0.1235 - val_auc: 0.6598\n",
      "Epoch 174/1000\n",
      " - 0s - loss: 0.0520 - auc: 0.6597 - val_loss: 0.1238 - val_auc: 0.6599\n",
      "Epoch 175/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.6601 - val_loss: 0.1239 - val_auc: 0.6602\n",
      "Epoch 176/1000\n",
      " - 0s - loss: 0.0519 - auc: 0.6603 - val_loss: 0.1239 - val_auc: 0.6604\n",
      "Epoch 177/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.6604 - val_loss: 0.1239 - val_auc: 0.6606\n",
      "Epoch 178/1000\n",
      " - 0s - loss: 0.0530 - auc: 0.6607 - val_loss: 0.1240 - val_auc: 0.6607\n",
      "Epoch 179/1000\n",
      " - 0s - loss: 0.0515 - auc: 0.6607 - val_loss: 0.1236 - val_auc: 0.6609\n",
      "Epoch 180/1000\n",
      " - 0s - loss: 0.0511 - auc: 0.6610 - val_loss: 0.1243 - val_auc: 0.6610\n",
      "Epoch 181/1000\n",
      " - 0s - loss: 0.0502 - auc: 0.6612 - val_loss: 0.1240 - val_auc: 0.6613\n",
      "Epoch 182/1000\n",
      " - 0s - loss: 0.0528 - auc: 0.6614 - val_loss: 0.1240 - val_auc: 0.6615\n",
      "Epoch 183/1000\n",
      " - 0s - loss: 0.0519 - auc: 0.6616 - val_loss: 0.1242 - val_auc: 0.6617\n",
      "Epoch 184/1000\n",
      " - 0s - loss: 0.0517 - auc: 0.6619 - val_loss: 0.1243 - val_auc: 0.6620\n",
      "Epoch 185/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6621 - val_loss: 0.1245 - val_auc: 0.6622\n",
      "Epoch 186/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6622 - val_loss: 0.1250 - val_auc: 0.6624\n",
      "Epoch 187/1000\n",
      " - 0s - loss: 0.0514 - auc: 0.6624 - val_loss: 0.1246 - val_auc: 0.6625\n",
      "Epoch 188/1000\n",
      " - 0s - loss: 0.0515 - auc: 0.6627 - val_loss: 0.1245 - val_auc: 0.6628\n",
      "Epoch 189/1000\n",
      " - 0s - loss: 0.0517 - auc: 0.6629 - val_loss: 0.1240 - val_auc: 0.6630\n",
      "Epoch 190/1000\n",
      " - 0s - loss: 0.0512 - auc: 0.6632 - val_loss: 0.1243 - val_auc: 0.6633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/1000\n",
      " - 0s - loss: 0.0522 - auc: 0.6633 - val_loss: 0.1248 - val_auc: 0.6635\n",
      "Epoch 192/1000\n",
      " - 0s - loss: 0.0519 - auc: 0.6636 - val_loss: 0.1247 - val_auc: 0.6637\n",
      "Epoch 193/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6637 - val_loss: 0.1244 - val_auc: 0.6639\n",
      "Epoch 194/1000\n",
      " - 0s - loss: 0.0508 - auc: 0.6640 - val_loss: 0.1250 - val_auc: 0.6642\n",
      "Epoch 195/1000\n",
      " - 0s - loss: 0.0538 - auc: 0.6641 - val_loss: 0.1250 - val_auc: 0.6642\n",
      "Epoch 196/1000\n",
      " - 0s - loss: 0.0511 - auc: 0.6642 - val_loss: 0.1244 - val_auc: 0.6643\n",
      "Epoch 197/1000\n",
      " - 0s - loss: 0.0518 - auc: 0.6644 - val_loss: 0.1247 - val_auc: 0.6645\n",
      "Epoch 198/1000\n",
      " - 0s - loss: 0.0509 - auc: 0.6645 - val_loss: 0.1245 - val_auc: 0.6647\n",
      "Epoch 199/1000\n",
      " - 0s - loss: 0.0519 - auc: 0.6648 - val_loss: 0.1244 - val_auc: 0.6650\n",
      "Epoch 200/1000\n",
      " - 0s - loss: 0.0538 - auc: 0.6650 - val_loss: 0.1245 - val_auc: 0.6650\n",
      "Epoch 201/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6651 - val_loss: 0.1240 - val_auc: 0.6653\n",
      "Epoch 202/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.6653 - val_loss: 0.1246 - val_auc: 0.6655\n",
      "Epoch 203/1000\n",
      " - 0s - loss: 0.0514 - auc: 0.6655 - val_loss: 0.1239 - val_auc: 0.6657\n",
      "Epoch 204/1000\n",
      " - 0s - loss: 0.0517 - auc: 0.6657 - val_loss: 0.1245 - val_auc: 0.6658\n",
      "Epoch 205/1000\n",
      " - 0s - loss: 0.0526 - auc: 0.6658 - val_loss: 0.1240 - val_auc: 0.6659\n",
      "Epoch 206/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6661 - val_loss: 0.1248 - val_auc: 0.6663\n",
      "Epoch 207/1000\n",
      " - 0s - loss: 0.0536 - auc: 0.6663 - val_loss: 0.1239 - val_auc: 0.6663\n",
      "Epoch 208/1000\n",
      " - 0s - loss: 0.0517 - auc: 0.6663 - val_loss: 0.1240 - val_auc: 0.6663\n",
      "Epoch 209/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6664 - val_loss: 0.1246 - val_auc: 0.6665\n",
      "Epoch 210/1000\n",
      " - 0s - loss: 0.0530 - auc: 0.6664 - val_loss: 0.1241 - val_auc: 0.6665\n",
      "Epoch 211/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.6665 - val_loss: 0.1259 - val_auc: 0.6666\n",
      "Epoch 212/1000\n",
      " - 0s - loss: 0.0517 - auc: 0.6667 - val_loss: 0.1257 - val_auc: 0.6667\n",
      "Epoch 213/1000\n",
      " - 0s - loss: 0.0515 - auc: 0.6667 - val_loss: 0.1249 - val_auc: 0.6669\n",
      "Epoch 214/1000\n",
      " - 0s - loss: 0.0539 - auc: 0.6668 - val_loss: 0.1239 - val_auc: 0.6669\n",
      "Epoch 215/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6669 - val_loss: 0.1237 - val_auc: 0.6671\n",
      "Epoch 216/1000\n",
      " - 0s - loss: 0.0507 - auc: 0.6672 - val_loss: 0.1243 - val_auc: 0.6673\n",
      "Epoch 217/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.6674 - val_loss: 0.1252 - val_auc: 0.6677\n",
      "Epoch 218/1000\n",
      " - 0s - loss: 0.0533 - auc: 0.6677 - val_loss: 0.1248 - val_auc: 0.6677\n",
      "Epoch 219/1000\n",
      " - 0s - loss: 0.0511 - auc: 0.6677 - val_loss: 0.1247 - val_auc: 0.6678\n",
      "Epoch 220/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6679 - val_loss: 0.1247 - val_auc: 0.6680\n",
      "Epoch 221/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6680 - val_loss: 0.1247 - val_auc: 0.6683\n",
      "Epoch 222/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6683 - val_loss: 0.1248 - val_auc: 0.6685\n",
      "Epoch 223/1000\n",
      " - 0s - loss: 0.0536 - auc: 0.6685 - val_loss: 0.1243 - val_auc: 0.6686\n",
      "Epoch 224/1000\n",
      " - 0s - loss: 0.0514 - auc: 0.6686 - val_loss: 0.1247 - val_auc: 0.6687\n",
      "Epoch 225/1000\n",
      " - 0s - loss: 0.0519 - auc: 0.6688 - val_loss: 0.1238 - val_auc: 0.6688\n",
      "Epoch 226/1000\n",
      " - 0s - loss: 0.0511 - auc: 0.6689 - val_loss: 0.1247 - val_auc: 0.6690\n",
      "Epoch 227/1000\n",
      " - 0s - loss: 0.0520 - auc: 0.6690 - val_loss: 0.1243 - val_auc: 0.6691\n",
      "Epoch 228/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.6693 - val_loss: 0.1248 - val_auc: 0.6695\n",
      "Epoch 229/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6696 - val_loss: 0.1250 - val_auc: 0.6697\n",
      "Epoch 230/1000\n",
      " - 0s - loss: 0.0517 - auc: 0.6698 - val_loss: 0.1253 - val_auc: 0.6698\n",
      "Epoch 231/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6699 - val_loss: 0.1248 - val_auc: 0.6700\n",
      "Epoch 232/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6700 - val_loss: 0.1258 - val_auc: 0.6701\n",
      "Epoch 233/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.6702 - val_loss: 0.1254 - val_auc: 0.6704\n",
      "Epoch 234/1000\n",
      " - 0s - loss: 0.0508 - auc: 0.6704 - val_loss: 0.1247 - val_auc: 0.6705\n",
      "Epoch 235/1000\n",
      " - 0s - loss: 0.0505 - auc: 0.6706 - val_loss: 0.1252 - val_auc: 0.6706\n",
      "Epoch 236/1000\n",
      " - 0s - loss: 0.0523 - auc: 0.6707 - val_loss: 0.1250 - val_auc: 0.6708\n",
      "Epoch 237/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.6709 - val_loss: 0.1253 - val_auc: 0.6709\n",
      "Epoch 238/1000\n",
      " - 0s - loss: 0.0509 - auc: 0.6710 - val_loss: 0.1261 - val_auc: 0.6712\n",
      "Epoch 239/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.6713 - val_loss: 0.1264 - val_auc: 0.6714\n",
      "Epoch 240/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6715 - val_loss: 0.1258 - val_auc: 0.6716\n",
      "Epoch 241/1000\n",
      " - 0s - loss: 0.0519 - auc: 0.6717 - val_loss: 0.1266 - val_auc: 0.6718\n",
      "Epoch 242/1000\n",
      " - 0s - loss: 0.0514 - auc: 0.6719 - val_loss: 0.1248 - val_auc: 0.6719\n",
      "Epoch 243/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.6719 - val_loss: 0.1255 - val_auc: 0.6721\n",
      "Epoch 244/1000\n",
      " - 0s - loss: 0.0518 - auc: 0.6721 - val_loss: 0.1256 - val_auc: 0.6722\n",
      "Epoch 245/1000\n",
      " - 0s - loss: 0.0516 - auc: 0.6722 - val_loss: 0.1261 - val_auc: 0.6723\n",
      "Epoch 246/1000\n",
      " - 0s - loss: 0.0521 - auc: 0.6723 - val_loss: 0.1254 - val_auc: 0.6724\n",
      "Epoch 247/1000\n",
      " - 0s - loss: 0.0518 - auc: 0.6725 - val_loss: 0.1258 - val_auc: 0.6726\n",
      "Epoch 248/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6726 - val_loss: 0.1254 - val_auc: 0.6727\n",
      "Epoch 249/1000\n",
      " - 0s - loss: 0.0511 - auc: 0.6727 - val_loss: 0.1248 - val_auc: 0.6728\n",
      "Epoch 250/1000\n",
      " - 0s - loss: 0.0523 - auc: 0.6728 - val_loss: 0.1256 - val_auc: 0.6728\n",
      "Epoch 251/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.6729 - val_loss: 0.1252 - val_auc: 0.6730\n",
      "Epoch 252/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6730 - val_loss: 0.1253 - val_auc: 0.6730\n",
      "Epoch 253/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6731 - val_loss: 0.1264 - val_auc: 0.6732\n",
      "Epoch 254/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6732 - val_loss: 0.1259 - val_auc: 0.6734\n",
      "Epoch 255/1000\n",
      " - 0s - loss: 0.0505 - auc: 0.6734 - val_loss: 0.1249 - val_auc: 0.6735\n",
      "Epoch 256/1000\n",
      " - 0s - loss: 0.0511 - auc: 0.6736 - val_loss: 0.1254 - val_auc: 0.6736\n",
      "Epoch 257/1000\n",
      " - 0s - loss: 0.0515 - auc: 0.6736 - val_loss: 0.1252 - val_auc: 0.6737\n",
      "Epoch 258/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6737 - val_loss: 0.1249 - val_auc: 0.6737\n",
      "Epoch 259/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6737 - val_loss: 0.1250 - val_auc: 0.6738\n",
      "Epoch 260/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6739 - val_loss: 0.1248 - val_auc: 0.6740\n",
      "Epoch 261/1000\n",
      " - 0s - loss: 0.0505 - auc: 0.6741 - val_loss: 0.1248 - val_auc: 0.6742\n",
      "Epoch 262/1000\n",
      " - 0s - loss: 0.0517 - auc: 0.6742 - val_loss: 0.1259 - val_auc: 0.6743\n",
      "Epoch 263/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6744 - val_loss: 0.1254 - val_auc: 0.6746\n",
      "Epoch 264/1000\n",
      " - 0s - loss: 0.0506 - auc: 0.6746 - val_loss: 0.1263 - val_auc: 0.6748\n",
      "Epoch 265/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6748 - val_loss: 0.1260 - val_auc: 0.6749\n",
      "Epoch 266/1000\n",
      " - 0s - loss: 0.0508 - auc: 0.6749 - val_loss: 0.1266 - val_auc: 0.6750\n",
      "Epoch 267/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.6749 - val_loss: 0.1255 - val_auc: 0.6750\n",
      "Epoch 268/1000\n",
      " - 0s - loss: 0.0501 - auc: 0.6750 - val_loss: 0.1257 - val_auc: 0.6751\n",
      "Epoch 269/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.6752 - val_loss: 0.1251 - val_auc: 0.6753\n",
      "Epoch 270/1000\n",
      " - 0s - loss: 0.0534 - auc: 0.6753 - val_loss: 0.1257 - val_auc: 0.6754\n",
      "Epoch 271/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6753 - val_loss: 0.1246 - val_auc: 0.6754\n",
      "Epoch 272/1000\n",
      " - 0s - loss: 0.0516 - auc: 0.6754 - val_loss: 0.1254 - val_auc: 0.6755\n",
      "Epoch 273/1000\n",
      " - 0s - loss: 0.0509 - auc: 0.6755 - val_loss: 0.1251 - val_auc: 0.6755\n",
      "Epoch 274/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6756 - val_loss: 0.1263 - val_auc: 0.6757\n",
      "Epoch 275/1000\n",
      " - 0s - loss: 0.0505 - auc: 0.6758 - val_loss: 0.1253 - val_auc: 0.6759\n",
      "Epoch 276/1000\n",
      " - 0s - loss: 0.0534 - auc: 0.6759 - val_loss: 0.1255 - val_auc: 0.6759\n",
      "Epoch 277/1000\n",
      " - 0s - loss: 0.0509 - auc: 0.6759 - val_loss: 0.1251 - val_auc: 0.6760\n",
      "Epoch 278/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6761 - val_loss: 0.1257 - val_auc: 0.6762\n",
      "Epoch 279/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.6762 - val_loss: 0.1261 - val_auc: 0.6763\n",
      "Epoch 280/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.6764 - val_loss: 0.1262 - val_auc: 0.6765\n",
      "Epoch 281/1000\n",
      " - 0s - loss: 0.0509 - auc: 0.6766 - val_loss: 0.1257 - val_auc: 0.6766\n",
      "Epoch 282/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6766 - val_loss: 0.1256 - val_auc: 0.6767\n",
      "Epoch 283/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6768 - val_loss: 0.1259 - val_auc: 0.6768\n",
      "Epoch 284/1000\n",
      " - 0s - loss: 0.0514 - auc: 0.6768 - val_loss: 0.1265 - val_auc: 0.6769\n",
      "Epoch 285/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0510 - auc: 0.6769 - val_loss: 0.1254 - val_auc: 0.6770\n",
      "Epoch 286/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6771 - val_loss: 0.1258 - val_auc: 0.6771\n",
      "Epoch 287/1000\n",
      " - 0s - loss: 0.0518 - auc: 0.6771 - val_loss: 0.1258 - val_auc: 0.6771\n",
      "Epoch 288/1000\n",
      " - 0s - loss: 0.0518 - auc: 0.6772 - val_loss: 0.1264 - val_auc: 0.6772\n",
      "Epoch 289/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6772 - val_loss: 0.1259 - val_auc: 0.6773\n",
      "Epoch 290/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.6774 - val_loss: 0.1263 - val_auc: 0.6775\n",
      "Epoch 291/1000\n",
      " - 0s - loss: 0.0528 - auc: 0.6776 - val_loss: 0.1271 - val_auc: 0.6775\n",
      "Epoch 292/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6776 - val_loss: 0.1255 - val_auc: 0.6777\n",
      "Epoch 293/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6778 - val_loss: 0.1254 - val_auc: 0.6778\n",
      "Epoch 294/1000\n",
      " - 0s - loss: 0.0529 - auc: 0.6778 - val_loss: 0.1256 - val_auc: 0.6778\n",
      "Epoch 295/1000\n",
      " - 0s - loss: 0.0525 - auc: 0.6778 - val_loss: 0.1246 - val_auc: 0.6778\n",
      "Epoch 296/1000\n",
      " - 0s - loss: 0.0503 - auc: 0.6779 - val_loss: 0.1258 - val_auc: 0.6780\n",
      "Epoch 297/1000\n",
      " - 0s - loss: 0.0508 - auc: 0.6780 - val_loss: 0.1256 - val_auc: 0.6781\n",
      "Epoch 298/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6781 - val_loss: 0.1255 - val_auc: 0.6782\n",
      "Epoch 299/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6783 - val_loss: 0.1261 - val_auc: 0.6783\n",
      "Epoch 300/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6784 - val_loss: 0.1259 - val_auc: 0.6785\n",
      "Epoch 301/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6786 - val_loss: 0.1263 - val_auc: 0.6787\n",
      "Epoch 302/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6787 - val_loss: 0.1254 - val_auc: 0.6788\n",
      "Epoch 303/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.6788 - val_loss: 0.1258 - val_auc: 0.6789\n",
      "Epoch 304/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6790 - val_loss: 0.1260 - val_auc: 0.6791\n",
      "Epoch 305/1000\n",
      " - 0s - loss: 0.0524 - auc: 0.6790 - val_loss: 0.1253 - val_auc: 0.6791\n",
      "Epoch 306/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6791 - val_loss: 0.1253 - val_auc: 0.6793\n",
      "Epoch 307/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6793 - val_loss: 0.1246 - val_auc: 0.6794\n",
      "Epoch 308/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6795 - val_loss: 0.1251 - val_auc: 0.6796\n",
      "Epoch 309/1000\n",
      " - 0s - loss: 0.0509 - auc: 0.6796 - val_loss: 0.1259 - val_auc: 0.6797\n",
      "Epoch 310/1000\n",
      " - 0s - loss: 0.0502 - auc: 0.6797 - val_loss: 0.1254 - val_auc: 0.6798\n",
      "Epoch 311/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6798 - val_loss: 0.1257 - val_auc: 0.6799\n",
      "Epoch 312/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6798 - val_loss: 0.1246 - val_auc: 0.6799\n",
      "Epoch 313/1000\n",
      " - 0s - loss: 0.0506 - auc: 0.6799 - val_loss: 0.1256 - val_auc: 0.6800\n",
      "Epoch 314/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.6801 - val_loss: 0.1257 - val_auc: 0.6802\n",
      "Epoch 315/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.6802 - val_loss: 0.1259 - val_auc: 0.6802\n",
      "Epoch 316/1000\n",
      " - 0s - loss: 0.0517 - auc: 0.6802 - val_loss: 0.1256 - val_auc: 0.6802\n",
      "Epoch 317/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6803 - val_loss: 0.1256 - val_auc: 0.6804\n",
      "Epoch 318/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.6804 - val_loss: 0.1266 - val_auc: 0.6805\n",
      "Epoch 319/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6805 - val_loss: 0.1266 - val_auc: 0.6805\n",
      "Epoch 320/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6806 - val_loss: 0.1261 - val_auc: 0.6806\n",
      "Epoch 321/1000\n",
      " - 0s - loss: 0.0508 - auc: 0.6806 - val_loss: 0.1262 - val_auc: 0.6807\n",
      "Epoch 322/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6807 - val_loss: 0.1252 - val_auc: 0.6808\n",
      "Epoch 323/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.6808 - val_loss: 0.1257 - val_auc: 0.6808\n",
      "Epoch 324/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6809 - val_loss: 0.1253 - val_auc: 0.6810\n",
      "Epoch 325/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6810 - val_loss: 0.1259 - val_auc: 0.6811\n",
      "Epoch 326/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6811 - val_loss: 0.1270 - val_auc: 0.6812\n",
      "Epoch 327/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6813 - val_loss: 0.1270 - val_auc: 0.6814\n",
      "Epoch 328/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6814 - val_loss: 0.1260 - val_auc: 0.6815\n",
      "Epoch 329/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6816 - val_loss: 0.1261 - val_auc: 0.6817\n",
      "Epoch 330/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6817 - val_loss: 0.1263 - val_auc: 0.6817\n",
      "Epoch 331/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6817 - val_loss: 0.1259 - val_auc: 0.6818\n",
      "Epoch 332/1000\n",
      " - 0s - loss: 0.0507 - auc: 0.6819 - val_loss: 0.1259 - val_auc: 0.6819\n",
      "Epoch 333/1000\n",
      " - 0s - loss: 0.0515 - auc: 0.6819 - val_loss: 0.1265 - val_auc: 0.6819\n",
      "Epoch 334/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6820 - val_loss: 0.1258 - val_auc: 0.6820\n",
      "Epoch 335/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.6821 - val_loss: 0.1258 - val_auc: 0.6822\n",
      "Epoch 336/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6822 - val_loss: 0.1266 - val_auc: 0.6822\n",
      "Epoch 337/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6823 - val_loss: 0.1260 - val_auc: 0.6823\n",
      "Epoch 338/1000\n",
      " - 0s - loss: 0.0531 - auc: 0.6823 - val_loss: 0.1265 - val_auc: 0.6823\n",
      "Epoch 339/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.6823 - val_loss: 0.1268 - val_auc: 0.6824\n",
      "Epoch 340/1000\n",
      " - 0s - loss: 0.0517 - auc: 0.6824 - val_loss: 0.1261 - val_auc: 0.6824\n",
      "Epoch 341/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6824 - val_loss: 0.1259 - val_auc: 0.6825\n",
      "Epoch 342/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6825 - val_loss: 0.1260 - val_auc: 0.6826\n",
      "Epoch 343/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6826 - val_loss: 0.1257 - val_auc: 0.6827\n",
      "Epoch 344/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.6827 - val_loss: 0.1265 - val_auc: 0.6828\n",
      "Epoch 345/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6828 - val_loss: 0.1269 - val_auc: 0.6829\n",
      "Epoch 346/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.6830 - val_loss: 0.1260 - val_auc: 0.6831\n",
      "Epoch 347/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.6831 - val_loss: 0.1262 - val_auc: 0.6832\n",
      "Epoch 348/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6833 - val_loss: 0.1274 - val_auc: 0.6834\n",
      "Epoch 349/1000\n",
      " - 0s - loss: 0.0508 - auc: 0.6834 - val_loss: 0.1267 - val_auc: 0.6834\n",
      "Epoch 350/1000\n",
      " - 0s - loss: 0.0508 - auc: 0.6834 - val_loss: 0.1268 - val_auc: 0.6835\n",
      "Epoch 351/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6835 - val_loss: 0.1260 - val_auc: 0.6836\n",
      "Epoch 352/1000\n",
      " - 0s - loss: 0.0501 - auc: 0.6836 - val_loss: 0.1258 - val_auc: 0.6837\n",
      "Epoch 353/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6837 - val_loss: 0.1264 - val_auc: 0.6838\n",
      "Epoch 354/1000\n",
      " - 0s - loss: 0.0516 - auc: 0.6838 - val_loss: 0.1255 - val_auc: 0.6838\n",
      "Epoch 355/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.6838 - val_loss: 0.1254 - val_auc: 0.6839\n",
      "Epoch 356/1000\n",
      " - 0s - loss: 0.0505 - auc: 0.6839 - val_loss: 0.1268 - val_auc: 0.6840\n",
      "Epoch 357/1000\n",
      " - 0s - loss: 0.0509 - auc: 0.6840 - val_loss: 0.1264 - val_auc: 0.6840\n",
      "Epoch 358/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.6841 - val_loss: 0.1266 - val_auc: 0.6842\n",
      "Epoch 359/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.6842 - val_loss: 0.1260 - val_auc: 0.6843\n",
      "Epoch 360/1000\n",
      " - 0s - loss: 0.0527 - auc: 0.6842 - val_loss: 0.1268 - val_auc: 0.6842\n",
      "Epoch 361/1000\n",
      " - 0s - loss: 0.0519 - auc: 0.6842 - val_loss: 0.1267 - val_auc: 0.6843\n",
      "Epoch 362/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6843 - val_loss: 0.1263 - val_auc: 0.6844\n",
      "Epoch 363/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6844 - val_loss: 0.1274 - val_auc: 0.6845\n",
      "Epoch 364/1000\n",
      " - 0s - loss: 0.0516 - auc: 0.6845 - val_loss: 0.1268 - val_auc: 0.6845\n",
      "Epoch 365/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6846 - val_loss: 0.1254 - val_auc: 0.6847\n",
      "Epoch 366/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6848 - val_loss: 0.1260 - val_auc: 0.6849\n",
      "Epoch 367/1000\n",
      " - 0s - loss: 0.0511 - auc: 0.6849 - val_loss: 0.1254 - val_auc: 0.6849\n",
      "Epoch 368/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6850 - val_loss: 0.1265 - val_auc: 0.6850\n",
      "Epoch 369/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.6850 - val_loss: 0.1267 - val_auc: 0.6851\n",
      "Epoch 370/1000\n",
      " - 0s - loss: 0.0509 - auc: 0.6852 - val_loss: 0.1269 - val_auc: 0.6852\n",
      "Epoch 371/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.6853 - val_loss: 0.1270 - val_auc: 0.6854\n",
      "Epoch 372/1000\n",
      " - 0s - loss: 0.0506 - auc: 0.6854 - val_loss: 0.1272 - val_auc: 0.6855\n",
      "Epoch 373/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6855 - val_loss: 0.1269 - val_auc: 0.6856\n",
      "Epoch 374/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.6856 - val_loss: 0.1268 - val_auc: 0.6856\n",
      "Epoch 375/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6857 - val_loss: 0.1263 - val_auc: 0.6858\n",
      "Epoch 376/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.6858 - val_loss: 0.1266 - val_auc: 0.6858\n",
      "Epoch 377/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6858 - val_loss: 0.1273 - val_auc: 0.6859\n",
      "Epoch 378/1000\n",
      " - 0s - loss: 0.0502 - auc: 0.6859 - val_loss: 0.1262 - val_auc: 0.6860\n",
      "Epoch 379/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.6861 - val_loss: 0.1268 - val_auc: 0.6861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6861 - val_loss: 0.1279 - val_auc: 0.6862\n",
      "Epoch 381/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.6862 - val_loss: 0.1282 - val_auc: 0.6862\n",
      "Epoch 382/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6863 - val_loss: 0.1282 - val_auc: 0.6863\n",
      "Epoch 383/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6863 - val_loss: 0.1278 - val_auc: 0.6864\n",
      "Epoch 384/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6865 - val_loss: 0.1283 - val_auc: 0.6865\n",
      "Epoch 385/1000\n",
      " - 0s - loss: 0.0502 - auc: 0.6865 - val_loss: 0.1281 - val_auc: 0.6866\n",
      "Epoch 386/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6866 - val_loss: 0.1280 - val_auc: 0.6867\n",
      "Epoch 387/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6867 - val_loss: 0.1279 - val_auc: 0.6868\n",
      "Epoch 388/1000\n",
      " - 0s - loss: 0.0535 - auc: 0.6867 - val_loss: 0.1274 - val_auc: 0.6867\n",
      "Epoch 389/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.6867 - val_loss: 0.1277 - val_auc: 0.6868\n",
      "Epoch 390/1000\n",
      " - 0s - loss: 0.0486 - auc: 0.6868 - val_loss: 0.1275 - val_auc: 0.6869\n",
      "Epoch 391/1000\n",
      " - 0s - loss: 0.0520 - auc: 0.6869 - val_loss: 0.1279 - val_auc: 0.6869\n",
      "Epoch 392/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6869 - val_loss: 0.1276 - val_auc: 0.6869\n",
      "Epoch 393/1000\n",
      " - 0s - loss: 0.0486 - auc: 0.6870 - val_loss: 0.1273 - val_auc: 0.6871\n",
      "Epoch 394/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6871 - val_loss: 0.1281 - val_auc: 0.6872\n",
      "Epoch 395/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.6872 - val_loss: 0.1278 - val_auc: 0.6873\n",
      "Epoch 396/1000\n",
      " - 0s - loss: 0.0503 - auc: 0.6873 - val_loss: 0.1279 - val_auc: 0.6874\n",
      "Epoch 397/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6874 - val_loss: 0.1274 - val_auc: 0.6875\n",
      "Epoch 398/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.6875 - val_loss: 0.1276 - val_auc: 0.6876\n",
      "Epoch 399/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6876 - val_loss: 0.1286 - val_auc: 0.6877\n",
      "Epoch 400/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.6877 - val_loss: 0.1287 - val_auc: 0.6878\n",
      "Epoch 401/1000\n",
      " - 0s - loss: 0.0501 - auc: 0.6878 - val_loss: 0.1286 - val_auc: 0.6878\n",
      "Epoch 402/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6878 - val_loss: 0.1283 - val_auc: 0.6879\n",
      "Epoch 403/1000\n",
      " - 0s - loss: 0.0505 - auc: 0.6878 - val_loss: 0.1280 - val_auc: 0.6879\n",
      "Epoch 404/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6879 - val_loss: 0.1279 - val_auc: 0.6880\n",
      "Epoch 405/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6880 - val_loss: 0.1265 - val_auc: 0.6881\n",
      "Epoch 406/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6881 - val_loss: 0.1278 - val_auc: 0.6881\n",
      "Epoch 407/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.6882 - val_loss: 0.1269 - val_auc: 0.6882\n",
      "Epoch 408/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.6882 - val_loss: 0.1278 - val_auc: 0.6883\n",
      "Epoch 409/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6884 - val_loss: 0.1281 - val_auc: 0.6884\n",
      "Epoch 410/1000\n",
      " - 0s - loss: 0.0507 - auc: 0.6884 - val_loss: 0.1271 - val_auc: 0.6884\n",
      "Epoch 411/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6884 - val_loss: 0.1283 - val_auc: 0.6885\n",
      "Epoch 412/1000\n",
      " - 0s - loss: 0.0514 - auc: 0.6885 - val_loss: 0.1284 - val_auc: 0.6885\n",
      "Epoch 413/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.6885 - val_loss: 0.1282 - val_auc: 0.6886\n",
      "Epoch 414/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6886 - val_loss: 0.1271 - val_auc: 0.6886\n",
      "Epoch 415/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6887 - val_loss: 0.1274 - val_auc: 0.6887\n",
      "Epoch 416/1000\n",
      " - 0s - loss: 0.0516 - auc: 0.6887 - val_loss: 0.1279 - val_auc: 0.6887\n",
      "Epoch 417/1000\n",
      " - 0s - loss: 0.0501 - auc: 0.6888 - val_loss: 0.1286 - val_auc: 0.6888\n",
      "Epoch 418/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.6888 - val_loss: 0.1278 - val_auc: 0.6889\n",
      "Epoch 419/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.6889 - val_loss: 0.1279 - val_auc: 0.6889\n",
      "Epoch 420/1000\n",
      " - 0s - loss: 0.0501 - auc: 0.6889 - val_loss: 0.1274 - val_auc: 0.6890\n",
      "Epoch 421/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.6891 - val_loss: 0.1279 - val_auc: 0.6892\n",
      "Epoch 422/1000\n",
      " - 0s - loss: 0.0506 - auc: 0.6892 - val_loss: 0.1284 - val_auc: 0.6891\n",
      "Epoch 423/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6891 - val_loss: 0.1271 - val_auc: 0.6892\n",
      "Epoch 424/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.6893 - val_loss: 0.1280 - val_auc: 0.6894\n",
      "Epoch 425/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6894 - val_loss: 0.1282 - val_auc: 0.6894\n",
      "Epoch 426/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.6894 - val_loss: 0.1287 - val_auc: 0.6895\n",
      "Epoch 427/1000\n",
      " - 0s - loss: 0.0516 - auc: 0.6894 - val_loss: 0.1286 - val_auc: 0.6895\n",
      "Epoch 428/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.6895 - val_loss: 0.1282 - val_auc: 0.6896\n",
      "Epoch 429/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.6896 - val_loss: 0.1286 - val_auc: 0.6897\n",
      "Epoch 430/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6897 - val_loss: 0.1280 - val_auc: 0.6898\n",
      "Epoch 431/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.6899 - val_loss: 0.1284 - val_auc: 0.6899\n",
      "Epoch 432/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6900 - val_loss: 0.1269 - val_auc: 0.6900\n",
      "Epoch 433/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.6901 - val_loss: 0.1263 - val_auc: 0.6902\n",
      "Epoch 434/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6902 - val_loss: 0.1280 - val_auc: 0.6903\n",
      "Epoch 435/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6903 - val_loss: 0.1275 - val_auc: 0.6903\n",
      "Epoch 436/1000\n",
      " - 0s - loss: 0.0502 - auc: 0.6904 - val_loss: 0.1281 - val_auc: 0.6904\n",
      "Epoch 437/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6904 - val_loss: 0.1271 - val_auc: 0.6905\n",
      "Epoch 438/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.6905 - val_loss: 0.1274 - val_auc: 0.6906\n",
      "Epoch 439/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6906 - val_loss: 0.1281 - val_auc: 0.6906\n",
      "Epoch 440/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.6907 - val_loss: 0.1288 - val_auc: 0.6907\n",
      "Epoch 441/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.6907 - val_loss: 0.1290 - val_auc: 0.6908\n",
      "Epoch 442/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.6908 - val_loss: 0.1284 - val_auc: 0.6909\n",
      "Epoch 443/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.6909 - val_loss: 0.1292 - val_auc: 0.6910\n",
      "Epoch 444/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.6910 - val_loss: 0.1290 - val_auc: 0.6911\n",
      "Epoch 445/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6911 - val_loss: 0.1289 - val_auc: 0.6912\n",
      "Epoch 446/1000\n",
      " - 0s - loss: 0.0510 - auc: 0.6912 - val_loss: 0.1280 - val_auc: 0.6912\n",
      "Epoch 447/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6912 - val_loss: 0.1292 - val_auc: 0.6913\n",
      "Epoch 448/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.6913 - val_loss: 0.1275 - val_auc: 0.6913\n",
      "Epoch 449/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6914 - val_loss: 0.1283 - val_auc: 0.6914\n",
      "Epoch 450/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6915 - val_loss: 0.1277 - val_auc: 0.6915\n",
      "Epoch 451/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.6916 - val_loss: 0.1277 - val_auc: 0.6916\n",
      "Epoch 452/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6916 - val_loss: 0.1291 - val_auc: 0.6917\n",
      "Epoch 453/1000\n",
      " - 0s - loss: 0.0501 - auc: 0.6917 - val_loss: 0.1287 - val_auc: 0.6917\n",
      "Epoch 454/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6918 - val_loss: 0.1277 - val_auc: 0.6918\n",
      "Epoch 455/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6918 - val_loss: 0.1276 - val_auc: 0.6918\n",
      "Epoch 456/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.6918 - val_loss: 0.1282 - val_auc: 0.6919\n",
      "Epoch 457/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6919 - val_loss: 0.1286 - val_auc: 0.6919\n",
      "Epoch 458/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.6919 - val_loss: 0.1272 - val_auc: 0.6919\n",
      "Epoch 459/1000\n",
      " - 0s - loss: 0.0506 - auc: 0.6919 - val_loss: 0.1266 - val_auc: 0.6920\n",
      "Epoch 460/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.6920 - val_loss: 0.1273 - val_auc: 0.6921\n",
      "Epoch 461/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6922 - val_loss: 0.1278 - val_auc: 0.6922\n",
      "Epoch 462/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.6922 - val_loss: 0.1280 - val_auc: 0.6923\n",
      "Epoch 463/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6923 - val_loss: 0.1271 - val_auc: 0.6923\n",
      "Epoch 464/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.6924 - val_loss: 0.1269 - val_auc: 0.6924\n",
      "Epoch 465/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6924 - val_loss: 0.1275 - val_auc: 0.6925\n",
      "Epoch 466/1000\n",
      " - 0s - loss: 0.0508 - auc: 0.6925 - val_loss: 0.1273 - val_auc: 0.6925\n",
      "Epoch 467/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6925 - val_loss: 0.1263 - val_auc: 0.6925\n",
      "Epoch 468/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6925 - val_loss: 0.1267 - val_auc: 0.6925\n",
      "Epoch 469/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6926 - val_loss: 0.1265 - val_auc: 0.6926\n",
      "Epoch 470/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.6926 - val_loss: 0.1275 - val_auc: 0.6927\n",
      "Epoch 471/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6927 - val_loss: 0.1281 - val_auc: 0.6927\n",
      "Epoch 472/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.6928 - val_loss: 0.1281 - val_auc: 0.6928\n",
      "Epoch 473/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6928 - val_loss: 0.1274 - val_auc: 0.6929\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0500 - auc: 0.6929 - val_loss: 0.1275 - val_auc: 0.6929\n",
      "Epoch 475/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6929 - val_loss: 0.1279 - val_auc: 0.6929\n",
      "Epoch 476/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6930 - val_loss: 0.1268 - val_auc: 0.6930\n",
      "Epoch 477/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6930 - val_loss: 0.1278 - val_auc: 0.6930\n",
      "Epoch 478/1000\n",
      " - 0s - loss: 0.0507 - auc: 0.6930 - val_loss: 0.1267 - val_auc: 0.6930\n",
      "Epoch 479/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6930 - val_loss: 0.1269 - val_auc: 0.6930\n",
      "Epoch 480/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.6930 - val_loss: 0.1270 - val_auc: 0.6931\n",
      "Epoch 481/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.6932 - val_loss: 0.1272 - val_auc: 0.6932\n",
      "Epoch 482/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6932 - val_loss: 0.1270 - val_auc: 0.6933\n",
      "Epoch 483/1000\n",
      " - 0s - loss: 0.0517 - auc: 0.6933 - val_loss: 0.1272 - val_auc: 0.6933\n",
      "Epoch 484/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.6933 - val_loss: 0.1267 - val_auc: 0.6934\n",
      "Epoch 485/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.6933 - val_loss: 0.1266 - val_auc: 0.6934\n",
      "Epoch 486/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6935 - val_loss: 0.1271 - val_auc: 0.6935\n",
      "Epoch 487/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.6935 - val_loss: 0.1264 - val_auc: 0.6936\n",
      "Epoch 488/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6936 - val_loss: 0.1248 - val_auc: 0.6936\n",
      "Epoch 489/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6936 - val_loss: 0.1250 - val_auc: 0.6937\n",
      "Epoch 490/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6937 - val_loss: 0.1251 - val_auc: 0.6938\n",
      "Epoch 491/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6938 - val_loss: 0.1258 - val_auc: 0.6938\n",
      "Epoch 492/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.6939 - val_loss: 0.1262 - val_auc: 0.6939\n",
      "Epoch 493/1000\n",
      " - 0s - loss: 0.0486 - auc: 0.6939 - val_loss: 0.1261 - val_auc: 0.6939\n",
      "Epoch 494/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.6940 - val_loss: 0.1273 - val_auc: 0.6941\n",
      "Epoch 495/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.6941 - val_loss: 0.1260 - val_auc: 0.6941\n",
      "Epoch 496/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6942 - val_loss: 0.1256 - val_auc: 0.6943\n",
      "Epoch 497/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6943 - val_loss: 0.1255 - val_auc: 0.6943\n",
      "Epoch 498/1000\n",
      " - 0s - loss: 0.0486 - auc: 0.6943 - val_loss: 0.1260 - val_auc: 0.6944\n",
      "Epoch 499/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.6944 - val_loss: 0.1250 - val_auc: 0.6945\n",
      "Epoch 500/1000\n",
      " - 0s - loss: 0.0507 - auc: 0.6945 - val_loss: 0.1245 - val_auc: 0.6945\n",
      "Epoch 501/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.6945 - val_loss: 0.1235 - val_auc: 0.6946\n",
      "Epoch 502/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6946 - val_loss: 0.1243 - val_auc: 0.6947\n",
      "Epoch 503/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.6947 - val_loss: 0.1249 - val_auc: 0.6947\n",
      "Epoch 504/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.6948 - val_loss: 0.1251 - val_auc: 0.6948\n",
      "Epoch 505/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6948 - val_loss: 0.1253 - val_auc: 0.6949\n",
      "Epoch 506/1000\n",
      " - 0s - loss: 0.0506 - auc: 0.6949 - val_loss: 0.1249 - val_auc: 0.6949\n",
      "Epoch 507/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.6949 - val_loss: 0.1257 - val_auc: 0.6949\n",
      "Epoch 508/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.6949 - val_loss: 0.1246 - val_auc: 0.6949\n",
      "Epoch 509/1000\n",
      " - 0s - loss: 0.0513 - auc: 0.6949 - val_loss: 0.1242 - val_auc: 0.6949\n",
      "Epoch 510/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.6950 - val_loss: 0.1252 - val_auc: 0.6950\n",
      "Epoch 511/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.6950 - val_loss: 0.1260 - val_auc: 0.6951\n",
      "Epoch 512/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6951 - val_loss: 0.1254 - val_auc: 0.6951\n",
      "Epoch 513/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.6951 - val_loss: 0.1242 - val_auc: 0.6952\n",
      "Epoch 514/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6952 - val_loss: 0.1245 - val_auc: 0.6952\n",
      "Epoch 515/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6952 - val_loss: 0.1247 - val_auc: 0.6953\n",
      "Epoch 516/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.6953 - val_loss: 0.1255 - val_auc: 0.6953\n",
      "Epoch 517/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.6954 - val_loss: 0.1248 - val_auc: 0.6954\n",
      "Epoch 518/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.6954 - val_loss: 0.1245 - val_auc: 0.6955\n",
      "Epoch 519/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6955 - val_loss: 0.1254 - val_auc: 0.6955\n",
      "Epoch 520/1000\n",
      " - 0s - loss: 0.0503 - auc: 0.6955 - val_loss: 0.1254 - val_auc: 0.6956\n",
      "Epoch 521/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6956 - val_loss: 0.1246 - val_auc: 0.6956\n",
      "Epoch 522/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.6957 - val_loss: 0.1249 - val_auc: 0.6957\n",
      "Epoch 523/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.6957 - val_loss: 0.1251 - val_auc: 0.6958\n",
      "Epoch 524/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.6958 - val_loss: 0.1257 - val_auc: 0.6959\n",
      "Epoch 525/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.6959 - val_loss: 0.1248 - val_auc: 0.6960\n",
      "Epoch 526/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6960 - val_loss: 0.1241 - val_auc: 0.6960\n",
      "Epoch 527/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6960 - val_loss: 0.1249 - val_auc: 0.6960\n",
      "Epoch 528/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.6961 - val_loss: 0.1260 - val_auc: 0.6962\n",
      "Epoch 529/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.6962 - val_loss: 0.1257 - val_auc: 0.6962\n",
      "Epoch 530/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.6962 - val_loss: 0.1245 - val_auc: 0.6963\n",
      "Epoch 531/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.6962 - val_loss: 0.1237 - val_auc: 0.6963\n",
      "Epoch 532/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.6963 - val_loss: 0.1240 - val_auc: 0.6964\n",
      "Epoch 533/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.6964 - val_loss: 0.1242 - val_auc: 0.6965\n",
      "Epoch 534/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.6965 - val_loss: 0.1238 - val_auc: 0.6966\n",
      "Epoch 535/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6966 - val_loss: 0.1229 - val_auc: 0.6966\n",
      "Epoch 536/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.6966 - val_loss: 0.1232 - val_auc: 0.6966\n",
      "Epoch 537/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.6966 - val_loss: 0.1237 - val_auc: 0.6967\n",
      "Epoch 538/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6967 - val_loss: 0.1227 - val_auc: 0.6967\n",
      "Epoch 539/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6967 - val_loss: 0.1225 - val_auc: 0.6968\n",
      "Epoch 540/1000\n",
      " - 0s - loss: 0.0500 - auc: 0.6968 - val_loss: 0.1226 - val_auc: 0.6968\n",
      "Epoch 541/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.6968 - val_loss: 0.1217 - val_auc: 0.6968\n",
      "Epoch 542/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.6968 - val_loss: 0.1227 - val_auc: 0.6968\n",
      "Epoch 543/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6968 - val_loss: 0.1224 - val_auc: 0.6969\n",
      "Epoch 544/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.6969 - val_loss: 0.1216 - val_auc: 0.6970\n",
      "Epoch 545/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6970 - val_loss: 0.1206 - val_auc: 0.6970\n",
      "Epoch 546/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6970 - val_loss: 0.1210 - val_auc: 0.6970\n",
      "Epoch 547/1000\n",
      " - 0s - loss: 0.0504 - auc: 0.6971 - val_loss: 0.1209 - val_auc: 0.6970\n",
      "Epoch 548/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6970 - val_loss: 0.1216 - val_auc: 0.6971\n",
      "Epoch 549/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6971 - val_loss: 0.1221 - val_auc: 0.6971\n",
      "Epoch 550/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.6972 - val_loss: 0.1227 - val_auc: 0.6972\n",
      "Epoch 551/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.6972 - val_loss: 0.1217 - val_auc: 0.6972\n",
      "Epoch 552/1000\n",
      " - 0s - loss: 0.0501 - auc: 0.6972 - val_loss: 0.1214 - val_auc: 0.6972\n",
      "Epoch 553/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.6973 - val_loss: 0.1205 - val_auc: 0.6973\n",
      "Epoch 554/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6973 - val_loss: 0.1208 - val_auc: 0.6974\n",
      "Epoch 555/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6974 - val_loss: 0.1212 - val_auc: 0.6974\n",
      "Epoch 556/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6975 - val_loss: 0.1221 - val_auc: 0.6975\n",
      "Epoch 557/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6975 - val_loss: 0.1219 - val_auc: 0.6975\n",
      "Epoch 558/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6976 - val_loss: 0.1204 - val_auc: 0.6976\n",
      "Epoch 559/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.6976 - val_loss: 0.1202 - val_auc: 0.6976\n",
      "Epoch 560/1000\n",
      " - 0s - loss: 0.0472 - auc: 0.6976 - val_loss: 0.1208 - val_auc: 0.6977\n",
      "Epoch 561/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6977 - val_loss: 0.1202 - val_auc: 0.6977\n",
      "Epoch 562/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.6977 - val_loss: 0.1214 - val_auc: 0.6978\n",
      "Epoch 563/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.6978 - val_loss: 0.1223 - val_auc: 0.6978\n",
      "Epoch 564/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.6978 - val_loss: 0.1213 - val_auc: 0.6979\n",
      "Epoch 565/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.6979 - val_loss: 0.1214 - val_auc: 0.6979\n",
      "Epoch 566/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.6979 - val_loss: 0.1213 - val_auc: 0.6980\n",
      "Epoch 567/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.6980 - val_loss: 0.1206 - val_auc: 0.6980\n",
      "Epoch 568/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.6980 - val_loss: 0.1206 - val_auc: 0.6980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6980 - val_loss: 0.1215 - val_auc: 0.6981\n",
      "Epoch 570/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6981 - val_loss: 0.1199 - val_auc: 0.6981\n",
      "Epoch 571/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.6982 - val_loss: 0.1204 - val_auc: 0.6982\n",
      "Epoch 572/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.6982 - val_loss: 0.1196 - val_auc: 0.6982\n",
      "Epoch 573/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.6982 - val_loss: 0.1202 - val_auc: 0.6982\n",
      "Epoch 574/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.6982 - val_loss: 0.1194 - val_auc: 0.6982\n",
      "Epoch 575/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6982 - val_loss: 0.1192 - val_auc: 0.6983\n",
      "Epoch 576/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6983 - val_loss: 0.1194 - val_auc: 0.6983\n",
      "Epoch 577/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.6983 - val_loss: 0.1189 - val_auc: 0.6984\n",
      "Epoch 578/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6984 - val_loss: 0.1189 - val_auc: 0.6985\n",
      "Epoch 579/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6985 - val_loss: 0.1194 - val_auc: 0.6985\n",
      "Epoch 580/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.6985 - val_loss: 0.1196 - val_auc: 0.6986\n",
      "Epoch 581/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.6986 - val_loss: 0.1204 - val_auc: 0.6986\n",
      "Epoch 582/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.6986 - val_loss: 0.1193 - val_auc: 0.6987\n",
      "Epoch 583/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.6987 - val_loss: 0.1201 - val_auc: 0.6987\n",
      "Epoch 584/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.6988 - val_loss: 0.1203 - val_auc: 0.6988\n",
      "Epoch 585/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.6989 - val_loss: 0.1201 - val_auc: 0.6989\n",
      "Epoch 586/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.6989 - val_loss: 0.1199 - val_auc: 0.6989\n",
      "Epoch 587/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.6989 - val_loss: 0.1195 - val_auc: 0.6989\n",
      "Epoch 588/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.6990 - val_loss: 0.1184 - val_auc: 0.6990\n",
      "Epoch 589/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.6991 - val_loss: 0.1190 - val_auc: 0.6991\n",
      "Epoch 590/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.6991 - val_loss: 0.1186 - val_auc: 0.6992\n",
      "Epoch 591/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.6992 - val_loss: 0.1185 - val_auc: 0.6992\n",
      "Epoch 592/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6993 - val_loss: 0.1187 - val_auc: 0.6993\n",
      "Epoch 593/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.6993 - val_loss: 0.1187 - val_auc: 0.6994\n",
      "Epoch 594/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.6994 - val_loss: 0.1193 - val_auc: 0.6994\n",
      "Epoch 595/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.6994 - val_loss: 0.1198 - val_auc: 0.6994\n",
      "Epoch 596/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.6995 - val_loss: 0.1184 - val_auc: 0.6995\n",
      "Epoch 597/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6995 - val_loss: 0.1180 - val_auc: 0.6995\n",
      "Epoch 598/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.6996 - val_loss: 0.1188 - val_auc: 0.6996\n",
      "Epoch 599/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.6996 - val_loss: 0.1177 - val_auc: 0.6996\n",
      "Epoch 600/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.6997 - val_loss: 0.1181 - val_auc: 0.6996\n",
      "Epoch 601/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.6997 - val_loss: 0.1195 - val_auc: 0.6997\n",
      "Epoch 602/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.6997 - val_loss: 0.1188 - val_auc: 0.6997\n",
      "Epoch 603/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.6997 - val_loss: 0.1183 - val_auc: 0.6997\n",
      "Epoch 604/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6998 - val_loss: 0.1174 - val_auc: 0.6998\n",
      "Epoch 605/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.6998 - val_loss: 0.1178 - val_auc: 0.6998\n",
      "Epoch 606/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.6999 - val_loss: 0.1173 - val_auc: 0.6999\n",
      "Epoch 607/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.6999 - val_loss: 0.1177 - val_auc: 0.6999\n",
      "Epoch 608/1000\n",
      " - 0s - loss: 0.0486 - auc: 0.6999 - val_loss: 0.1183 - val_auc: 0.6999\n",
      "Epoch 609/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.6999 - val_loss: 0.1186 - val_auc: 0.7000\n",
      "Epoch 610/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.7000 - val_loss: 0.1181 - val_auc: 0.7000\n",
      "Epoch 611/1000\n",
      " - 0s - loss: 0.0486 - auc: 0.7000 - val_loss: 0.1168 - val_auc: 0.7001\n",
      "Epoch 612/1000\n",
      " - 0s - loss: 0.0506 - auc: 0.7001 - val_loss: 0.1167 - val_auc: 0.7001\n",
      "Epoch 613/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7001 - val_loss: 0.1174 - val_auc: 0.7001\n",
      "Epoch 614/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.7001 - val_loss: 0.1169 - val_auc: 0.7001\n",
      "Epoch 615/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.7001 - val_loss: 0.1175 - val_auc: 0.7002\n",
      "Epoch 616/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7002 - val_loss: 0.1183 - val_auc: 0.7003\n",
      "Epoch 617/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7003 - val_loss: 0.1192 - val_auc: 0.7004\n",
      "Epoch 618/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.7003 - val_loss: 0.1177 - val_auc: 0.7004\n",
      "Epoch 619/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.7004 - val_loss: 0.1183 - val_auc: 0.7005\n",
      "Epoch 620/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.7005 - val_loss: 0.1177 - val_auc: 0.7006\n",
      "Epoch 621/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7006 - val_loss: 0.1180 - val_auc: 0.7006\n",
      "Epoch 622/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.7006 - val_loss: 0.1189 - val_auc: 0.7007\n",
      "Epoch 623/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7007 - val_loss: 0.1181 - val_auc: 0.7007\n",
      "Epoch 624/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7007 - val_loss: 0.1175 - val_auc: 0.7008\n",
      "Epoch 625/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.7008 - val_loss: 0.1177 - val_auc: 0.7008\n",
      "Epoch 626/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7008 - val_loss: 0.1183 - val_auc: 0.7009\n",
      "Epoch 627/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.7009 - val_loss: 0.1184 - val_auc: 0.7009\n",
      "Epoch 628/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.7010 - val_loss: 0.1181 - val_auc: 0.7010\n",
      "Epoch 629/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.7010 - val_loss: 0.1161 - val_auc: 0.7010\n",
      "Epoch 630/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.7010 - val_loss: 0.1176 - val_auc: 0.7011\n",
      "Epoch 631/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7011 - val_loss: 0.1168 - val_auc: 0.7011\n",
      "Epoch 632/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.7011 - val_loss: 0.1175 - val_auc: 0.7012\n",
      "Epoch 633/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.7012 - val_loss: 0.1174 - val_auc: 0.7012\n",
      "Epoch 634/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7013 - val_loss: 0.1172 - val_auc: 0.7013\n",
      "Epoch 635/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7013 - val_loss: 0.1177 - val_auc: 0.7013\n",
      "Epoch 636/1000\n",
      " - 0s - loss: 0.0461 - auc: 0.7014 - val_loss: 0.1165 - val_auc: 0.7014\n",
      "Epoch 637/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7015 - val_loss: 0.1168 - val_auc: 0.7015\n",
      "Epoch 638/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.7015 - val_loss: 0.1174 - val_auc: 0.7015\n",
      "Epoch 639/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7016 - val_loss: 0.1166 - val_auc: 0.7016\n",
      "Epoch 640/1000\n",
      " - 0s - loss: 0.0454 - auc: 0.7017 - val_loss: 0.1179 - val_auc: 0.7017\n",
      "Epoch 641/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7017 - val_loss: 0.1171 - val_auc: 0.7018\n",
      "Epoch 642/1000\n",
      " - 0s - loss: 0.0489 - auc: 0.7017 - val_loss: 0.1178 - val_auc: 0.7017\n",
      "Epoch 643/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7018 - val_loss: 0.1173 - val_auc: 0.7018\n",
      "Epoch 644/1000\n",
      " - 0s - loss: 0.0472 - auc: 0.7018 - val_loss: 0.1167 - val_auc: 0.7019\n",
      "Epoch 645/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.7019 - val_loss: 0.1186 - val_auc: 0.7019\n",
      "Epoch 646/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.7019 - val_loss: 0.1168 - val_auc: 0.7020\n",
      "Epoch 647/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7020 - val_loss: 0.1160 - val_auc: 0.7020\n",
      "Epoch 648/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7020 - val_loss: 0.1167 - val_auc: 0.7021\n",
      "Epoch 649/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.7021 - val_loss: 0.1179 - val_auc: 0.7021\n",
      "Epoch 650/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.7021 - val_loss: 0.1171 - val_auc: 0.7022\n",
      "Epoch 651/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7022 - val_loss: 0.1162 - val_auc: 0.7022\n",
      "Epoch 652/1000\n",
      " - 0s - loss: 0.0498 - auc: 0.7023 - val_loss: 0.1166 - val_auc: 0.7023\n",
      "Epoch 653/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.7023 - val_loss: 0.1157 - val_auc: 0.7023\n",
      "Epoch 654/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.7023 - val_loss: 0.1162 - val_auc: 0.7024\n",
      "Epoch 655/1000\n",
      " - 0s - loss: 0.0486 - auc: 0.7024 - val_loss: 0.1167 - val_auc: 0.7024\n",
      "Epoch 656/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7024 - val_loss: 0.1161 - val_auc: 0.7025\n",
      "Epoch 657/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.7024 - val_loss: 0.1171 - val_auc: 0.7025\n",
      "Epoch 658/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.7025 - val_loss: 0.1170 - val_auc: 0.7025\n",
      "Epoch 659/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7025 - val_loss: 0.1168 - val_auc: 0.7026\n",
      "Epoch 660/1000\n",
      " - 0s - loss: 0.0472 - auc: 0.7026 - val_loss: 0.1170 - val_auc: 0.7026\n",
      "Epoch 661/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.7027 - val_loss: 0.1166 - val_auc: 0.7027\n",
      "Epoch 662/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.7027 - val_loss: 0.1158 - val_auc: 0.7028\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0487 - auc: 0.7028 - val_loss: 0.1164 - val_auc: 0.7028\n",
      "Epoch 664/1000\n",
      " - 0s - loss: 0.0501 - auc: 0.7028 - val_loss: 0.1149 - val_auc: 0.7029\n",
      "Epoch 665/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7029 - val_loss: 0.1155 - val_auc: 0.7029\n",
      "Epoch 666/1000\n",
      " - 0s - loss: 0.0449 - auc: 0.7030 - val_loss: 0.1153 - val_auc: 0.7030\n",
      "Epoch 667/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7031 - val_loss: 0.1162 - val_auc: 0.7031\n",
      "Epoch 668/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7031 - val_loss: 0.1148 - val_auc: 0.7031\n",
      "Epoch 669/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7032 - val_loss: 0.1157 - val_auc: 0.7032\n",
      "Epoch 670/1000\n",
      " - 0s - loss: 0.0459 - auc: 0.7032 - val_loss: 0.1160 - val_auc: 0.7033\n",
      "Epoch 671/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7033 - val_loss: 0.1167 - val_auc: 0.7034\n",
      "Epoch 672/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.7034 - val_loss: 0.1156 - val_auc: 0.7034\n",
      "Epoch 673/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7034 - val_loss: 0.1173 - val_auc: 0.7035\n",
      "Epoch 674/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.7035 - val_loss: 0.1157 - val_auc: 0.7035\n",
      "Epoch 675/1000\n",
      " - 0s - loss: 0.0461 - auc: 0.7036 - val_loss: 0.1154 - val_auc: 0.7036\n",
      "Epoch 676/1000\n",
      " - 0s - loss: 0.0495 - auc: 0.7037 - val_loss: 0.1159 - val_auc: 0.7037\n",
      "Epoch 677/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.7037 - val_loss: 0.1147 - val_auc: 0.7037\n",
      "Epoch 678/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7038 - val_loss: 0.1150 - val_auc: 0.7038\n",
      "Epoch 679/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7038 - val_loss: 0.1149 - val_auc: 0.7038\n",
      "Epoch 680/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7039 - val_loss: 0.1165 - val_auc: 0.7039\n",
      "Epoch 681/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.7039 - val_loss: 0.1154 - val_auc: 0.7040\n",
      "Epoch 682/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7040 - val_loss: 0.1154 - val_auc: 0.7040\n",
      "Epoch 683/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7041 - val_loss: 0.1155 - val_auc: 0.7041\n",
      "Epoch 684/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7041 - val_loss: 0.1149 - val_auc: 0.7041\n",
      "Epoch 685/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.7041 - val_loss: 0.1163 - val_auc: 0.7042\n",
      "Epoch 686/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.7042 - val_loss: 0.1155 - val_auc: 0.7042\n",
      "Epoch 687/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7042 - val_loss: 0.1160 - val_auc: 0.7043\n",
      "Epoch 688/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7043 - val_loss: 0.1158 - val_auc: 0.7043\n",
      "Epoch 689/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.7043 - val_loss: 0.1157 - val_auc: 0.7044\n",
      "Epoch 690/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7044 - val_loss: 0.1167 - val_auc: 0.7044\n",
      "Epoch 691/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7045 - val_loss: 0.1154 - val_auc: 0.7045\n",
      "Epoch 692/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7045 - val_loss: 0.1152 - val_auc: 0.7045\n",
      "Epoch 693/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.7045 - val_loss: 0.1161 - val_auc: 0.7046\n",
      "Epoch 694/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.7046 - val_loss: 0.1163 - val_auc: 0.7046\n",
      "Epoch 695/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7047 - val_loss: 0.1146 - val_auc: 0.7047\n",
      "Epoch 696/1000\n",
      " - 0s - loss: 0.0455 - auc: 0.7047 - val_loss: 0.1153 - val_auc: 0.7048\n",
      "Epoch 697/1000\n",
      " - 0s - loss: 0.0457 - auc: 0.7048 - val_loss: 0.1154 - val_auc: 0.7049\n",
      "Epoch 698/1000\n",
      " - 0s - loss: 0.0454 - auc: 0.7049 - val_loss: 0.1157 - val_auc: 0.7050\n",
      "Epoch 699/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7050 - val_loss: 0.1160 - val_auc: 0.7050\n",
      "Epoch 700/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.7050 - val_loss: 0.1158 - val_auc: 0.7050\n",
      "Epoch 701/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.7050 - val_loss: 0.1158 - val_auc: 0.7051\n",
      "Epoch 702/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7051 - val_loss: 0.1151 - val_auc: 0.7051\n",
      "Epoch 703/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.7051 - val_loss: 0.1144 - val_auc: 0.7051\n",
      "Epoch 704/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.7051 - val_loss: 0.1145 - val_auc: 0.7052\n",
      "Epoch 705/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7052 - val_loss: 0.1158 - val_auc: 0.7052\n",
      "Epoch 706/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7053 - val_loss: 0.1165 - val_auc: 0.7053\n",
      "Epoch 707/1000\n",
      " - 0s - loss: 0.0472 - auc: 0.7053 - val_loss: 0.1166 - val_auc: 0.7053\n",
      "Epoch 708/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.7053 - val_loss: 0.1154 - val_auc: 0.7053\n",
      "Epoch 709/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.7054 - val_loss: 0.1149 - val_auc: 0.7054\n",
      "Epoch 710/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7054 - val_loss: 0.1147 - val_auc: 0.7054\n",
      "Epoch 711/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7055 - val_loss: 0.1148 - val_auc: 0.7055\n",
      "Epoch 712/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7055 - val_loss: 0.1142 - val_auc: 0.7055\n",
      "Epoch 713/1000\n",
      " - 0s - loss: 0.0486 - auc: 0.7055 - val_loss: 0.1137 - val_auc: 0.7056\n",
      "Epoch 714/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.7056 - val_loss: 0.1144 - val_auc: 0.7056\n",
      "Epoch 715/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7057 - val_loss: 0.1139 - val_auc: 0.7057\n",
      "Epoch 716/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7057 - val_loss: 0.1152 - val_auc: 0.7058\n",
      "Epoch 717/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.7058 - val_loss: 0.1140 - val_auc: 0.7058\n",
      "Epoch 718/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.7059 - val_loss: 0.1143 - val_auc: 0.7059\n",
      "Epoch 719/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7059 - val_loss: 0.1143 - val_auc: 0.7059\n",
      "Epoch 720/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7060 - val_loss: 0.1138 - val_auc: 0.7060\n",
      "Epoch 721/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7060 - val_loss: 0.1138 - val_auc: 0.7060\n",
      "Epoch 722/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7061 - val_loss: 0.1146 - val_auc: 0.7061\n",
      "Epoch 723/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7061 - val_loss: 0.1155 - val_auc: 0.7062\n",
      "Epoch 724/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7062 - val_loss: 0.1145 - val_auc: 0.7062\n",
      "Epoch 725/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.7062 - val_loss: 0.1147 - val_auc: 0.7063\n",
      "Epoch 726/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.7063 - val_loss: 0.1137 - val_auc: 0.7063\n",
      "Epoch 727/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.7063 - val_loss: 0.1137 - val_auc: 0.7064\n",
      "Epoch 728/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7064 - val_loss: 0.1142 - val_auc: 0.7065\n",
      "Epoch 729/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7065 - val_loss: 0.1144 - val_auc: 0.7065\n",
      "Epoch 730/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.7065 - val_loss: 0.1147 - val_auc: 0.7066\n",
      "Epoch 731/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7066 - val_loss: 0.1145 - val_auc: 0.7066\n",
      "Epoch 732/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7066 - val_loss: 0.1135 - val_auc: 0.7067\n",
      "Epoch 733/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.7067 - val_loss: 0.1126 - val_auc: 0.7067\n",
      "Epoch 734/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.7068 - val_loss: 0.1138 - val_auc: 0.7068\n",
      "Epoch 735/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7068 - val_loss: 0.1133 - val_auc: 0.7068\n",
      "Epoch 736/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7069 - val_loss: 0.1133 - val_auc: 0.7069\n",
      "Epoch 737/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.7069 - val_loss: 0.1140 - val_auc: 0.7070\n",
      "Epoch 738/1000\n",
      " - 0s - loss: 0.0453 - auc: 0.7070 - val_loss: 0.1150 - val_auc: 0.7071\n",
      "Epoch 739/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.7071 - val_loss: 0.1149 - val_auc: 0.7071\n",
      "Epoch 740/1000\n",
      " - 0s - loss: 0.0499 - auc: 0.7071 - val_loss: 0.1158 - val_auc: 0.7072\n",
      "Epoch 741/1000\n",
      " - 0s - loss: 0.0459 - auc: 0.7072 - val_loss: 0.1145 - val_auc: 0.7072\n",
      "Epoch 742/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7073 - val_loss: 0.1150 - val_auc: 0.7073\n",
      "Epoch 743/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.7073 - val_loss: 0.1147 - val_auc: 0.7073\n",
      "Epoch 744/1000\n",
      " - 0s - loss: 0.0497 - auc: 0.7073 - val_loss: 0.1150 - val_auc: 0.7074\n",
      "Epoch 745/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7074 - val_loss: 0.1156 - val_auc: 0.7074\n",
      "Epoch 746/1000\n",
      " - 0s - loss: 0.0463 - auc: 0.7074 - val_loss: 0.1154 - val_auc: 0.7074\n",
      "Epoch 747/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7075 - val_loss: 0.1154 - val_auc: 0.7075\n",
      "Epoch 748/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7075 - val_loss: 0.1153 - val_auc: 0.7076\n",
      "Epoch 749/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7076 - val_loss: 0.1153 - val_auc: 0.7076\n",
      "Epoch 750/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7076 - val_loss: 0.1147 - val_auc: 0.7077\n",
      "Epoch 751/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7077 - val_loss: 0.1156 - val_auc: 0.7077\n",
      "Epoch 752/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7077 - val_loss: 0.1160 - val_auc: 0.7078\n",
      "Epoch 753/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.7078 - val_loss: 0.1158 - val_auc: 0.7078\n",
      "Epoch 754/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7078 - val_loss: 0.1159 - val_auc: 0.7079\n",
      "Epoch 755/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7079 - val_loss: 0.1157 - val_auc: 0.7079\n",
      "Epoch 756/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7079 - val_loss: 0.1154 - val_auc: 0.7080\n",
      "Epoch 757/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7080 - val_loss: 0.1159 - val_auc: 0.7080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7080 - val_loss: 0.1155 - val_auc: 0.7080\n",
      "Epoch 759/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7080 - val_loss: 0.1154 - val_auc: 0.7081\n",
      "Epoch 760/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7081 - val_loss: 0.1151 - val_auc: 0.7081\n",
      "Epoch 761/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7081 - val_loss: 0.1157 - val_auc: 0.7082\n",
      "Epoch 762/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7082 - val_loss: 0.1148 - val_auc: 0.7082\n",
      "Epoch 763/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.7082 - val_loss: 0.1146 - val_auc: 0.7083\n",
      "Epoch 764/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7083 - val_loss: 0.1158 - val_auc: 0.7084\n",
      "Epoch 765/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7084 - val_loss: 0.1171 - val_auc: 0.7084\n",
      "Epoch 766/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7084 - val_loss: 0.1162 - val_auc: 0.7085\n",
      "Epoch 767/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.7085 - val_loss: 0.1163 - val_auc: 0.7085\n",
      "Epoch 768/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7085 - val_loss: 0.1157 - val_auc: 0.7085\n",
      "Epoch 769/1000\n",
      " - 0s - loss: 0.0449 - auc: 0.7086 - val_loss: 0.1164 - val_auc: 0.7086\n",
      "Epoch 770/1000\n",
      " - 0s - loss: 0.0461 - auc: 0.7086 - val_loss: 0.1164 - val_auc: 0.7087\n",
      "Epoch 771/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.7087 - val_loss: 0.1155 - val_auc: 0.7087\n",
      "Epoch 772/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7087 - val_loss: 0.1151 - val_auc: 0.7088\n",
      "Epoch 773/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7088 - val_loss: 0.1154 - val_auc: 0.7088\n",
      "Epoch 774/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.7088 - val_loss: 0.1135 - val_auc: 0.7089\n",
      "Epoch 775/1000\n",
      " - 0s - loss: 0.0458 - auc: 0.7089 - val_loss: 0.1138 - val_auc: 0.7089\n",
      "Epoch 776/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.7090 - val_loss: 0.1143 - val_auc: 0.7090\n",
      "Epoch 777/1000\n",
      " - 0s - loss: 0.0472 - auc: 0.7090 - val_loss: 0.1142 - val_auc: 0.7090\n",
      "Epoch 778/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.7091 - val_loss: 0.1152 - val_auc: 0.7091\n",
      "Epoch 779/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.7091 - val_loss: 0.1142 - val_auc: 0.7091\n",
      "Epoch 780/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7091 - val_loss: 0.1139 - val_auc: 0.7092\n",
      "Epoch 781/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.7092 - val_loss: 0.1131 - val_auc: 0.7092\n",
      "Epoch 782/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7092 - val_loss: 0.1138 - val_auc: 0.7093\n",
      "Epoch 783/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7093 - val_loss: 0.1139 - val_auc: 0.7093\n",
      "Epoch 784/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7093 - val_loss: 0.1141 - val_auc: 0.7094\n",
      "Epoch 785/1000\n",
      " - 0s - loss: 0.0461 - auc: 0.7094 - val_loss: 0.1134 - val_auc: 0.7095\n",
      "Epoch 786/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7095 - val_loss: 0.1148 - val_auc: 0.7095\n",
      "Epoch 787/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.7095 - val_loss: 0.1158 - val_auc: 0.7096\n",
      "Epoch 788/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7096 - val_loss: 0.1149 - val_auc: 0.7096\n",
      "Epoch 789/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7096 - val_loss: 0.1153 - val_auc: 0.7097\n",
      "Epoch 790/1000\n",
      " - 0s - loss: 0.0486 - auc: 0.7097 - val_loss: 0.1142 - val_auc: 0.7097\n",
      "Epoch 791/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7097 - val_loss: 0.1138 - val_auc: 0.7098\n",
      "Epoch 792/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7098 - val_loss: 0.1148 - val_auc: 0.7098\n",
      "Epoch 793/1000\n",
      " - 0s - loss: 0.0494 - auc: 0.7098 - val_loss: 0.1150 - val_auc: 0.7098\n",
      "Epoch 794/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.7098 - val_loss: 0.1147 - val_auc: 0.7098\n",
      "Epoch 795/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.7099 - val_loss: 0.1147 - val_auc: 0.7099\n",
      "Epoch 796/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7099 - val_loss: 0.1142 - val_auc: 0.7099\n",
      "Epoch 797/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7099 - val_loss: 0.1142 - val_auc: 0.7100\n",
      "Epoch 798/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.7100 - val_loss: 0.1135 - val_auc: 0.7100\n",
      "Epoch 799/1000\n",
      " - 0s - loss: 0.0457 - auc: 0.7101 - val_loss: 0.1134 - val_auc: 0.7101\n",
      "Epoch 800/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7101 - val_loss: 0.1133 - val_auc: 0.7101\n",
      "Epoch 801/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7101 - val_loss: 0.1138 - val_auc: 0.7102\n",
      "Epoch 802/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7102 - val_loss: 0.1139 - val_auc: 0.7102\n",
      "Epoch 803/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7102 - val_loss: 0.1139 - val_auc: 0.7102\n",
      "Epoch 804/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.7102 - val_loss: 0.1126 - val_auc: 0.7103\n",
      "Epoch 805/1000\n",
      " - 0s - loss: 0.0453 - auc: 0.7103 - val_loss: 0.1130 - val_auc: 0.7103\n",
      "Epoch 806/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7103 - val_loss: 0.1127 - val_auc: 0.7104\n",
      "Epoch 807/1000\n",
      " - 0s - loss: 0.0457 - auc: 0.7104 - val_loss: 0.1129 - val_auc: 0.7105\n",
      "Epoch 808/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7105 - val_loss: 0.1135 - val_auc: 0.7105\n",
      "Epoch 809/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.7105 - val_loss: 0.1137 - val_auc: 0.7106\n",
      "Epoch 810/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.7106 - val_loss: 0.1132 - val_auc: 0.7106\n",
      "Epoch 811/1000\n",
      " - 0s - loss: 0.0461 - auc: 0.7106 - val_loss: 0.1134 - val_auc: 0.7107\n",
      "Epoch 812/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7107 - val_loss: 0.1126 - val_auc: 0.7107\n",
      "Epoch 813/1000\n",
      " - 0s - loss: 0.0455 - auc: 0.7108 - val_loss: 0.1135 - val_auc: 0.7108\n",
      "Epoch 814/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7108 - val_loss: 0.1137 - val_auc: 0.7108\n",
      "Epoch 815/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7109 - val_loss: 0.1141 - val_auc: 0.7109\n",
      "Epoch 816/1000\n",
      " - 0s - loss: 0.0463 - auc: 0.7109 - val_loss: 0.1130 - val_auc: 0.7110\n",
      "Epoch 817/1000\n",
      " - 0s - loss: 0.0463 - auc: 0.7110 - val_loss: 0.1119 - val_auc: 0.7110\n",
      "Epoch 818/1000\n",
      " - 0s - loss: 0.0449 - auc: 0.7111 - val_loss: 0.1130 - val_auc: 0.7111\n",
      "Epoch 819/1000\n",
      " - 0s - loss: 0.0463 - auc: 0.7111 - val_loss: 0.1148 - val_auc: 0.7111\n",
      "Epoch 820/1000\n",
      " - 0s - loss: 0.0472 - auc: 0.7112 - val_loss: 0.1142 - val_auc: 0.7112\n",
      "Epoch 821/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.7112 - val_loss: 0.1134 - val_auc: 0.7112\n",
      "Epoch 822/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.7112 - val_loss: 0.1125 - val_auc: 0.7113\n",
      "Epoch 823/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7113 - val_loss: 0.1121 - val_auc: 0.7113\n",
      "Epoch 824/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.7114 - val_loss: 0.1122 - val_auc: 0.7114\n",
      "Epoch 825/1000\n",
      " - 0s - loss: 0.0453 - auc: 0.7114 - val_loss: 0.1136 - val_auc: 0.7114\n",
      "Epoch 826/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7114 - val_loss: 0.1126 - val_auc: 0.7115\n",
      "Epoch 827/1000\n",
      " - 0s - loss: 0.0463 - auc: 0.7115 - val_loss: 0.1129 - val_auc: 0.7115\n",
      "Epoch 828/1000\n",
      " - 0s - loss: 0.0459 - auc: 0.7116 - val_loss: 0.1115 - val_auc: 0.7116\n",
      "Epoch 829/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7116 - val_loss: 0.1116 - val_auc: 0.7117\n",
      "Epoch 830/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7117 - val_loss: 0.1117 - val_auc: 0.7117\n",
      "Epoch 831/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7117 - val_loss: 0.1123 - val_auc: 0.7117\n",
      "Epoch 832/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7117 - val_loss: 0.1120 - val_auc: 0.7118\n",
      "Epoch 833/1000\n",
      " - 0s - loss: 0.0463 - auc: 0.7118 - val_loss: 0.1114 - val_auc: 0.7118\n",
      "Epoch 834/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7119 - val_loss: 0.1133 - val_auc: 0.7119\n",
      "Epoch 835/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7119 - val_loss: 0.1131 - val_auc: 0.7119\n",
      "Epoch 836/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7119 - val_loss: 0.1139 - val_auc: 0.7119\n",
      "Epoch 837/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7119 - val_loss: 0.1122 - val_auc: 0.7120\n",
      "Epoch 838/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7120 - val_loss: 0.1121 - val_auc: 0.7120\n",
      "Epoch 839/1000\n",
      " - 0s - loss: 0.0461 - auc: 0.7120 - val_loss: 0.1133 - val_auc: 0.7121\n",
      "Epoch 840/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7121 - val_loss: 0.1122 - val_auc: 0.7121\n",
      "Epoch 841/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7121 - val_loss: 0.1126 - val_auc: 0.7122\n",
      "Epoch 842/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7122 - val_loss: 0.1110 - val_auc: 0.7122\n",
      "Epoch 843/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7122 - val_loss: 0.1112 - val_auc: 0.7123\n",
      "Epoch 844/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7123 - val_loss: 0.1132 - val_auc: 0.7123\n",
      "Epoch 845/1000\n",
      " - 0s - loss: 0.0492 - auc: 0.7123 - val_loss: 0.1113 - val_auc: 0.7124\n",
      "Epoch 846/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7124 - val_loss: 0.1106 - val_auc: 0.7124\n",
      "Epoch 847/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.7124 - val_loss: 0.1122 - val_auc: 0.7124\n",
      "Epoch 848/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7124 - val_loss: 0.1117 - val_auc: 0.7125\n",
      "Epoch 849/1000\n",
      " - 0s - loss: 0.0456 - auc: 0.7125 - val_loss: 0.1125 - val_auc: 0.7125\n",
      "Epoch 850/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7126 - val_loss: 0.1127 - val_auc: 0.7126\n",
      "Epoch 851/1000\n",
      " - 0s - loss: 0.0472 - auc: 0.7126 - val_loss: 0.1125 - val_auc: 0.7126\n",
      "Epoch 852/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0470 - auc: 0.7126 - val_loss: 0.1122 - val_auc: 0.7127\n",
      "Epoch 853/1000\n",
      " - 0s - loss: 0.0454 - auc: 0.7127 - val_loss: 0.1125 - val_auc: 0.7127\n",
      "Epoch 854/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.7128 - val_loss: 0.1115 - val_auc: 0.7128\n",
      "Epoch 855/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7128 - val_loss: 0.1124 - val_auc: 0.7128\n",
      "Epoch 856/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7128 - val_loss: 0.1125 - val_auc: 0.7129\n",
      "Epoch 857/1000\n",
      " - 0s - loss: 0.0448 - auc: 0.7129 - val_loss: 0.1122 - val_auc: 0.7130\n",
      "Epoch 858/1000\n",
      " - 0s - loss: 0.0496 - auc: 0.7129 - val_loss: 0.1115 - val_auc: 0.7129\n",
      "Epoch 859/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7130 - val_loss: 0.1117 - val_auc: 0.7130\n",
      "Epoch 860/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7130 - val_loss: 0.1123 - val_auc: 0.7130\n",
      "Epoch 861/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.7131 - val_loss: 0.1131 - val_auc: 0.7131\n",
      "Epoch 862/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7131 - val_loss: 0.1126 - val_auc: 0.7131\n",
      "Epoch 863/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7131 - val_loss: 0.1124 - val_auc: 0.7131\n",
      "Epoch 864/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.7131 - val_loss: 0.1125 - val_auc: 0.7131\n",
      "Epoch 865/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.7132 - val_loss: 0.1127 - val_auc: 0.7132\n",
      "Epoch 866/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7132 - val_loss: 0.1129 - val_auc: 0.7133\n",
      "Epoch 867/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7133 - val_loss: 0.1125 - val_auc: 0.7133\n",
      "Epoch 868/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.7133 - val_loss: 0.1131 - val_auc: 0.7133\n",
      "Epoch 869/1000\n",
      " - 0s - loss: 0.0451 - auc: 0.7134 - val_loss: 0.1120 - val_auc: 0.7134\n",
      "Epoch 870/1000\n",
      " - 0s - loss: 0.0487 - auc: 0.7135 - val_loss: 0.1119 - val_auc: 0.7135\n",
      "Epoch 871/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7135 - val_loss: 0.1114 - val_auc: 0.7135\n",
      "Epoch 872/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.7135 - val_loss: 0.1125 - val_auc: 0.7136\n",
      "Epoch 873/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7136 - val_loss: 0.1125 - val_auc: 0.7136\n",
      "Epoch 874/1000\n",
      " - 0s - loss: 0.0458 - auc: 0.7136 - val_loss: 0.1133 - val_auc: 0.7137\n",
      "Epoch 875/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7137 - val_loss: 0.1137 - val_auc: 0.7137\n",
      "Epoch 876/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7137 - val_loss: 0.1134 - val_auc: 0.7138\n",
      "Epoch 877/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7138 - val_loss: 0.1118 - val_auc: 0.7138\n",
      "Epoch 878/1000\n",
      " - 0s - loss: 0.0491 - auc: 0.7138 - val_loss: 0.1116 - val_auc: 0.7138\n",
      "Epoch 879/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.7138 - val_loss: 0.1129 - val_auc: 0.7138\n",
      "Epoch 880/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.7139 - val_loss: 0.1132 - val_auc: 0.7139\n",
      "Epoch 881/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.7139 - val_loss: 0.1130 - val_auc: 0.7139\n",
      "Epoch 882/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7139 - val_loss: 0.1131 - val_auc: 0.7140\n",
      "Epoch 883/1000\n",
      " - 0s - loss: 0.0446 - auc: 0.7140 - val_loss: 0.1125 - val_auc: 0.7140\n",
      "Epoch 884/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.7141 - val_loss: 0.1127 - val_auc: 0.7141\n",
      "Epoch 885/1000\n",
      " - 0s - loss: 0.0455 - auc: 0.7141 - val_loss: 0.1126 - val_auc: 0.7141\n",
      "Epoch 886/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7142 - val_loss: 0.1118 - val_auc: 0.7142\n",
      "Epoch 887/1000\n",
      " - 0s - loss: 0.0454 - auc: 0.7142 - val_loss: 0.1120 - val_auc: 0.7142\n",
      "Epoch 888/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.7143 - val_loss: 0.1126 - val_auc: 0.7143\n",
      "Epoch 889/1000\n",
      " - 0s - loss: 0.0463 - auc: 0.7143 - val_loss: 0.1138 - val_auc: 0.7143\n",
      "Epoch 890/1000\n",
      " - 0s - loss: 0.0446 - auc: 0.7144 - val_loss: 0.1135 - val_auc: 0.7144\n",
      "Epoch 891/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7144 - val_loss: 0.1129 - val_auc: 0.7144\n",
      "Epoch 892/1000\n",
      " - 0s - loss: 0.0490 - auc: 0.7145 - val_loss: 0.1141 - val_auc: 0.7145\n",
      "Epoch 893/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7145 - val_loss: 0.1144 - val_auc: 0.7145\n",
      "Epoch 894/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7145 - val_loss: 0.1141 - val_auc: 0.7145\n",
      "Epoch 895/1000\n",
      " - 0s - loss: 0.0468 - auc: 0.7146 - val_loss: 0.1137 - val_auc: 0.7146\n",
      "Epoch 896/1000\n",
      " - 0s - loss: 0.0454 - auc: 0.7146 - val_loss: 0.1141 - val_auc: 0.7146\n",
      "Epoch 897/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7147 - val_loss: 0.1147 - val_auc: 0.7147\n",
      "Epoch 898/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7147 - val_loss: 0.1142 - val_auc: 0.7147\n",
      "Epoch 899/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7147 - val_loss: 0.1139 - val_auc: 0.7148\n",
      "Epoch 900/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.7148 - val_loss: 0.1140 - val_auc: 0.7148\n",
      "Epoch 901/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7148 - val_loss: 0.1131 - val_auc: 0.7148\n",
      "Epoch 902/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.7148 - val_loss: 0.1121 - val_auc: 0.7149\n",
      "Epoch 903/1000\n",
      " - 0s - loss: 0.0485 - auc: 0.7149 - val_loss: 0.1125 - val_auc: 0.7149\n",
      "Epoch 904/1000\n",
      " - 0s - loss: 0.0459 - auc: 0.7149 - val_loss: 0.1129 - val_auc: 0.7150\n",
      "Epoch 905/1000\n",
      " - 0s - loss: 0.0482 - auc: 0.7150 - val_loss: 0.1135 - val_auc: 0.7150\n",
      "Epoch 906/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7150 - val_loss: 0.1122 - val_auc: 0.7150\n",
      "Epoch 907/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7150 - val_loss: 0.1123 - val_auc: 0.7151\n",
      "Epoch 908/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7151 - val_loss: 0.1129 - val_auc: 0.7151\n",
      "Epoch 909/1000\n",
      " - 0s - loss: 0.0453 - auc: 0.7151 - val_loss: 0.1135 - val_auc: 0.7152\n",
      "Epoch 910/1000\n",
      " - 0s - loss: 0.0478 - auc: 0.7152 - val_loss: 0.1130 - val_auc: 0.7152\n",
      "Epoch 911/1000\n",
      " - 0s - loss: 0.0445 - auc: 0.7152 - val_loss: 0.1143 - val_auc: 0.7153\n",
      "Epoch 912/1000\n",
      " - 0s - loss: 0.0446 - auc: 0.7153 - val_loss: 0.1146 - val_auc: 0.7154\n",
      "Epoch 913/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7154 - val_loss: 0.1134 - val_auc: 0.7154\n",
      "Epoch 914/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7154 - val_loss: 0.1138 - val_auc: 0.7154\n",
      "Epoch 915/1000\n",
      " - 0s - loss: 0.0456 - auc: 0.7154 - val_loss: 0.1136 - val_auc: 0.7155\n",
      "Epoch 916/1000\n",
      " - 0s - loss: 0.0461 - auc: 0.7155 - val_loss: 0.1133 - val_auc: 0.7155\n",
      "Epoch 917/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7155 - val_loss: 0.1126 - val_auc: 0.7156\n",
      "Epoch 918/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7156 - val_loss: 0.1129 - val_auc: 0.7156\n",
      "Epoch 919/1000\n",
      " - 0s - loss: 0.0461 - auc: 0.7157 - val_loss: 0.1127 - val_auc: 0.7157\n",
      "Epoch 920/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7157 - val_loss: 0.1122 - val_auc: 0.7157\n",
      "Epoch 921/1000\n",
      " - 0s - loss: 0.0486 - auc: 0.7157 - val_loss: 0.1124 - val_auc: 0.7158\n",
      "Epoch 922/1000\n",
      " - 0s - loss: 0.0459 - auc: 0.7158 - val_loss: 0.1127 - val_auc: 0.7158\n",
      "Epoch 923/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7158 - val_loss: 0.1134 - val_auc: 0.7158\n",
      "Epoch 924/1000\n",
      " - 0s - loss: 0.0483 - auc: 0.7158 - val_loss: 0.1136 - val_auc: 0.7159\n",
      "Epoch 925/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7159 - val_loss: 0.1131 - val_auc: 0.7159\n",
      "Epoch 926/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7159 - val_loss: 0.1124 - val_auc: 0.7160\n",
      "Epoch 927/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7160 - val_loss: 0.1118 - val_auc: 0.7160\n",
      "Epoch 928/1000\n",
      " - 0s - loss: 0.0451 - auc: 0.7160 - val_loss: 0.1120 - val_auc: 0.7161\n",
      "Epoch 929/1000\n",
      " - 0s - loss: 0.0454 - auc: 0.7161 - val_loss: 0.1134 - val_auc: 0.7161\n",
      "Epoch 930/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7162 - val_loss: 0.1126 - val_auc: 0.7162\n",
      "Epoch 931/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7162 - val_loss: 0.1124 - val_auc: 0.7162\n",
      "Epoch 932/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7162 - val_loss: 0.1123 - val_auc: 0.7162\n",
      "Epoch 933/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7163 - val_loss: 0.1128 - val_auc: 0.7163\n",
      "Epoch 934/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7163 - val_loss: 0.1115 - val_auc: 0.7163\n",
      "Epoch 935/1000\n",
      " - 0s - loss: 0.0457 - auc: 0.7164 - val_loss: 0.1127 - val_auc: 0.7164\n",
      "Epoch 936/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.7164 - val_loss: 0.1121 - val_auc: 0.7165\n",
      "Epoch 937/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7165 - val_loss: 0.1122 - val_auc: 0.7165\n",
      "Epoch 938/1000\n",
      " - 0s - loss: 0.0472 - auc: 0.7165 - val_loss: 0.1124 - val_auc: 0.7165\n",
      "Epoch 939/1000\n",
      " - 0s - loss: 0.0484 - auc: 0.7165 - val_loss: 0.1127 - val_auc: 0.7165\n",
      "Epoch 940/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7165 - val_loss: 0.1121 - val_auc: 0.7166\n",
      "Epoch 941/1000\n",
      " - 0s - loss: 0.0493 - auc: 0.7166 - val_loss: 0.1117 - val_auc: 0.7166\n",
      "Epoch 942/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7166 - val_loss: 0.1114 - val_auc: 0.7166\n",
      "Epoch 943/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7166 - val_loss: 0.1118 - val_auc: 0.7166\n",
      "Epoch 944/1000\n",
      " - 0s - loss: 0.0456 - auc: 0.7167 - val_loss: 0.1123 - val_auc: 0.7167\n",
      "Epoch 945/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.7167 - val_loss: 0.1117 - val_auc: 0.7168\n",
      "Epoch 946/1000\n",
      " - 0s - loss: 0.0480 - auc: 0.7168 - val_loss: 0.1113 - val_auc: 0.7168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7168 - val_loss: 0.1113 - val_auc: 0.7168\n",
      "Epoch 948/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7168 - val_loss: 0.1114 - val_auc: 0.7168\n",
      "Epoch 949/1000\n",
      " - 0s - loss: 0.0472 - auc: 0.7169 - val_loss: 0.1121 - val_auc: 0.7169\n",
      "Epoch 950/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7169 - val_loss: 0.1121 - val_auc: 0.7169\n",
      "Epoch 951/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7169 - val_loss: 0.1117 - val_auc: 0.7170\n",
      "Epoch 952/1000\n",
      " - 0s - loss: 0.0475 - auc: 0.7170 - val_loss: 0.1121 - val_auc: 0.7170\n",
      "Epoch 953/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7170 - val_loss: 0.1114 - val_auc: 0.7171\n",
      "Epoch 954/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7171 - val_loss: 0.1111 - val_auc: 0.7171\n",
      "Epoch 955/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7171 - val_loss: 0.1117 - val_auc: 0.7171\n",
      "Epoch 956/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7172 - val_loss: 0.1119 - val_auc: 0.7172\n",
      "Epoch 957/1000\n",
      " - 0s - loss: 0.0453 - auc: 0.7172 - val_loss: 0.1123 - val_auc: 0.7172\n",
      "Epoch 958/1000\n",
      " - 0s - loss: 0.0479 - auc: 0.7172 - val_loss: 0.1116 - val_auc: 0.7172\n",
      "Epoch 959/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7173 - val_loss: 0.1117 - val_auc: 0.7173\n",
      "Epoch 960/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7173 - val_loss: 0.1116 - val_auc: 0.7173\n",
      "Epoch 961/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7173 - val_loss: 0.1112 - val_auc: 0.7174\n",
      "Epoch 962/1000\n",
      " - 0s - loss: 0.0471 - auc: 0.7174 - val_loss: 0.1120 - val_auc: 0.7174\n",
      "Epoch 963/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7174 - val_loss: 0.1112 - val_auc: 0.7174\n",
      "Epoch 964/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.7174 - val_loss: 0.1113 - val_auc: 0.7175\n",
      "Epoch 965/1000\n",
      " - 0s - loss: 0.0456 - auc: 0.7175 - val_loss: 0.1134 - val_auc: 0.7175\n",
      "Epoch 966/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7176 - val_loss: 0.1130 - val_auc: 0.7176\n",
      "Epoch 967/1000\n",
      " - 0s - loss: 0.0458 - auc: 0.7176 - val_loss: 0.1135 - val_auc: 0.7176\n",
      "Epoch 968/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7176 - val_loss: 0.1132 - val_auc: 0.7177\n",
      "Epoch 969/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7177 - val_loss: 0.1112 - val_auc: 0.7177\n",
      "Epoch 970/1000\n",
      " - 0s - loss: 0.0459 - auc: 0.7177 - val_loss: 0.1120 - val_auc: 0.7178\n",
      "Epoch 971/1000\n",
      " - 0s - loss: 0.0476 - auc: 0.7178 - val_loss: 0.1117 - val_auc: 0.7178\n",
      "Epoch 972/1000\n",
      " - 0s - loss: 0.0456 - auc: 0.7178 - val_loss: 0.1121 - val_auc: 0.7179\n",
      "Epoch 973/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7179 - val_loss: 0.1124 - val_auc: 0.7179\n",
      "Epoch 974/1000\n",
      " - 0s - loss: 0.0447 - auc: 0.7179 - val_loss: 0.1134 - val_auc: 0.7179\n",
      "Epoch 975/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7179 - val_loss: 0.1119 - val_auc: 0.7180\n",
      "Epoch 976/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7180 - val_loss: 0.1118 - val_auc: 0.7180\n",
      "Epoch 977/1000\n",
      " - 0s - loss: 0.0462 - auc: 0.7181 - val_loss: 0.1129 - val_auc: 0.7181\n",
      "Epoch 978/1000\n",
      " - 0s - loss: 0.0467 - auc: 0.7181 - val_loss: 0.1131 - val_auc: 0.7181\n",
      "Epoch 979/1000\n",
      " - 0s - loss: 0.0457 - auc: 0.7181 - val_loss: 0.1125 - val_auc: 0.7182\n",
      "Epoch 980/1000\n",
      " - 0s - loss: 0.0470 - auc: 0.7182 - val_loss: 0.1128 - val_auc: 0.7182\n",
      "Epoch 981/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7182 - val_loss: 0.1127 - val_auc: 0.7183\n",
      "Epoch 982/1000\n",
      " - 0s - loss: 0.0474 - auc: 0.7183 - val_loss: 0.1131 - val_auc: 0.7183\n",
      "Epoch 983/1000\n",
      " - 0s - loss: 0.0481 - auc: 0.7183 - val_loss: 0.1126 - val_auc: 0.7183\n",
      "Epoch 984/1000\n",
      " - 0s - loss: 0.0460 - auc: 0.7184 - val_loss: 0.1120 - val_auc: 0.7184\n",
      "Epoch 985/1000\n",
      " - 0s - loss: 0.0457 - auc: 0.7184 - val_loss: 0.1144 - val_auc: 0.7184\n",
      "Epoch 986/1000\n",
      " - 0s - loss: 0.0452 - auc: 0.7185 - val_loss: 0.1140 - val_auc: 0.7185\n",
      "Epoch 987/1000\n",
      " - 0s - loss: 0.0477 - auc: 0.7185 - val_loss: 0.1145 - val_auc: 0.7185\n",
      "Epoch 988/1000\n",
      " - 0s - loss: 0.0466 - auc: 0.7185 - val_loss: 0.1129 - val_auc: 0.7186\n",
      "Epoch 989/1000\n",
      " - 0s - loss: 0.0456 - auc: 0.7186 - val_loss: 0.1128 - val_auc: 0.7186\n",
      "Epoch 990/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.7186 - val_loss: 0.1131 - val_auc: 0.7186\n",
      "Epoch 991/1000\n",
      " - 0s - loss: 0.0465 - auc: 0.7187 - val_loss: 0.1129 - val_auc: 0.7187\n",
      "Epoch 992/1000\n",
      " - 0s - loss: 0.0488 - auc: 0.7187 - val_loss: 0.1134 - val_auc: 0.7187\n",
      "Epoch 993/1000\n",
      " - 0s - loss: 0.0473 - auc: 0.7187 - val_loss: 0.1140 - val_auc: 0.7187\n",
      "Epoch 994/1000\n",
      " - 0s - loss: 0.0443 - auc: 0.7188 - val_loss: 0.1138 - val_auc: 0.7188\n",
      "Epoch 995/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.7188 - val_loss: 0.1149 - val_auc: 0.7188\n",
      "Epoch 996/1000\n",
      " - 0s - loss: 0.0469 - auc: 0.7189 - val_loss: 0.1134 - val_auc: 0.7189\n",
      "Epoch 997/1000\n",
      " - 0s - loss: 0.0448 - auc: 0.7189 - val_loss: 0.1142 - val_auc: 0.7189\n",
      "Epoch 998/1000\n",
      " - 0s - loss: 0.0464 - auc: 0.7189 - val_loss: 0.1146 - val_auc: 0.7189\n",
      "Epoch 999/1000\n",
      " - 0s - loss: 0.0451 - auc: 0.7190 - val_loss: 0.1135 - val_auc: 0.7190\n",
      "Epoch 1000/1000\n",
      " - 0s - loss: 0.0449 - auc: 0.7190 - val_loss: 0.1158 - val_auc: 0.7191\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "Tensor_X_1_I = Input(shape = (len(TYPE_1),))\n",
    "Tensor_X_1 = Dense(units = 8, kernel_initializer = glorot_uniform(seed=RANDOM_SEED)) (Tensor_X_1_I)\n",
    "\n",
    "Tensor_X_2_I = Input(shape = (len(TYPE_2),))\n",
    "Tensor_X_2 = Dense(units = 8, kernel_initializer = glorot_uniform(seed=RANDOM_SEED)) (Tensor_X_2_I)\n",
    "\n",
    "Tensor_X_3_I = Input(shape = (len(TYPE_3),))\n",
    "Tensor_X_3 = Dense(units = 8, kernel_initializer = glorot_uniform(seed=RANDOM_SEED)) (Tensor_X_3_I)\n",
    "\n",
    "Tensor_X_4_I = Input(shape = (len(TYPE_4),))\n",
    "Tensor_X_4 = Dense(units = 8, kernel_initializer = glorot_uniform(seed=RANDOM_SEED)) (Tensor_X_4_I)\n",
    "\n",
    "Tensor_X = Concatenate(name = 'concat') ([Tensor_X_1, Tensor_X_2, Tensor_X_3, Tensor_X_4])\n",
    "Tensor_X = Dense(units = 32, kernel_initializer = glorot_uniform(seed=0), kernel_regularizer=penalties[best_test_index]) (Tensor_X)\n",
    "Tensor_X = Activation('relu') (Tensor_X)\n",
    "Tensor_X = Dropout(best_dropout_ratio , seed = RANDOM_SEED) (Tensor_X)\n",
    "Tensor_X = Dense(units = 1, kernel_initializer = glorot_uniform(seed=RANDOM_SEED), kernel_regularizer=penalties[best_test_index]) (Tensor_X)\n",
    "Tensor_X = Activation('sigmoid') (Tensor_X)\n",
    "\n",
    "model_4 = Model(inputs = [Tensor_X_1_I, Tensor_X_2_I, Tensor_X_3_I, Tensor_X_4_I], outputs = Tensor_X)\n",
    "        \n",
    "adam = Adam()\n",
    "model_4.compile(loss=\"binary_crossentropy\", optimizer = adam, metrics=[auc_metric])\n",
    "history_4 = model_4.fit(X_trains, y_train, batch_size=256, epochs=1000, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ebc55d8c18>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1008 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model_4, to_file='model4.png')\n",
    "\n",
    "plt.figure(figsize = (14,14))\n",
    "plt.imshow(plt.imread('model4.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_4 = model_4.predict(X_tests)[:, 0]\n",
    "fpr_4, tpr_4, thresholds_4 = roc_curve(y_test, y_pred_4)\n",
    "\n",
    "roc_auc_4 = auc(fpr_4, tpr_4)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_4, tpr_4, 'b',label='AUC = %0.3f'% roc_auc_4)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.save('model_4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multibranches (cont'd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_537 (Dense)               (None, 16)           64          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 25)           0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 dense_537[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           832         concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 1)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 929\n",
      "Trainable params: 929\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TYPE_1 = ['MARQUE_BMW', 'MARQUE_CHV', 'MARQUE_CIT', 'MARQUE_MAZ', 'MARQUE_SEA', 'MARQUE_VAU']\n",
    "TYPE_2 = ['MODE_LOGT_2.0', 'MODE_LOGT_nan']\n",
    "TYPE_3 = ['PRIX_VEH', 'MT_APPORT', 'AGE_CLI']\n",
    "TYPE_4 = ['DUREE_CONTRAT']\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "Tensor_X_1_I = Input(shape = (len(TYPE_1),), name = 'input_1')\n",
    "\n",
    "Tensor_X_2_I = Input(shape = (len(TYPE_2),), name = 'input_2')\n",
    "\n",
    "Tensor_X_3_I = Input(shape = (len(TYPE_3),), name = 'input_3')\n",
    "Tensor_X_3 = Dense(units = 16, kernel_initializer = glorot_uniform(seed=RANDOM_SEED)) (Tensor_X_3_I)\n",
    "\n",
    "Tensor_X_4_I = Input(shape = (len(TYPE_4),), name = 'input_4')\n",
    "\n",
    "Tensor_X = Concatenate(name = 'concat') ([Tensor_X_1_I, Tensor_X_2_I, Tensor_X_3, Tensor_X_4_I])\n",
    "Tensor_X = Dense(units = 32, name = 'dense_1', kernel_initializer = glorot_uniform(seed=RANDOM_SEED), kernel_regularizer=regularizers.l1(1e-4)) (Tensor_X)\n",
    "Tensor_X = Activation('relu', name = 'relu') (Tensor_X)\n",
    "Tensor_X = Dropout(0.4, seed = RANDOM_SEED, name = 'dropout') (Tensor_X)\n",
    "Tensor_X = Dense(units = 1, name = 'dense_2', kernel_initializer = glorot_uniform(seed=RANDOM_SEED), kernel_regularizer=regularizers.l1(1e-5)) (Tensor_X)\n",
    "Tensor_X = Activation('sigmoid') (Tensor_X)\n",
    "\n",
    "model_5 = Model(inputs = [Tensor_X_1_I, Tensor_X_2_I, Tensor_X_3_I, Tensor_X_4_I], outputs = Tensor_X)\n",
    "model_5.summary()\n",
    "\n",
    "# 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eb8fce1898>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1008 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(model_5, to_file='model5.png')\n",
    "\n",
    "plt.figure(figsize = (14,14))\n",
    "plt.imshow(plt.imread('model5.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4059 samples, validate on 1015 samples\n",
      "Epoch 1/1000\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 0.5705 - auc: 0.3144 - val_loss: 0.4608 - val_auc: 0.3381\n",
      "Epoch 2/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.4480 - auc: 0.3429 - val_loss: 0.3569 - val_auc: 0.3493\n",
      "Epoch 3/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.3473 - auc: 0.3561 - val_loss: 0.2845 - val_auc: 0.3689\n",
      "Epoch 4/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.2786 - auc: 0.3659 - val_loss: 0.2352 - val_auc: 0.3692\n",
      "Epoch 5/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.2283 - auc: 0.3690 - val_loss: 0.2017 - val_auc: 0.3749\n",
      "Epoch 6/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.1925 - auc: 0.3810 - val_loss: 0.1788 - val_auc: 0.3861\n",
      "Epoch 7/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.1718 - auc: 0.3879 - val_loss: 0.1630 - val_auc: 0.3940\n",
      "Epoch 8/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.1477 - auc: 0.3987 - val_loss: 0.1520 - val_auc: 0.4063\n",
      "Epoch 9/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.1375 - auc: 0.4090 - val_loss: 0.1439 - val_auc: 0.4120\n",
      "Epoch 10/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.1307 - auc: 0.4123 - val_loss: 0.1383 - val_auc: 0.4153\n",
      "Epoch 11/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.1260 - auc: 0.4157 - val_loss: 0.1343 - val_auc: 0.4195\n",
      "Epoch 12/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.1072 - auc: 0.4218 - val_loss: 0.1311 - val_auc: 0.4263\n",
      "Epoch 13/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.1102 - auc: 0.4281 - val_loss: 0.1287 - val_auc: 0.4318\n",
      "Epoch 14/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0980 - auc: 0.4355 - val_loss: 0.1274 - val_auc: 0.4402\n",
      "Epoch 15/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0977 - auc: 0.4405 - val_loss: 0.1263 - val_auc: 0.4447\n",
      "Epoch 16/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0878 - auc: 0.4472 - val_loss: 0.1259 - val_auc: 0.4517\n",
      "Epoch 17/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0945 - auc: 0.4526 - val_loss: 0.1253 - val_auc: 0.4555\n",
      "Epoch 18/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0951 - auc: 0.4560 - val_loss: 0.1246 - val_auc: 0.4585\n",
      "Epoch 19/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0928 - auc: 0.4597 - val_loss: 0.1242 - val_auc: 0.4630\n",
      "Epoch 20/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0927 - auc: 0.4633 - val_loss: 0.1237 - val_auc: 0.4659\n",
      "Epoch 21/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0878 - auc: 0.4666 - val_loss: 0.1229 - val_auc: 0.4689\n",
      "Epoch 22/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0907 - auc: 0.4695 - val_loss: 0.1222 - val_auc: 0.4713\n",
      "Epoch 23/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0874 - auc: 0.4726 - val_loss: 0.1220 - val_auc: 0.4752\n",
      "Epoch 24/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0847 - auc: 0.4754 - val_loss: 0.1214 - val_auc: 0.4769\n",
      "Epoch 25/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0827 - auc: 0.4780 - val_loss: 0.1211 - val_auc: 0.4801\n",
      "Epoch 26/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0854 - auc: 0.4806 - val_loss: 0.1203 - val_auc: 0.4825\n",
      "Epoch 27/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0761 - auc: 0.4849 - val_loss: 0.1199 - val_auc: 0.4880\n",
      "Epoch 28/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0794 - auc: 0.4891 - val_loss: 0.1199 - val_auc: 0.4918\n",
      "Epoch 29/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0831 - auc: 0.4926 - val_loss: 0.1199 - val_auc: 0.4942\n",
      "Epoch 30/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0797 - auc: 0.4956 - val_loss: 0.1197 - val_auc: 0.4981\n",
      "Epoch 31/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0728 - auc: 0.5007 - val_loss: 0.1198 - val_auc: 0.5028\n",
      "Epoch 32/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0776 - auc: 0.5043 - val_loss: 0.1194 - val_auc: 0.5066\n",
      "Epoch 33/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0785 - auc: 0.5078 - val_loss: 0.1192 - val_auc: 0.5090\n",
      "Epoch 34/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0786 - auc: 0.5101 - val_loss: 0.1186 - val_auc: 0.5114\n",
      "Epoch 35/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0763 - auc: 0.5126 - val_loss: 0.1182 - val_auc: 0.5143\n",
      "Epoch 36/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0752 - auc: 0.5153 - val_loss: 0.1176 - val_auc: 0.5173\n",
      "Epoch 37/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0743 - auc: 0.5184 - val_loss: 0.1175 - val_auc: 0.5204\n",
      "Epoch 38/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0776 - auc: 0.5217 - val_loss: 0.1173 - val_auc: 0.5230\n",
      "Epoch 39/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0784 - auc: 0.5238 - val_loss: 0.1169 - val_auc: 0.5246\n",
      "Epoch 40/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0685 - auc: 0.5258 - val_loss: 0.1171 - val_auc: 0.5279\n",
      "Epoch 41/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0706 - auc: 0.5293 - val_loss: 0.1173 - val_auc: 0.5309\n",
      "Epoch 42/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0725 - auc: 0.5317 - val_loss: 0.1171 - val_auc: 0.5333\n",
      "Epoch 43/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0706 - auc: 0.5345 - val_loss: 0.1170 - val_auc: 0.5363\n",
      "Epoch 44/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0749 - auc: 0.5370 - val_loss: 0.1171 - val_auc: 0.5381\n",
      "Epoch 45/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0711 - auc: 0.5389 - val_loss: 0.1170 - val_auc: 0.5405\n",
      "Epoch 46/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0708 - auc: 0.5413 - val_loss: 0.1169 - val_auc: 0.5427\n",
      "Epoch 47/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0698 - auc: 0.5438 - val_loss: 0.1168 - val_auc: 0.5453\n",
      "Epoch 48/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0714 - auc: 0.5462 - val_loss: 0.1169 - val_auc: 0.5476\n",
      "Epoch 49/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0698 - auc: 0.5486 - val_loss: 0.1169 - val_auc: 0.5501\n",
      "Epoch 50/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0686 - auc: 0.5514 - val_loss: 0.1170 - val_auc: 0.5528\n",
      "Epoch 51/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0710 - auc: 0.5538 - val_loss: 0.1168 - val_auc: 0.5545\n",
      "Epoch 52/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0691 - auc: 0.5552 - val_loss: 0.1161 - val_auc: 0.5563\n",
      "Epoch 53/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0721 - auc: 0.5569 - val_loss: 0.1158 - val_auc: 0.5578\n",
      "Epoch 54/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0678 - auc: 0.5585 - val_loss: 0.1153 - val_auc: 0.5595\n",
      "Epoch 55/1000\n",
      "4059/4059 [==============================] - 0s 44us/step - loss: 0.0681 - auc: 0.5604 - val_loss: 0.1152 - val_auc: 0.5616\n",
      "Epoch 56/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0728 - auc: 0.5620 - val_loss: 0.1152 - val_auc: 0.5625\n",
      "Epoch 57/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0685 - auc: 0.5633 - val_loss: 0.1151 - val_auc: 0.5641\n",
      "Epoch 58/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0718 - auc: 0.5644 - val_loss: 0.1150 - val_auc: 0.5651\n",
      "Epoch 59/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0663 - auc: 0.5656 - val_loss: 0.1151 - val_auc: 0.5669\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0716 - auc: 0.5673 - val_loss: 0.1151 - val_auc: 0.5680\n",
      "Epoch 61/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0659 - auc: 0.5689 - val_loss: 0.1156 - val_auc: 0.5700\n",
      "Epoch 62/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0689 - auc: 0.5707 - val_loss: 0.1156 - val_auc: 0.5716\n",
      "Epoch 63/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0698 - auc: 0.5722 - val_loss: 0.1156 - val_auc: 0.5729\n",
      "Epoch 64/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0700 - auc: 0.5734 - val_loss: 0.1158 - val_auc: 0.5744\n",
      "Epoch 65/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0676 - auc: 0.5750 - val_loss: 0.1160 - val_auc: 0.5756\n",
      "Epoch 66/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0658 - auc: 0.5760 - val_loss: 0.1155 - val_auc: 0.5768\n",
      "Epoch 67/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0694 - auc: 0.5773 - val_loss: 0.1158 - val_auc: 0.5777\n",
      "Epoch 68/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0690 - auc: 0.5782 - val_loss: 0.1159 - val_auc: 0.5789\n",
      "Epoch 69/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0660 - auc: 0.5794 - val_loss: 0.1160 - val_auc: 0.5805\n",
      "Epoch 70/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0650 - auc: 0.5811 - val_loss: 0.1166 - val_auc: 0.5820\n",
      "Epoch 71/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0673 - auc: 0.5824 - val_loss: 0.1166 - val_auc: 0.5831\n",
      "Epoch 72/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0682 - auc: 0.5832 - val_loss: 0.1159 - val_auc: 0.5839\n",
      "Epoch 73/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0661 - auc: 0.5843 - val_loss: 0.1158 - val_auc: 0.5851\n",
      "Epoch 74/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0640 - auc: 0.5856 - val_loss: 0.1163 - val_auc: 0.5864\n",
      "Epoch 75/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0672 - auc: 0.5869 - val_loss: 0.1165 - val_auc: 0.5875\n",
      "Epoch 76/1000\n",
      "4059/4059 [==============================] - 0s 43us/step - loss: 0.0644 - auc: 0.5878 - val_loss: 0.1157 - val_auc: 0.5886\n",
      "Epoch 77/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0670 - auc: 0.5889 - val_loss: 0.1155 - val_auc: 0.5895\n",
      "Epoch 78/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0652 - auc: 0.5900 - val_loss: 0.1154 - val_auc: 0.5907\n",
      "Epoch 79/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0639 - auc: 0.5911 - val_loss: 0.1155 - val_auc: 0.5919\n",
      "Epoch 80/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0634 - auc: 0.5923 - val_loss: 0.1160 - val_auc: 0.5930\n",
      "Epoch 81/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0617 - auc: 0.5935 - val_loss: 0.1161 - val_auc: 0.5943\n",
      "Epoch 82/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0657 - auc: 0.5946 - val_loss: 0.1155 - val_auc: 0.5951\n",
      "Epoch 83/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0653 - auc: 0.5953 - val_loss: 0.1152 - val_auc: 0.5960\n",
      "Epoch 84/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0644 - auc: 0.5965 - val_loss: 0.1152 - val_auc: 0.5972\n",
      "Epoch 85/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0665 - auc: 0.5975 - val_loss: 0.1154 - val_auc: 0.5978\n",
      "Epoch 86/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0656 - auc: 0.5982 - val_loss: 0.1153 - val_auc: 0.5987\n",
      "Epoch 87/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0642 - auc: 0.5990 - val_loss: 0.1149 - val_auc: 0.5995\n",
      "Epoch 88/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0688 - auc: 0.5995 - val_loss: 0.1146 - val_auc: 0.5998\n",
      "Epoch 89/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0656 - auc: 0.6000 - val_loss: 0.1144 - val_auc: 0.6003\n",
      "Epoch 90/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0649 - auc: 0.6006 - val_loss: 0.1143 - val_auc: 0.6012\n",
      "Epoch 91/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0640 - auc: 0.6016 - val_loss: 0.1146 - val_auc: 0.6022\n",
      "Epoch 92/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0615 - auc: 0.6026 - val_loss: 0.1145 - val_auc: 0.6033\n",
      "Epoch 93/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0606 - auc: 0.6038 - val_loss: 0.1148 - val_auc: 0.6044\n",
      "Epoch 94/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0645 - auc: 0.6045 - val_loss: 0.1148 - val_auc: 0.6050\n",
      "Epoch 95/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0629 - auc: 0.6054 - val_loss: 0.1143 - val_auc: 0.6058\n",
      "Epoch 96/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0642 - auc: 0.6061 - val_loss: 0.1142 - val_auc: 0.6065\n",
      "Epoch 97/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0607 - auc: 0.6069 - val_loss: 0.1143 - val_auc: 0.6074\n",
      "Epoch 98/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0655 - auc: 0.6076 - val_loss: 0.1145 - val_auc: 0.6079\n",
      "Epoch 99/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0616 - auc: 0.6084 - val_loss: 0.1142 - val_auc: 0.6089\n",
      "Epoch 100/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0660 - auc: 0.6090 - val_loss: 0.1141 - val_auc: 0.6093\n",
      "Epoch 101/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0661 - auc: 0.6094 - val_loss: 0.1138 - val_auc: 0.6097\n",
      "Epoch 102/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0598 - auc: 0.6101 - val_loss: 0.1140 - val_auc: 0.6106\n",
      "Epoch 103/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0634 - auc: 0.6109 - val_loss: 0.1142 - val_auc: 0.6112\n",
      "Epoch 104/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0616 - auc: 0.6116 - val_loss: 0.1141 - val_auc: 0.6122\n",
      "Epoch 105/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0636 - auc: 0.6123 - val_loss: 0.1138 - val_auc: 0.6127\n",
      "Epoch 106/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0615 - auc: 0.6131 - val_loss: 0.1139 - val_auc: 0.6136\n",
      "Epoch 107/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0642 - auc: 0.6137 - val_loss: 0.1137 - val_auc: 0.6140\n",
      "Epoch 108/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0603 - auc: 0.6142 - val_loss: 0.1135 - val_auc: 0.6147\n",
      "Epoch 109/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0631 - auc: 0.6149 - val_loss: 0.1135 - val_auc: 0.6151\n",
      "Epoch 110/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0610 - auc: 0.6153 - val_loss: 0.1131 - val_auc: 0.6159\n",
      "Epoch 111/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0636 - auc: 0.6160 - val_loss: 0.1133 - val_auc: 0.6163\n",
      "Epoch 112/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0616 - auc: 0.6166 - val_loss: 0.1132 - val_auc: 0.6170\n",
      "Epoch 113/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0622 - auc: 0.6172 - val_loss: 0.1132 - val_auc: 0.6177\n",
      "Epoch 114/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0614 - auc: 0.6180 - val_loss: 0.1133 - val_auc: 0.6183\n",
      "Epoch 115/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0604 - auc: 0.6187 - val_loss: 0.1135 - val_auc: 0.6191\n",
      "Epoch 116/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0605 - auc: 0.6194 - val_loss: 0.1134 - val_auc: 0.6196\n",
      "Epoch 117/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0612 - auc: 0.6198 - val_loss: 0.1130 - val_auc: 0.6201\n",
      "Epoch 118/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0589 - auc: 0.6204 - val_loss: 0.1128 - val_auc: 0.6209\n",
      "Epoch 119/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0635 - auc: 0.6211 - val_loss: 0.1133 - val_auc: 0.6212\n",
      "Epoch 120/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0628 - auc: 0.6213 - val_loss: 0.1126 - val_auc: 0.6216\n",
      "Epoch 121/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0611 - auc: 0.6217 - val_loss: 0.1128 - val_auc: 0.6221\n",
      "Epoch 122/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0608 - auc: 0.6223 - val_loss: 0.1136 - val_auc: 0.6227\n",
      "Epoch 123/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0614 - auc: 0.6229 - val_loss: 0.1138 - val_auc: 0.6232\n",
      "Epoch 124/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0610 - auc: 0.6234 - val_loss: 0.1134 - val_auc: 0.6236\n",
      "Epoch 125/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0596 - auc: 0.6239 - val_loss: 0.1137 - val_auc: 0.6243\n",
      "Epoch 126/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0605 - auc: 0.6245 - val_loss: 0.1137 - val_auc: 0.6248\n",
      "Epoch 127/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0646 - auc: 0.6249 - val_loss: 0.1133 - val_auc: 0.6250\n",
      "Epoch 128/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0596 - auc: 0.6252 - val_loss: 0.1134 - val_auc: 0.6256\n",
      "Epoch 129/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0594 - auc: 0.6258 - val_loss: 0.1135 - val_auc: 0.6261\n",
      "Epoch 130/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0583 - auc: 0.6264 - val_loss: 0.1135 - val_auc: 0.6269\n",
      "Epoch 131/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0607 - auc: 0.6271 - val_loss: 0.1135 - val_auc: 0.6273\n",
      "Epoch 132/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0612 - auc: 0.6275 - val_loss: 0.1133 - val_auc: 0.6277\n",
      "Epoch 133/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0606 - auc: 0.6278 - val_loss: 0.1129 - val_auc: 0.6279\n",
      "Epoch 134/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0581 - auc: 0.6281 - val_loss: 0.1122 - val_auc: 0.6284\n",
      "Epoch 135/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0601 - auc: 0.6286 - val_loss: 0.1123 - val_auc: 0.6289\n",
      "Epoch 136/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0600 - auc: 0.6290 - val_loss: 0.1121 - val_auc: 0.6293\n",
      "Epoch 137/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0583 - auc: 0.6296 - val_loss: 0.1125 - val_auc: 0.6299\n",
      "Epoch 138/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0603 - auc: 0.6300 - val_loss: 0.1127 - val_auc: 0.6302\n",
      "Epoch 139/1000\n",
      "4059/4059 [==============================] - 0s 42us/step - loss: 0.0591 - auc: 0.6303 - val_loss: 0.1124 - val_auc: 0.6306\n",
      "Epoch 140/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0593 - auc: 0.6307 - val_loss: 0.1124 - val_auc: 0.6310\n",
      "Epoch 141/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0583 - auc: 0.6311 - val_loss: 0.1126 - val_auc: 0.6314\n",
      "Epoch 142/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0596 - auc: 0.6315 - val_loss: 0.1124 - val_auc: 0.6319\n",
      "Epoch 143/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0613 - auc: 0.6320 - val_loss: 0.1121 - val_auc: 0.6322\n",
      "Epoch 144/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0613 - auc: 0.6323 - val_loss: 0.1116 - val_auc: 0.6324\n",
      "Epoch 145/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0577 - auc: 0.6327 - val_loss: 0.1120 - val_auc: 0.6329\n",
      "Epoch 146/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0593 - auc: 0.6331 - val_loss: 0.1120 - val_auc: 0.6333\n",
      "Epoch 147/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0587 - auc: 0.6333 - val_loss: 0.1117 - val_auc: 0.6336\n",
      "Epoch 148/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0604 - auc: 0.6338 - val_loss: 0.1119 - val_auc: 0.6340\n",
      "Epoch 149/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0593 - auc: 0.6341 - val_loss: 0.1115 - val_auc: 0.6343\n",
      "Epoch 150/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0565 - auc: 0.6346 - val_loss: 0.1120 - val_auc: 0.6349\n",
      "Epoch 151/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0568 - auc: 0.6351 - val_loss: 0.1124 - val_auc: 0.6353\n",
      "Epoch 152/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0585 - auc: 0.6354 - val_loss: 0.1121 - val_auc: 0.6356\n",
      "Epoch 153/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0581 - auc: 0.6358 - val_loss: 0.1115 - val_auc: 0.6361\n",
      "Epoch 154/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0598 - auc: 0.6363 - val_loss: 0.1113 - val_auc: 0.6366\n",
      "Epoch 155/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0574 - auc: 0.6369 - val_loss: 0.1115 - val_auc: 0.6372\n",
      "Epoch 156/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0600 - auc: 0.6372 - val_loss: 0.1113 - val_auc: 0.6374\n",
      "Epoch 157/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0597 - auc: 0.6376 - val_loss: 0.1114 - val_auc: 0.6377\n",
      "Epoch 158/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0569 - auc: 0.6380 - val_loss: 0.1113 - val_auc: 0.6382\n",
      "Epoch 159/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0606 - auc: 0.6383 - val_loss: 0.1109 - val_auc: 0.6385\n",
      "Epoch 160/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0586 - auc: 0.6387 - val_loss: 0.1108 - val_auc: 0.6389\n",
      "Epoch 161/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0578 - auc: 0.6391 - val_loss: 0.1112 - val_auc: 0.6393\n",
      "Epoch 162/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0586 - auc: 0.6395 - val_loss: 0.1112 - val_auc: 0.6397\n",
      "Epoch 163/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0592 - auc: 0.6398 - val_loss: 0.1110 - val_auc: 0.6400\n",
      "Epoch 164/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0605 - auc: 0.6400 - val_loss: 0.1106 - val_auc: 0.6402\n",
      "Epoch 165/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0593 - auc: 0.6404 - val_loss: 0.1105 - val_auc: 0.6405\n",
      "Epoch 166/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0593 - auc: 0.6406 - val_loss: 0.1103 - val_auc: 0.6408\n",
      "Epoch 167/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0595 - auc: 0.6409 - val_loss: 0.1100 - val_auc: 0.6411\n",
      "Epoch 168/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0579 - auc: 0.6413 - val_loss: 0.1106 - val_auc: 0.6414\n",
      "Epoch 169/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0613 - auc: 0.6414 - val_loss: 0.1103 - val_auc: 0.6416\n",
      "Epoch 170/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0595 - auc: 0.6416 - val_loss: 0.1095 - val_auc: 0.6418\n",
      "Epoch 171/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0579 - auc: 0.6420 - val_loss: 0.1098 - val_auc: 0.6422\n",
      "Epoch 172/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0545 - auc: 0.6424 - val_loss: 0.1102 - val_auc: 0.6427\n",
      "Epoch 173/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0567 - auc: 0.6430 - val_loss: 0.1103 - val_auc: 0.6433\n",
      "Epoch 174/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0592 - auc: 0.6434 - val_loss: 0.1100 - val_auc: 0.6436\n",
      "Epoch 175/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0578 - auc: 0.6438 - val_loss: 0.1096 - val_auc: 0.6440\n",
      "Epoch 176/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0605 - auc: 0.6441 - val_loss: 0.1094 - val_auc: 0.6443\n",
      "Epoch 177/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0574 - auc: 0.6445 - val_loss: 0.1097 - val_auc: 0.6447\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0600 - auc: 0.6448 - val_loss: 0.1098 - val_auc: 0.6450\n",
      "Epoch 179/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0587 - auc: 0.6451 - val_loss: 0.1096 - val_auc: 0.6453\n",
      "Epoch 180/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0577 - auc: 0.6454 - val_loss: 0.1094 - val_auc: 0.6456\n",
      "Epoch 181/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0582 - auc: 0.6457 - val_loss: 0.1096 - val_auc: 0.6459\n",
      "Epoch 182/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0565 - auc: 0.6460 - val_loss: 0.1094 - val_auc: 0.6462\n",
      "Epoch 183/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0564 - auc: 0.6464 - val_loss: 0.1096 - val_auc: 0.6466\n",
      "Epoch 184/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0571 - auc: 0.6468 - val_loss: 0.1099 - val_auc: 0.6469\n",
      "Epoch 185/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0581 - auc: 0.6471 - val_loss: 0.1097 - val_auc: 0.6472\n",
      "Epoch 186/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0574 - auc: 0.6474 - val_loss: 0.1094 - val_auc: 0.6475\n",
      "Epoch 187/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0570 - auc: 0.6477 - val_loss: 0.1095 - val_auc: 0.6479\n",
      "Epoch 188/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0550 - auc: 0.6481 - val_loss: 0.1098 - val_auc: 0.6483\n",
      "Epoch 189/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0544 - auc: 0.6485 - val_loss: 0.1101 - val_auc: 0.6489\n",
      "Epoch 190/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0579 - auc: 0.6489 - val_loss: 0.1097 - val_auc: 0.6491\n",
      "Epoch 191/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0546 - auc: 0.6493 - val_loss: 0.1096 - val_auc: 0.6496\n",
      "Epoch 192/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0572 - auc: 0.6497 - val_loss: 0.1098 - val_auc: 0.6499\n",
      "Epoch 193/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0568 - auc: 0.6501 - val_loss: 0.1097 - val_auc: 0.6502\n",
      "Epoch 194/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0563 - auc: 0.6505 - val_loss: 0.1100 - val_auc: 0.6506\n",
      "Epoch 195/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0609 - auc: 0.6506 - val_loss: 0.1093 - val_auc: 0.6507\n",
      "Epoch 196/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0564 - auc: 0.6508 - val_loss: 0.1090 - val_auc: 0.6510\n",
      "Epoch 197/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0565 - auc: 0.6510 - val_loss: 0.1087 - val_auc: 0.6513\n",
      "Epoch 198/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0594 - auc: 0.6513 - val_loss: 0.1085 - val_auc: 0.6514\n",
      "Epoch 199/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0562 - auc: 0.6516 - val_loss: 0.1082 - val_auc: 0.6517\n",
      "Epoch 200/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0562 - auc: 0.6518 - val_loss: 0.1086 - val_auc: 0.6520\n",
      "Epoch 201/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0607 - auc: 0.6520 - val_loss: 0.1082 - val_auc: 0.6522\n",
      "Epoch 202/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0558 - auc: 0.6523 - val_loss: 0.1082 - val_auc: 0.6525\n",
      "Epoch 203/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0555 - auc: 0.6527 - val_loss: 0.1080 - val_auc: 0.6529\n",
      "Epoch 204/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0554 - auc: 0.6530 - val_loss: 0.1083 - val_auc: 0.6532\n",
      "Epoch 205/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0554 - auc: 0.6533 - val_loss: 0.1089 - val_auc: 0.6535\n",
      "Epoch 206/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0562 - auc: 0.6536 - val_loss: 0.1090 - val_auc: 0.6538\n",
      "Epoch 207/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0584 - auc: 0.6539 - val_loss: 0.1089 - val_auc: 0.6540\n",
      "Epoch 208/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0575 - auc: 0.6542 - val_loss: 0.1080 - val_auc: 0.6543\n",
      "Epoch 209/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0571 - auc: 0.6544 - val_loss: 0.1076 - val_auc: 0.6545\n",
      "Epoch 210/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0550 - auc: 0.6547 - val_loss: 0.1083 - val_auc: 0.6549\n",
      "Epoch 211/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0569 - auc: 0.6550 - val_loss: 0.1081 - val_auc: 0.6552\n",
      "Epoch 212/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0554 - auc: 0.6553 - val_loss: 0.1081 - val_auc: 0.6555\n",
      "Epoch 213/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0579 - auc: 0.6556 - val_loss: 0.1082 - val_auc: 0.6558\n",
      "Epoch 214/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0589 - auc: 0.6558 - val_loss: 0.1078 - val_auc: 0.6559\n",
      "Epoch 215/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0566 - auc: 0.6560 - val_loss: 0.1078 - val_auc: 0.6561\n",
      "Epoch 216/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0562 - auc: 0.6562 - val_loss: 0.1079 - val_auc: 0.6564\n",
      "Epoch 217/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0565 - auc: 0.6565 - val_loss: 0.1081 - val_auc: 0.6567\n",
      "Epoch 218/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0549 - auc: 0.6568 - val_loss: 0.1078 - val_auc: 0.6570\n",
      "Epoch 219/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0571 - auc: 0.6570 - val_loss: 0.1075 - val_auc: 0.6572\n",
      "Epoch 220/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0574 - auc: 0.6573 - val_loss: 0.1076 - val_auc: 0.6574\n",
      "Epoch 221/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0570 - auc: 0.6575 - val_loss: 0.1074 - val_auc: 0.6577\n",
      "Epoch 222/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0558 - auc: 0.6578 - val_loss: 0.1071 - val_auc: 0.6580\n",
      "Epoch 223/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0550 - auc: 0.6581 - val_loss: 0.1076 - val_auc: 0.6583\n",
      "Epoch 224/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0569 - auc: 0.6584 - val_loss: 0.1073 - val_auc: 0.6586\n",
      "Epoch 225/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0567 - auc: 0.6586 - val_loss: 0.1070 - val_auc: 0.6587\n",
      "Epoch 226/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0553 - auc: 0.6588 - val_loss: 0.1072 - val_auc: 0.6590\n",
      "Epoch 227/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0558 - auc: 0.6591 - val_loss: 0.1077 - val_auc: 0.6593\n",
      "Epoch 228/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0530 - auc: 0.6594 - val_loss: 0.1078 - val_auc: 0.6597\n",
      "Epoch 229/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0591 - auc: 0.6597 - val_loss: 0.1077 - val_auc: 0.6598\n",
      "Epoch 230/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0562 - auc: 0.6598 - val_loss: 0.1076 - val_auc: 0.6600\n",
      "Epoch 231/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0566 - auc: 0.6600 - val_loss: 0.1076 - val_auc: 0.6601\n",
      "Epoch 232/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0554 - auc: 0.6602 - val_loss: 0.1073 - val_auc: 0.6603\n",
      "Epoch 233/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0592 - auc: 0.6603 - val_loss: 0.1071 - val_auc: 0.6603\n",
      "Epoch 234/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0574 - auc: 0.6603 - val_loss: 0.1064 - val_auc: 0.6604\n",
      "Epoch 235/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0534 - auc: 0.6605 - val_loss: 0.1070 - val_auc: 0.6608\n",
      "Epoch 236/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0558 - auc: 0.6608 - val_loss: 0.1076 - val_auc: 0.6609\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0550 - auc: 0.6610 - val_loss: 0.1078 - val_auc: 0.6612\n",
      "Epoch 238/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0571 - auc: 0.6612 - val_loss: 0.1073 - val_auc: 0.6613\n",
      "Epoch 239/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0562 - auc: 0.6614 - val_loss: 0.1068 - val_auc: 0.6615\n",
      "Epoch 240/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0580 - auc: 0.6615 - val_loss: 0.1064 - val_auc: 0.6615\n",
      "Epoch 241/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0576 - auc: 0.6615 - val_loss: 0.1061 - val_auc: 0.6617\n",
      "Epoch 242/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0551 - auc: 0.6618 - val_loss: 0.1062 - val_auc: 0.6620\n",
      "Epoch 243/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0548 - auc: 0.6621 - val_loss: 0.1067 - val_auc: 0.6622\n",
      "Epoch 244/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0564 - auc: 0.6623 - val_loss: 0.1068 - val_auc: 0.6624\n",
      "Epoch 245/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0566 - auc: 0.6624 - val_loss: 0.1063 - val_auc: 0.6625\n",
      "Epoch 246/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0541 - auc: 0.6627 - val_loss: 0.1066 - val_auc: 0.6628\n",
      "Epoch 247/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0550 - auc: 0.6629 - val_loss: 0.1070 - val_auc: 0.6631\n",
      "Epoch 248/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0547 - auc: 0.6632 - val_loss: 0.1073 - val_auc: 0.6633\n",
      "Epoch 249/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0574 - auc: 0.6633 - val_loss: 0.1068 - val_auc: 0.6633\n",
      "Epoch 250/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0575 - auc: 0.6634 - val_loss: 0.1064 - val_auc: 0.6634\n",
      "Epoch 251/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0557 - auc: 0.6635 - val_loss: 0.1066 - val_auc: 0.6636\n",
      "Epoch 252/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0532 - auc: 0.6637 - val_loss: 0.1065 - val_auc: 0.6639\n",
      "Epoch 253/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0553 - auc: 0.6639 - val_loss: 0.1067 - val_auc: 0.6640\n",
      "Epoch 254/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0548 - auc: 0.6641 - val_loss: 0.1067 - val_auc: 0.6642\n",
      "Epoch 255/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0548 - auc: 0.6643 - val_loss: 0.1067 - val_auc: 0.6644\n",
      "Epoch 256/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0551 - auc: 0.6645 - val_loss: 0.1070 - val_auc: 0.6647\n",
      "Epoch 257/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0552 - auc: 0.6648 - val_loss: 0.1067 - val_auc: 0.6648\n",
      "Epoch 258/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0547 - auc: 0.6648 - val_loss: 0.1060 - val_auc: 0.6650\n",
      "Epoch 259/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0536 - auc: 0.6651 - val_loss: 0.1063 - val_auc: 0.6652\n",
      "Epoch 260/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0551 - auc: 0.6653 - val_loss: 0.1068 - val_auc: 0.6654\n",
      "Epoch 261/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0524 - auc: 0.6656 - val_loss: 0.1077 - val_auc: 0.6658\n",
      "Epoch 262/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0546 - auc: 0.6659 - val_loss: 0.1078 - val_auc: 0.6660\n",
      "Epoch 263/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0539 - auc: 0.6661 - val_loss: 0.1073 - val_auc: 0.6663\n",
      "Epoch 264/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0550 - auc: 0.6663 - val_loss: 0.1068 - val_auc: 0.6664\n",
      "Epoch 265/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0549 - auc: 0.6665 - val_loss: 0.1064 - val_auc: 0.6666\n",
      "Epoch 266/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0552 - auc: 0.6666 - val_loss: 0.1066 - val_auc: 0.6668\n",
      "Epoch 267/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0542 - auc: 0.6668 - val_loss: 0.1070 - val_auc: 0.6670\n",
      "Epoch 268/1000\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 0.0553 - auc: 0.667 - 0s 32us/step - loss: 0.0542 - auc: 0.6670 - val_loss: 0.1066 - val_auc: 0.6671\n",
      "Epoch 269/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0545 - auc: 0.6672 - val_loss: 0.1063 - val_auc: 0.6674\n",
      "Epoch 270/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0551 - auc: 0.6674 - val_loss: 0.1062 - val_auc: 0.6676\n",
      "Epoch 271/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0553 - auc: 0.6677 - val_loss: 0.1067 - val_auc: 0.6677\n",
      "Epoch 272/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0561 - auc: 0.6678 - val_loss: 0.1067 - val_auc: 0.6678\n",
      "Epoch 273/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0584 - auc: 0.6678 - val_loss: 0.1056 - val_auc: 0.6679\n",
      "Epoch 274/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0551 - auc: 0.6679 - val_loss: 0.1055 - val_auc: 0.6681\n",
      "Epoch 275/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0548 - auc: 0.6681 - val_loss: 0.1060 - val_auc: 0.6682\n",
      "Epoch 276/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0544 - auc: 0.6683 - val_loss: 0.1062 - val_auc: 0.6684\n",
      "Epoch 277/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0552 - auc: 0.6685 - val_loss: 0.1060 - val_auc: 0.6686\n",
      "Epoch 278/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0553 - auc: 0.6687 - val_loss: 0.1060 - val_auc: 0.6688\n",
      "Epoch 279/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0563 - auc: 0.6689 - val_loss: 0.1057 - val_auc: 0.6689\n",
      "Epoch 280/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0531 - auc: 0.6690 - val_loss: 0.1056 - val_auc: 0.6691\n",
      "Epoch 281/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0546 - auc: 0.6692 - val_loss: 0.1056 - val_auc: 0.6693\n",
      "Epoch 282/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0566 - auc: 0.6693 - val_loss: 0.1055 - val_auc: 0.6694\n",
      "Epoch 283/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0558 - auc: 0.6694 - val_loss: 0.1054 - val_auc: 0.6696\n",
      "Epoch 284/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0547 - auc: 0.6696 - val_loss: 0.1056 - val_auc: 0.6697\n",
      "Epoch 285/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0556 - auc: 0.6698 - val_loss: 0.1059 - val_auc: 0.6699\n",
      "Epoch 286/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0557 - auc: 0.6699 - val_loss: 0.1060 - val_auc: 0.6699\n",
      "Epoch 287/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0543 - auc: 0.6700 - val_loss: 0.1056 - val_auc: 0.6702\n",
      "Epoch 288/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0566 - auc: 0.6702 - val_loss: 0.1054 - val_auc: 0.6703\n",
      "Epoch 289/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0557 - auc: 0.6703 - val_loss: 0.1056 - val_auc: 0.6704\n",
      "Epoch 290/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0558 - auc: 0.6704 - val_loss: 0.1051 - val_auc: 0.6705\n",
      "Epoch 291/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0572 - auc: 0.6705 - val_loss: 0.1048 - val_auc: 0.6706\n",
      "Epoch 292/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0555 - auc: 0.6706 - val_loss: 0.1049 - val_auc: 0.6707\n",
      "Epoch 293/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0526 - auc: 0.6708 - val_loss: 0.1054 - val_auc: 0.6709\n",
      "Epoch 294/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0534 - auc: 0.6710 - val_loss: 0.1055 - val_auc: 0.6711\n",
      "Epoch 295/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0556 - auc: 0.6712 - val_loss: 0.1053 - val_auc: 0.6712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0550 - auc: 0.6713 - val_loss: 0.1055 - val_auc: 0.6714\n",
      "Epoch 297/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0538 - auc: 0.6715 - val_loss: 0.1054 - val_auc: 0.6716\n",
      "Epoch 298/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0549 - auc: 0.6716 - val_loss: 0.1053 - val_auc: 0.6717\n",
      "Epoch 299/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0537 - auc: 0.6718 - val_loss: 0.1052 - val_auc: 0.6719\n",
      "Epoch 300/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0560 - auc: 0.6719 - val_loss: 0.1050 - val_auc: 0.6720\n",
      "Epoch 301/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0544 - auc: 0.6721 - val_loss: 0.1053 - val_auc: 0.6722\n",
      "Epoch 302/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0551 - auc: 0.6722 - val_loss: 0.1053 - val_auc: 0.6723\n",
      "Epoch 303/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0557 - auc: 0.6724 - val_loss: 0.1051 - val_auc: 0.6724\n",
      "Epoch 304/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0542 - auc: 0.6725 - val_loss: 0.1054 - val_auc: 0.6726\n",
      "Epoch 305/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0550 - auc: 0.6727 - val_loss: 0.1055 - val_auc: 0.6727\n",
      "Epoch 306/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0543 - auc: 0.6728 - val_loss: 0.1056 - val_auc: 0.6729\n",
      "Epoch 307/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0539 - auc: 0.6730 - val_loss: 0.1058 - val_auc: 0.6731\n",
      "Epoch 308/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0519 - auc: 0.6732 - val_loss: 0.1063 - val_auc: 0.6733\n",
      "Epoch 309/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0562 - auc: 0.6733 - val_loss: 0.1057 - val_auc: 0.6733\n",
      "Epoch 310/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0546 - auc: 0.6734 - val_loss: 0.1054 - val_auc: 0.6735\n",
      "Epoch 311/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0522 - auc: 0.6736 - val_loss: 0.1063 - val_auc: 0.6737\n",
      "Epoch 312/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0561 - auc: 0.6737 - val_loss: 0.1063 - val_auc: 0.6738\n",
      "Epoch 313/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0531 - auc: 0.6738 - val_loss: 0.1056 - val_auc: 0.6740\n",
      "Epoch 314/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0528 - auc: 0.6740 - val_loss: 0.1053 - val_auc: 0.6741\n",
      "Epoch 315/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0537 - auc: 0.6742 - val_loss: 0.1059 - val_auc: 0.6743\n",
      "Epoch 316/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0537 - auc: 0.6744 - val_loss: 0.1061 - val_auc: 0.6744\n",
      "Epoch 317/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0523 - auc: 0.6746 - val_loss: 0.1062 - val_auc: 0.6747\n",
      "Epoch 318/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0542 - auc: 0.6747 - val_loss: 0.1064 - val_auc: 0.6748\n",
      "Epoch 319/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0531 - auc: 0.6749 - val_loss: 0.1061 - val_auc: 0.6750\n",
      "Epoch 320/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0542 - auc: 0.6751 - val_loss: 0.1061 - val_auc: 0.6752\n",
      "Epoch 321/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0547 - auc: 0.6753 - val_loss: 0.1064 - val_auc: 0.6753\n",
      "Epoch 322/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0543 - auc: 0.6754 - val_loss: 0.1061 - val_auc: 0.6755\n",
      "Epoch 323/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0515 - auc: 0.6756 - val_loss: 0.1059 - val_auc: 0.6757\n",
      "Epoch 324/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0544 - auc: 0.6757 - val_loss: 0.1058 - val_auc: 0.6758\n",
      "Epoch 325/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0551 - auc: 0.6758 - val_loss: 0.1057 - val_auc: 0.6759\n",
      "Epoch 326/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0528 - auc: 0.6760 - val_loss: 0.1056 - val_auc: 0.6761\n",
      "Epoch 327/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0527 - auc: 0.6762 - val_loss: 0.1060 - val_auc: 0.6763\n",
      "Epoch 328/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0533 - auc: 0.6764 - val_loss: 0.1059 - val_auc: 0.6764\n",
      "Epoch 329/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0526 - auc: 0.6765 - val_loss: 0.1058 - val_auc: 0.6767\n",
      "Epoch 330/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0524 - auc: 0.6768 - val_loss: 0.1060 - val_auc: 0.6769\n",
      "Epoch 331/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0542 - auc: 0.6770 - val_loss: 0.1060 - val_auc: 0.6771\n",
      "Epoch 332/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0499 - auc: 0.6772 - val_loss: 0.1061 - val_auc: 0.6773\n",
      "Epoch 333/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0521 - auc: 0.6774 - val_loss: 0.1059 - val_auc: 0.6775\n",
      "Epoch 334/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0547 - auc: 0.6776 - val_loss: 0.1057 - val_auc: 0.6776\n",
      "Epoch 335/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0540 - auc: 0.6777 - val_loss: 0.1056 - val_auc: 0.6778\n",
      "Epoch 336/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0540 - auc: 0.6778 - val_loss: 0.1063 - val_auc: 0.6778\n",
      "Epoch 337/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0546 - auc: 0.6779 - val_loss: 0.1066 - val_auc: 0.6779\n",
      "Epoch 338/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0555 - auc: 0.6780 - val_loss: 0.1061 - val_auc: 0.6780\n",
      "Epoch 339/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0537 - auc: 0.6781 - val_loss: 0.1056 - val_auc: 0.6781\n",
      "Epoch 340/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0518 - auc: 0.6782 - val_loss: 0.1063 - val_auc: 0.6783\n",
      "Epoch 341/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0532 - auc: 0.6784 - val_loss: 0.1063 - val_auc: 0.6785\n",
      "Epoch 342/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0543 - auc: 0.6785 - val_loss: 0.1061 - val_auc: 0.6785\n",
      "Epoch 343/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0540 - auc: 0.6785 - val_loss: 0.1058 - val_auc: 0.6786\n",
      "Epoch 344/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0521 - auc: 0.6786 - val_loss: 0.1061 - val_auc: 0.6787\n",
      "Epoch 345/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0542 - auc: 0.6787 - val_loss: 0.1061 - val_auc: 0.6788\n",
      "Epoch 346/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0544 - auc: 0.6788 - val_loss: 0.1056 - val_auc: 0.6789\n",
      "Epoch 347/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0539 - auc: 0.6789 - val_loss: 0.1058 - val_auc: 0.6790\n",
      "Epoch 348/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0535 - auc: 0.6790 - val_loss: 0.1062 - val_auc: 0.6791\n",
      "Epoch 349/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0524 - auc: 0.6791 - val_loss: 0.1061 - val_auc: 0.6792\n",
      "Epoch 350/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0526 - auc: 0.6793 - val_loss: 0.1063 - val_auc: 0.6795\n",
      "Epoch 351/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0524 - auc: 0.6795 - val_loss: 0.1067 - val_auc: 0.6796\n",
      "Epoch 352/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0536 - auc: 0.6796 - val_loss: 0.1060 - val_auc: 0.6797\n",
      "Epoch 353/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0532 - auc: 0.6797 - val_loss: 0.1061 - val_auc: 0.6798\n",
      "Epoch 354/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0533 - auc: 0.6798 - val_loss: 0.1060 - val_auc: 0.6799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0540 - auc: 0.6799 - val_loss: 0.1059 - val_auc: 0.6800\n",
      "Epoch 356/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0525 - auc: 0.6801 - val_loss: 0.1060 - val_auc: 0.6802\n",
      "Epoch 357/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0544 - auc: 0.6802 - val_loss: 0.1061 - val_auc: 0.6803\n",
      "Epoch 358/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0552 - auc: 0.6803 - val_loss: 0.1059 - val_auc: 0.6803\n",
      "Epoch 359/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0542 - auc: 0.6804 - val_loss: 0.1058 - val_auc: 0.6805\n",
      "Epoch 360/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0541 - auc: 0.6805 - val_loss: 0.1060 - val_auc: 0.6806\n",
      "Epoch 361/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0541 - auc: 0.6806 - val_loss: 0.1058 - val_auc: 0.6806\n",
      "Epoch 362/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0522 - auc: 0.6807 - val_loss: 0.1056 - val_auc: 0.6809\n",
      "Epoch 363/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0556 - auc: 0.6809 - val_loss: 0.1060 - val_auc: 0.6809\n",
      "Epoch 364/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0541 - auc: 0.6810 - val_loss: 0.1061 - val_auc: 0.6810\n",
      "Epoch 365/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0536 - auc: 0.6811 - val_loss: 0.1058 - val_auc: 0.6812\n",
      "Epoch 366/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0533 - auc: 0.6812 - val_loss: 0.1060 - val_auc: 0.6812\n",
      "Epoch 367/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0507 - auc: 0.6814 - val_loss: 0.1062 - val_auc: 0.6815\n",
      "Epoch 368/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0519 - auc: 0.6815 - val_loss: 0.1061 - val_auc: 0.6816\n",
      "Epoch 369/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0535 - auc: 0.6817 - val_loss: 0.1061 - val_auc: 0.6818\n",
      "Epoch 370/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0544 - auc: 0.6818 - val_loss: 0.1062 - val_auc: 0.6819\n",
      "Epoch 371/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0537 - auc: 0.6819 - val_loss: 0.1059 - val_auc: 0.6820\n",
      "Epoch 372/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0548 - auc: 0.6820 - val_loss: 0.1056 - val_auc: 0.6821\n",
      "Epoch 373/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0532 - auc: 0.6821 - val_loss: 0.1056 - val_auc: 0.6822\n",
      "Epoch 374/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0523 - auc: 0.6822 - val_loss: 0.1057 - val_auc: 0.6823\n",
      "Epoch 375/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0514 - auc: 0.6824 - val_loss: 0.1065 - val_auc: 0.6825\n",
      "Epoch 376/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0542 - auc: 0.6825 - val_loss: 0.1064 - val_auc: 0.6826\n",
      "Epoch 377/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0538 - auc: 0.6826 - val_loss: 0.1062 - val_auc: 0.6827\n",
      "Epoch 378/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0545 - auc: 0.6827 - val_loss: 0.1055 - val_auc: 0.6828\n",
      "Epoch 379/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0539 - auc: 0.6829 - val_loss: 0.1054 - val_auc: 0.6829\n",
      "Epoch 380/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0533 - auc: 0.6830 - val_loss: 0.1061 - val_auc: 0.6831\n",
      "Epoch 381/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0515 - auc: 0.6832 - val_loss: 0.1067 - val_auc: 0.6833\n",
      "Epoch 382/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0545 - auc: 0.6833 - val_loss: 0.1058 - val_auc: 0.6833\n",
      "Epoch 383/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0551 - auc: 0.6833 - val_loss: 0.1053 - val_auc: 0.6833\n",
      "Epoch 384/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0547 - auc: 0.6834 - val_loss: 0.1053 - val_auc: 0.6834\n",
      "Epoch 385/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0548 - auc: 0.6834 - val_loss: 0.1050 - val_auc: 0.6834\n",
      "Epoch 386/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0516 - auc: 0.6835 - val_loss: 0.1056 - val_auc: 0.6835\n",
      "Epoch 387/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0526 - auc: 0.6836 - val_loss: 0.1060 - val_auc: 0.6837\n",
      "Epoch 388/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0531 - auc: 0.6837 - val_loss: 0.1057 - val_auc: 0.6838\n",
      "Epoch 389/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0532 - auc: 0.6838 - val_loss: 0.1055 - val_auc: 0.6839\n",
      "Epoch 390/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0526 - auc: 0.6839 - val_loss: 0.1056 - val_auc: 0.6840\n",
      "Epoch 391/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0542 - auc: 0.6840 - val_loss: 0.1060 - val_auc: 0.6840\n",
      "Epoch 392/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0537 - auc: 0.6840 - val_loss: 0.1061 - val_auc: 0.6841\n",
      "Epoch 393/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0522 - auc: 0.6842 - val_loss: 0.1060 - val_auc: 0.6842\n",
      "Epoch 394/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0527 - auc: 0.6842 - val_loss: 0.1056 - val_auc: 0.6843\n",
      "Epoch 395/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0532 - auc: 0.6843 - val_loss: 0.1055 - val_auc: 0.6844\n",
      "Epoch 396/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0524 - auc: 0.6844 - val_loss: 0.1058 - val_auc: 0.6845\n",
      "Epoch 397/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0524 - auc: 0.6846 - val_loss: 0.1057 - val_auc: 0.6846\n",
      "Epoch 398/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0527 - auc: 0.6846 - val_loss: 0.1054 - val_auc: 0.6847\n",
      "Epoch 399/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0526 - auc: 0.6848 - val_loss: 0.1054 - val_auc: 0.6848\n",
      "Epoch 400/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0527 - auc: 0.6849 - val_loss: 0.1058 - val_auc: 0.6850\n",
      "Epoch 401/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0522 - auc: 0.6850 - val_loss: 0.1058 - val_auc: 0.6851\n",
      "Epoch 402/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0544 - auc: 0.6852 - val_loss: 0.1055 - val_auc: 0.6852\n",
      "Epoch 403/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0533 - auc: 0.6852 - val_loss: 0.1052 - val_auc: 0.6852\n",
      "Epoch 404/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0534 - auc: 0.6853 - val_loss: 0.1053 - val_auc: 0.6853\n",
      "Epoch 405/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0534 - auc: 0.6853 - val_loss: 0.1054 - val_auc: 0.6854\n",
      "Epoch 406/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0534 - auc: 0.6854 - val_loss: 0.1059 - val_auc: 0.6855\n",
      "Epoch 407/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0517 - auc: 0.6855 - val_loss: 0.1062 - val_auc: 0.6856\n",
      "Epoch 408/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0545 - auc: 0.6856 - val_loss: 0.1060 - val_auc: 0.6857\n",
      "Epoch 409/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0506 - auc: 0.6858 - val_loss: 0.1059 - val_auc: 0.6858\n",
      "Epoch 410/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0513 - auc: 0.6859 - val_loss: 0.1058 - val_auc: 0.6860\n",
      "Epoch 411/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0527 - auc: 0.6861 - val_loss: 0.1062 - val_auc: 0.6861\n",
      "Epoch 412/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0555 - auc: 0.6861 - val_loss: 0.1058 - val_auc: 0.6861\n",
      "Epoch 413/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0510 - auc: 0.6862 - val_loss: 0.1052 - val_auc: 0.6863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0526 - auc: 0.6863 - val_loss: 0.1055 - val_auc: 0.6863\n",
      "Epoch 415/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0522 - auc: 0.6864 - val_loss: 0.1059 - val_auc: 0.6864\n",
      "Epoch 416/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0542 - auc: 0.6864 - val_loss: 0.1054 - val_auc: 0.6865\n",
      "Epoch 417/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0527 - auc: 0.6865 - val_loss: 0.1049 - val_auc: 0.6865\n",
      "Epoch 418/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0537 - auc: 0.6865 - val_loss: 0.1045 - val_auc: 0.6866\n",
      "Epoch 419/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0518 - auc: 0.6866 - val_loss: 0.1049 - val_auc: 0.6867\n",
      "Epoch 420/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0526 - auc: 0.6867 - val_loss: 0.1052 - val_auc: 0.6868\n",
      "Epoch 421/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0530 - auc: 0.6868 - val_loss: 0.1052 - val_auc: 0.6869\n",
      "Epoch 422/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0552 - auc: 0.6869 - val_loss: 0.1055 - val_auc: 0.6869\n",
      "Epoch 423/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0517 - auc: 0.6870 - val_loss: 0.1057 - val_auc: 0.6870\n",
      "Epoch 424/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0497 - auc: 0.6871 - val_loss: 0.1062 - val_auc: 0.6872\n",
      "Epoch 425/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0500 - auc: 0.6873 - val_loss: 0.1067 - val_auc: 0.6875\n",
      "Epoch 426/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0526 - auc: 0.6875 - val_loss: 0.1063 - val_auc: 0.6876\n",
      "Epoch 427/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0525 - auc: 0.6876 - val_loss: 0.1062 - val_auc: 0.6877\n",
      "Epoch 428/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0517 - auc: 0.6877 - val_loss: 0.1061 - val_auc: 0.6878\n",
      "Epoch 429/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0535 - auc: 0.6879 - val_loss: 0.1062 - val_auc: 0.6879\n",
      "Epoch 430/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0500 - auc: 0.6880 - val_loss: 0.1062 - val_auc: 0.6881\n",
      "Epoch 431/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0521 - auc: 0.6881 - val_loss: 0.1061 - val_auc: 0.6881\n",
      "Epoch 432/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0512 - auc: 0.6882 - val_loss: 0.1062 - val_auc: 0.6883\n",
      "Epoch 433/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0523 - auc: 0.6883 - val_loss: 0.1059 - val_auc: 0.6884\n",
      "Epoch 434/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0523 - auc: 0.6884 - val_loss: 0.1056 - val_auc: 0.6885\n",
      "Epoch 435/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0524 - auc: 0.6886 - val_loss: 0.1058 - val_auc: 0.6887\n",
      "Epoch 436/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0528 - auc: 0.6887 - val_loss: 0.1057 - val_auc: 0.6887\n",
      "Epoch 437/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0530 - auc: 0.6888 - val_loss: 0.1060 - val_auc: 0.6888\n",
      "Epoch 438/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0529 - auc: 0.6889 - val_loss: 0.1061 - val_auc: 0.6889\n",
      "Epoch 439/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0541 - auc: 0.6889 - val_loss: 0.1058 - val_auc: 0.6890\n",
      "Epoch 440/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0530 - auc: 0.6890 - val_loss: 0.1059 - val_auc: 0.6890\n",
      "Epoch 441/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0543 - auc: 0.6890 - val_loss: 0.1058 - val_auc: 0.6891\n",
      "Epoch 442/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0508 - auc: 0.6891 - val_loss: 0.1058 - val_auc: 0.6892\n",
      "Epoch 443/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0542 - auc: 0.6892 - val_loss: 0.1053 - val_auc: 0.6892\n",
      "Epoch 444/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0548 - auc: 0.6892 - val_loss: 0.1050 - val_auc: 0.6892\n",
      "Epoch 445/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0532 - auc: 0.6893 - val_loss: 0.1054 - val_auc: 0.6893\n",
      "Epoch 446/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0528 - auc: 0.6893 - val_loss: 0.1058 - val_auc: 0.6894\n",
      "Epoch 447/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0537 - auc: 0.6894 - val_loss: 0.1057 - val_auc: 0.6895\n",
      "Epoch 448/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0535 - auc: 0.6895 - val_loss: 0.1057 - val_auc: 0.6895\n",
      "Epoch 449/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0528 - auc: 0.6895 - val_loss: 0.1055 - val_auc: 0.6896\n",
      "Epoch 450/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0532 - auc: 0.6896 - val_loss: 0.1052 - val_auc: 0.6896\n",
      "Epoch 451/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0531 - auc: 0.6897 - val_loss: 0.1053 - val_auc: 0.6897\n",
      "Epoch 452/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0525 - auc: 0.6898 - val_loss: 0.1058 - val_auc: 0.6898\n",
      "Epoch 453/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0517 - auc: 0.6898 - val_loss: 0.1059 - val_auc: 0.6899\n",
      "Epoch 454/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0519 - auc: 0.6899 - val_loss: 0.1057 - val_auc: 0.6900\n",
      "Epoch 455/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0513 - auc: 0.6900 - val_loss: 0.1059 - val_auc: 0.6901\n",
      "Epoch 456/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0515 - auc: 0.6902 - val_loss: 0.1063 - val_auc: 0.6902\n",
      "Epoch 457/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0523 - auc: 0.6902 - val_loss: 0.1058 - val_auc: 0.6903\n",
      "Epoch 458/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0525 - auc: 0.6903 - val_loss: 0.1055 - val_auc: 0.6904\n",
      "Epoch 459/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0523 - auc: 0.6904 - val_loss: 0.1059 - val_auc: 0.6905\n",
      "Epoch 460/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0518 - auc: 0.6905 - val_loss: 0.1061 - val_auc: 0.6906\n",
      "Epoch 461/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0508 - auc: 0.6906 - val_loss: 0.1064 - val_auc: 0.6907\n",
      "Epoch 462/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0544 - auc: 0.6907 - val_loss: 0.1059 - val_auc: 0.6907\n",
      "Epoch 463/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0513 - auc: 0.6908 - val_loss: 0.1061 - val_auc: 0.6908\n",
      "Epoch 464/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0536 - auc: 0.6908 - val_loss: 0.1065 - val_auc: 0.6909\n",
      "Epoch 465/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0514 - auc: 0.6909 - val_loss: 0.1064 - val_auc: 0.6909\n",
      "Epoch 466/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0500 - auc: 0.6910 - val_loss: 0.1061 - val_auc: 0.6911\n",
      "Epoch 467/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0512 - auc: 0.6911 - val_loss: 0.1066 - val_auc: 0.6912\n",
      "Epoch 468/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0529 - auc: 0.6912 - val_loss: 0.1066 - val_auc: 0.6912\n",
      "Epoch 469/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0516 - auc: 0.6913 - val_loss: 0.1063 - val_auc: 0.6914\n",
      "Epoch 470/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0529 - auc: 0.6914 - val_loss: 0.1056 - val_auc: 0.6914\n",
      "Epoch 471/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0524 - auc: 0.6915 - val_loss: 0.1057 - val_auc: 0.6915\n",
      "Epoch 472/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0518 - auc: 0.6915 - val_loss: 0.1055 - val_auc: 0.6916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0531 - auc: 0.6916 - val_loss: 0.1058 - val_auc: 0.6916\n",
      "Epoch 474/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0504 - auc: 0.6917 - val_loss: 0.1061 - val_auc: 0.6917\n",
      "Epoch 475/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0540 - auc: 0.6917 - val_loss: 0.1058 - val_auc: 0.6918\n",
      "Epoch 476/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0504 - auc: 0.6918 - val_loss: 0.1058 - val_auc: 0.6919\n",
      "Epoch 477/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0537 - auc: 0.6919 - val_loss: 0.1060 - val_auc: 0.6919\n",
      "Epoch 478/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0531 - auc: 0.6920 - val_loss: 0.1061 - val_auc: 0.6920\n",
      "Epoch 479/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0515 - auc: 0.6920 - val_loss: 0.1064 - val_auc: 0.6921\n",
      "Epoch 480/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0539 - auc: 0.6921 - val_loss: 0.1062 - val_auc: 0.6921\n",
      "Epoch 481/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0525 - auc: 0.6922 - val_loss: 0.1056 - val_auc: 0.6922\n",
      "Epoch 482/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0522 - auc: 0.6922 - val_loss: 0.1053 - val_auc: 0.6923\n",
      "Epoch 483/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0517 - auc: 0.6923 - val_loss: 0.1060 - val_auc: 0.6924\n",
      "Epoch 484/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0535 - auc: 0.6924 - val_loss: 0.1063 - val_auc: 0.6924\n",
      "Epoch 485/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0516 - auc: 0.6925 - val_loss: 0.1057 - val_auc: 0.6925\n",
      "Epoch 486/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0525 - auc: 0.6926 - val_loss: 0.1057 - val_auc: 0.6926\n",
      "Epoch 487/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0535 - auc: 0.6926 - val_loss: 0.1055 - val_auc: 0.6927\n",
      "Epoch 488/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0524 - auc: 0.6927 - val_loss: 0.1051 - val_auc: 0.6928\n",
      "Epoch 489/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0512 - auc: 0.6928 - val_loss: 0.1055 - val_auc: 0.6929\n",
      "Epoch 490/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0537 - auc: 0.6929 - val_loss: 0.1057 - val_auc: 0.6929\n",
      "Epoch 491/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0513 - auc: 0.6930 - val_loss: 0.1061 - val_auc: 0.6930\n",
      "Epoch 492/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0511 - auc: 0.6930 - val_loss: 0.1058 - val_auc: 0.6931\n",
      "Epoch 493/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0508 - auc: 0.6932 - val_loss: 0.1063 - val_auc: 0.6932\n",
      "Epoch 494/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0530 - auc: 0.6932 - val_loss: 0.1062 - val_auc: 0.6933\n",
      "Epoch 495/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0513 - auc: 0.6933 - val_loss: 0.1062 - val_auc: 0.6933\n",
      "Epoch 496/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0537 - auc: 0.6933 - val_loss: 0.1060 - val_auc: 0.6933\n",
      "Epoch 497/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0509 - auc: 0.6934 - val_loss: 0.1065 - val_auc: 0.6934\n",
      "Epoch 498/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0529 - auc: 0.6935 - val_loss: 0.1061 - val_auc: 0.6935\n",
      "Epoch 499/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0521 - auc: 0.6935 - val_loss: 0.1057 - val_auc: 0.6935\n",
      "Epoch 500/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0512 - auc: 0.6936 - val_loss: 0.1061 - val_auc: 0.6936\n",
      "Epoch 501/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0503 - auc: 0.6937 - val_loss: 0.1063 - val_auc: 0.6938\n",
      "Epoch 502/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0522 - auc: 0.6938 - val_loss: 0.1067 - val_auc: 0.6938\n",
      "Epoch 503/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0505 - auc: 0.6939 - val_loss: 0.1070 - val_auc: 0.6940\n",
      "Epoch 504/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0530 - auc: 0.6940 - val_loss: 0.1071 - val_auc: 0.6940\n",
      "Epoch 505/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0529 - auc: 0.6940 - val_loss: 0.1064 - val_auc: 0.6941\n",
      "Epoch 506/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0531 - auc: 0.6940 - val_loss: 0.1055 - val_auc: 0.6941\n",
      "Epoch 507/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0521 - auc: 0.6941 - val_loss: 0.1055 - val_auc: 0.6941\n",
      "Epoch 508/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0523 - auc: 0.6941 - val_loss: 0.1058 - val_auc: 0.6942\n",
      "Epoch 509/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0528 - auc: 0.6942 - val_loss: 0.1060 - val_auc: 0.6943\n",
      "Epoch 510/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0526 - auc: 0.6943 - val_loss: 0.1058 - val_auc: 0.6943\n",
      "Epoch 511/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0511 - auc: 0.6944 - val_loss: 0.1056 - val_auc: 0.6944\n",
      "Epoch 512/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0534 - auc: 0.6944 - val_loss: 0.1054 - val_auc: 0.6944\n",
      "Epoch 513/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0534 - auc: 0.6944 - val_loss: 0.1052 - val_auc: 0.6944\n",
      "Epoch 514/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0510 - auc: 0.6945 - val_loss: 0.1054 - val_auc: 0.6945\n",
      "Epoch 515/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0515 - auc: 0.6946 - val_loss: 0.1057 - val_auc: 0.6946\n",
      "Epoch 516/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0522 - auc: 0.6946 - val_loss: 0.1058 - val_auc: 0.6947\n",
      "Epoch 517/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0532 - auc: 0.6946 - val_loss: 0.1055 - val_auc: 0.6947\n",
      "Epoch 518/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0521 - auc: 0.6947 - val_loss: 0.1058 - val_auc: 0.6948\n",
      "Epoch 519/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0498 - auc: 0.6948 - val_loss: 0.1060 - val_auc: 0.6949\n",
      "Epoch 520/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0508 - auc: 0.6949 - val_loss: 0.1065 - val_auc: 0.6949\n",
      "Epoch 521/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0523 - auc: 0.6950 - val_loss: 0.1064 - val_auc: 0.6950\n",
      "Epoch 522/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0514 - auc: 0.6951 - val_loss: 0.1058 - val_auc: 0.6951\n",
      "Epoch 523/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0547 - auc: 0.6951 - val_loss: 0.1059 - val_auc: 0.6951\n",
      "Epoch 524/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0500 - auc: 0.6951 - val_loss: 0.1053 - val_auc: 0.6952\n",
      "Epoch 525/1000\n",
      "4059/4059 [==============================] - 0s 42us/step - loss: 0.0518 - auc: 0.6952 - val_loss: 0.1057 - val_auc: 0.6952\n",
      "Epoch 526/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0533 - auc: 0.6952 - val_loss: 0.1057 - val_auc: 0.6953\n",
      "Epoch 527/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0521 - auc: 0.6953 - val_loss: 0.1054 - val_auc: 0.6953\n",
      "Epoch 528/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0526 - auc: 0.6954 - val_loss: 0.1057 - val_auc: 0.6954\n",
      "Epoch 529/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0523 - auc: 0.6954 - val_loss: 0.1057 - val_auc: 0.6955\n",
      "Epoch 530/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0534 - auc: 0.6955 - val_loss: 0.1058 - val_auc: 0.6955\n",
      "Epoch 531/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0540 - auc: 0.6955 - val_loss: 0.1054 - val_auc: 0.6955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0515 - auc: 0.6955 - val_loss: 0.1057 - val_auc: 0.6956\n",
      "Epoch 533/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0494 - auc: 0.6956 - val_loss: 0.1060 - val_auc: 0.6957\n",
      "Epoch 534/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0517 - auc: 0.6957 - val_loss: 0.1057 - val_auc: 0.6957\n",
      "Epoch 535/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0525 - auc: 0.6957 - val_loss: 0.1056 - val_auc: 0.6957\n",
      "Epoch 536/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0498 - auc: 0.6958 - val_loss: 0.1062 - val_auc: 0.6959\n",
      "Epoch 537/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0538 - auc: 0.6959 - val_loss: 0.1061 - val_auc: 0.6959\n",
      "Epoch 538/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0522 - auc: 0.6959 - val_loss: 0.1056 - val_auc: 0.6960\n",
      "Epoch 539/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0507 - auc: 0.6960 - val_loss: 0.1055 - val_auc: 0.6961\n",
      "Epoch 540/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0524 - auc: 0.6961 - val_loss: 0.1055 - val_auc: 0.6961\n",
      "Epoch 541/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0516 - auc: 0.6961 - val_loss: 0.1056 - val_auc: 0.6962\n",
      "Epoch 542/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0520 - auc: 0.6962 - val_loss: 0.1058 - val_auc: 0.6962\n",
      "Epoch 543/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0512 - auc: 0.6962 - val_loss: 0.1061 - val_auc: 0.6963\n",
      "Epoch 544/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0516 - auc: 0.6963 - val_loss: 0.1068 - val_auc: 0.6963\n",
      "Epoch 545/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0527 - auc: 0.6963 - val_loss: 0.1058 - val_auc: 0.6963\n",
      "Epoch 546/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0511 - auc: 0.6963 - val_loss: 0.1053 - val_auc: 0.6964\n",
      "Epoch 547/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0494 - auc: 0.6965 - val_loss: 0.1058 - val_auc: 0.6965\n",
      "Epoch 548/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0516 - auc: 0.6965 - val_loss: 0.1059 - val_auc: 0.6966\n",
      "Epoch 549/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0526 - auc: 0.6966 - val_loss: 0.1056 - val_auc: 0.6967\n",
      "Epoch 550/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0515 - auc: 0.6967 - val_loss: 0.1060 - val_auc: 0.6967\n",
      "Epoch 551/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0516 - auc: 0.6967 - val_loss: 0.1058 - val_auc: 0.6968\n",
      "Epoch 552/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0534 - auc: 0.6968 - val_loss: 0.1058 - val_auc: 0.6968\n",
      "Epoch 553/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0520 - auc: 0.6968 - val_loss: 0.1057 - val_auc: 0.6969\n",
      "Epoch 554/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0494 - auc: 0.6969 - val_loss: 0.1062 - val_auc: 0.6970\n",
      "Epoch 555/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0505 - auc: 0.6970 - val_loss: 0.1060 - val_auc: 0.6971\n",
      "Epoch 556/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0514 - auc: 0.6971 - val_loss: 0.1058 - val_auc: 0.6971\n",
      "Epoch 557/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0527 - auc: 0.6971 - val_loss: 0.1057 - val_auc: 0.6971\n",
      "Epoch 558/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0507 - auc: 0.6971 - val_loss: 0.1057 - val_auc: 0.6972\n",
      "Epoch 559/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0534 - auc: 0.6972 - val_loss: 0.1060 - val_auc: 0.6972\n",
      "Epoch 560/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0520 - auc: 0.6972 - val_loss: 0.1058 - val_auc: 0.6973\n",
      "Epoch 561/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0524 - auc: 0.6973 - val_loss: 0.1053 - val_auc: 0.6973\n",
      "Epoch 562/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0509 - auc: 0.6973 - val_loss: 0.1060 - val_auc: 0.6974\n",
      "Epoch 563/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0528 - auc: 0.6974 - val_loss: 0.1060 - val_auc: 0.6974\n",
      "Epoch 564/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0511 - auc: 0.6975 - val_loss: 0.1060 - val_auc: 0.6975\n",
      "Epoch 565/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0524 - auc: 0.6975 - val_loss: 0.1060 - val_auc: 0.6975\n",
      "Epoch 566/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0515 - auc: 0.6976 - val_loss: 0.1059 - val_auc: 0.6976\n",
      "Epoch 567/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0495 - auc: 0.6977 - val_loss: 0.1059 - val_auc: 0.6977\n",
      "Epoch 568/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0520 - auc: 0.6977 - val_loss: 0.1061 - val_auc: 0.6978\n",
      "Epoch 569/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0530 - auc: 0.6978 - val_loss: 0.1056 - val_auc: 0.6978\n",
      "Epoch 570/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0515 - auc: 0.6978 - val_loss: 0.1056 - val_auc: 0.6979\n",
      "Epoch 571/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0534 - auc: 0.6979 - val_loss: 0.1054 - val_auc: 0.6979\n",
      "Epoch 572/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0521 - auc: 0.6979 - val_loss: 0.1051 - val_auc: 0.6979\n",
      "Epoch 573/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0495 - auc: 0.6979 - val_loss: 0.1057 - val_auc: 0.6980\n",
      "Epoch 574/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0501 - auc: 0.6981 - val_loss: 0.1061 - val_auc: 0.6981\n",
      "Epoch 575/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0505 - auc: 0.6981 - val_loss: 0.1062 - val_auc: 0.6982\n",
      "Epoch 576/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0526 - auc: 0.6982 - val_loss: 0.1060 - val_auc: 0.6982\n",
      "Epoch 577/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0548 - auc: 0.6982 - val_loss: 0.1057 - val_auc: 0.6982\n",
      "Epoch 578/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0513 - auc: 0.6982 - val_loss: 0.1054 - val_auc: 0.6983\n",
      "Epoch 579/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0487 - auc: 0.6983 - val_loss: 0.1059 - val_auc: 0.6984\n",
      "Epoch 580/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0516 - auc: 0.6984 - val_loss: 0.1063 - val_auc: 0.6985\n",
      "Epoch 581/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0510 - auc: 0.6985 - val_loss: 0.1058 - val_auc: 0.6986\n",
      "Epoch 582/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0514 - auc: 0.6986 - val_loss: 0.1055 - val_auc: 0.6986\n",
      "Epoch 583/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0517 - auc: 0.6986 - val_loss: 0.1054 - val_auc: 0.6987\n",
      "Epoch 584/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0508 - auc: 0.6987 - val_loss: 0.1054 - val_auc: 0.6988\n",
      "Epoch 585/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0520 - auc: 0.6988 - val_loss: 0.1054 - val_auc: 0.6988\n",
      "Epoch 586/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0513 - auc: 0.6989 - val_loss: 0.1052 - val_auc: 0.6989\n",
      "Epoch 587/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0508 - auc: 0.6989 - val_loss: 0.1053 - val_auc: 0.6990\n",
      "Epoch 588/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0520 - auc: 0.6990 - val_loss: 0.1058 - val_auc: 0.6990\n",
      "Epoch 589/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0502 - auc: 0.6991 - val_loss: 0.1062 - val_auc: 0.6991\n",
      "Epoch 590/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0540 - auc: 0.6991 - val_loss: 0.1060 - val_auc: 0.6991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0515 - auc: 0.6992 - val_loss: 0.1057 - val_auc: 0.6992\n",
      "Epoch 592/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0517 - auc: 0.6992 - val_loss: 0.1054 - val_auc: 0.6992\n",
      "Epoch 593/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0517 - auc: 0.6993 - val_loss: 0.1055 - val_auc: 0.6993\n",
      "Epoch 594/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0491 - auc: 0.6994 - val_loss: 0.1064 - val_auc: 0.6994\n",
      "Epoch 595/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0530 - auc: 0.6994 - val_loss: 0.1063 - val_auc: 0.6995\n",
      "Epoch 596/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0540 - auc: 0.6995 - val_loss: 0.1056 - val_auc: 0.6995\n",
      "Epoch 597/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0530 - auc: 0.6995 - val_loss: 0.1047 - val_auc: 0.6995\n",
      "Epoch 598/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0515 - auc: 0.6995 - val_loss: 0.1049 - val_auc: 0.6995\n",
      "Epoch 599/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0532 - auc: 0.6995 - val_loss: 0.1054 - val_auc: 0.6995\n",
      "Epoch 600/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0512 - auc: 0.6995 - val_loss: 0.1055 - val_auc: 0.6996\n",
      "Epoch 601/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0522 - auc: 0.6996 - val_loss: 0.1052 - val_auc: 0.6996\n",
      "Epoch 602/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0498 - auc: 0.6996 - val_loss: 0.1052 - val_auc: 0.6997\n",
      "Epoch 603/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0526 - auc: 0.6997 - val_loss: 0.1058 - val_auc: 0.6997\n",
      "Epoch 604/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0505 - auc: 0.6997 - val_loss: 0.1059 - val_auc: 0.6998\n",
      "Epoch 605/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0541 - auc: 0.6998 - val_loss: 0.1055 - val_auc: 0.6998\n",
      "Epoch 606/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0525 - auc: 0.6998 - val_loss: 0.1057 - val_auc: 0.6998\n",
      "Epoch 607/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0509 - auc: 0.6998 - val_loss: 0.1058 - val_auc: 0.6999\n",
      "Epoch 608/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0526 - auc: 0.6999 - val_loss: 0.1055 - val_auc: 0.6999\n",
      "Epoch 609/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0507 - auc: 0.7000 - val_loss: 0.1053 - val_auc: 0.7000\n",
      "Epoch 610/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0520 - auc: 0.7000 - val_loss: 0.1053 - val_auc: 0.7000\n",
      "Epoch 611/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0496 - auc: 0.7001 - val_loss: 0.1058 - val_auc: 0.7001\n",
      "Epoch 612/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0530 - auc: 0.7001 - val_loss: 0.1053 - val_auc: 0.7001\n",
      "Epoch 613/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0517 - auc: 0.7001 - val_loss: 0.1050 - val_auc: 0.7002\n",
      "Epoch 614/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0525 - auc: 0.7002 - val_loss: 0.1050 - val_auc: 0.7002\n",
      "Epoch 615/1000\n",
      "4059/4059 [==============================] - 0s 42us/step - loss: 0.0507 - auc: 0.7002 - val_loss: 0.1056 - val_auc: 0.7003\n",
      "Epoch 616/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0502 - auc: 0.7003 - val_loss: 0.1056 - val_auc: 0.7003\n",
      "Epoch 617/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0510 - auc: 0.7004 - val_loss: 0.1055 - val_auc: 0.7004\n",
      "Epoch 618/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0513 - auc: 0.7004 - val_loss: 0.1057 - val_auc: 0.7004\n",
      "Epoch 619/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0513 - auc: 0.7004 - val_loss: 0.1059 - val_auc: 0.7005\n",
      "Epoch 620/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0492 - auc: 0.7005 - val_loss: 0.1062 - val_auc: 0.7006\n",
      "Epoch 621/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0521 - auc: 0.7006 - val_loss: 0.1063 - val_auc: 0.7006\n",
      "Epoch 622/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0504 - auc: 0.7006 - val_loss: 0.1062 - val_auc: 0.7007\n",
      "Epoch 623/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0501 - auc: 0.7007 - val_loss: 0.1064 - val_auc: 0.7008\n",
      "Epoch 624/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0513 - auc: 0.7008 - val_loss: 0.1066 - val_auc: 0.7008\n",
      "Epoch 625/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0517 - auc: 0.7008 - val_loss: 0.1064 - val_auc: 0.7009\n",
      "Epoch 626/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0514 - auc: 0.7009 - val_loss: 0.1060 - val_auc: 0.7009\n",
      "Epoch 627/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0524 - auc: 0.7009 - val_loss: 0.1057 - val_auc: 0.7009\n",
      "Epoch 628/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0526 - auc: 0.7009 - val_loss: 0.1053 - val_auc: 0.7010\n",
      "Epoch 629/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0519 - auc: 0.7010 - val_loss: 0.1058 - val_auc: 0.7010\n",
      "Epoch 630/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0520 - auc: 0.7010 - val_loss: 0.1058 - val_auc: 0.7010\n",
      "Epoch 631/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0522 - auc: 0.7010 - val_loss: 0.1056 - val_auc: 0.7011\n",
      "Epoch 632/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0518 - auc: 0.7011 - val_loss: 0.1057 - val_auc: 0.7011\n",
      "Epoch 633/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0517 - auc: 0.7011 - val_loss: 0.1057 - val_auc: 0.7012\n",
      "Epoch 634/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0530 - auc: 0.7011 - val_loss: 0.1053 - val_auc: 0.7012\n",
      "Epoch 635/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0528 - auc: 0.7012 - val_loss: 0.1050 - val_auc: 0.7012\n",
      "Epoch 636/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0511 - auc: 0.7012 - val_loss: 0.1056 - val_auc: 0.7013\n",
      "Epoch 637/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0510 - auc: 0.7013 - val_loss: 0.1057 - val_auc: 0.7013\n",
      "Epoch 638/1000\n",
      "4059/4059 [==============================] - 0s 42us/step - loss: 0.0514 - auc: 0.7013 - val_loss: 0.1060 - val_auc: 0.7014\n",
      "Epoch 639/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0519 - auc: 0.7014 - val_loss: 0.1061 - val_auc: 0.7014\n",
      "Epoch 640/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0518 - auc: 0.7014 - val_loss: 0.1057 - val_auc: 0.7014\n",
      "Epoch 641/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0515 - auc: 0.7015 - val_loss: 0.1058 - val_auc: 0.7015\n",
      "Epoch 642/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0499 - auc: 0.7015 - val_loss: 0.1061 - val_auc: 0.7016\n",
      "Epoch 643/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0497 - auc: 0.7016 - val_loss: 0.1066 - val_auc: 0.7016\n",
      "Epoch 644/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0512 - auc: 0.7016 - val_loss: 0.1067 - val_auc: 0.7016\n",
      "Epoch 645/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0511 - auc: 0.7017 - val_loss: 0.1068 - val_auc: 0.7017\n",
      "Epoch 646/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0518 - auc: 0.7017 - val_loss: 0.1065 - val_auc: 0.7017\n",
      "Epoch 647/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0516 - auc: 0.7017 - val_loss: 0.1059 - val_auc: 0.7018\n",
      "Epoch 648/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0509 - auc: 0.7018 - val_loss: 0.1057 - val_auc: 0.7018\n",
      "Epoch 649/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0526 - auc: 0.7018 - val_loss: 0.1053 - val_auc: 0.7018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 650/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0492 - auc: 0.7019 - val_loss: 0.1058 - val_auc: 0.7020\n",
      "Epoch 651/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0513 - auc: 0.7020 - val_loss: 0.1064 - val_auc: 0.7020\n",
      "Epoch 652/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0499 - auc: 0.7021 - val_loss: 0.1063 - val_auc: 0.7021\n",
      "Epoch 653/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0512 - auc: 0.7021 - val_loss: 0.1059 - val_auc: 0.7021\n",
      "Epoch 654/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0505 - auc: 0.7021 - val_loss: 0.1058 - val_auc: 0.7022\n",
      "Epoch 655/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0500 - auc: 0.7022 - val_loss: 0.1061 - val_auc: 0.7022\n",
      "Epoch 656/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0523 - auc: 0.7023 - val_loss: 0.1061 - val_auc: 0.7023\n",
      "Epoch 657/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0514 - auc: 0.7023 - val_loss: 0.1065 - val_auc: 0.7023\n",
      "Epoch 658/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0492 - auc: 0.7023 - val_loss: 0.1064 - val_auc: 0.7024\n",
      "Epoch 659/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0538 - auc: 0.7024 - val_loss: 0.1059 - val_auc: 0.7024\n",
      "Epoch 660/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0504 - auc: 0.7024 - val_loss: 0.1059 - val_auc: 0.7024\n",
      "Epoch 661/1000\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 0.0477 - auc: 0.702 - 0s 36us/step - loss: 0.0515 - auc: 0.7024 - val_loss: 0.1058 - val_auc: 0.7025\n",
      "Epoch 662/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0513 - auc: 0.7025 - val_loss: 0.1052 - val_auc: 0.7025\n",
      "Epoch 663/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0535 - auc: 0.7025 - val_loss: 0.1053 - val_auc: 0.7025\n",
      "Epoch 664/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0527 - auc: 0.7025 - val_loss: 0.1047 - val_auc: 0.7025\n",
      "Epoch 665/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0501 - auc: 0.7025 - val_loss: 0.1048 - val_auc: 0.7025\n",
      "Epoch 666/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0511 - auc: 0.7025 - val_loss: 0.1053 - val_auc: 0.7026\n",
      "Epoch 667/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0499 - auc: 0.7026 - val_loss: 0.1055 - val_auc: 0.7026\n",
      "Epoch 668/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0519 - auc: 0.7026 - val_loss: 0.1054 - val_auc: 0.7027\n",
      "Epoch 669/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0518 - auc: 0.7027 - val_loss: 0.1058 - val_auc: 0.7027\n",
      "Epoch 670/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0514 - auc: 0.7027 - val_loss: 0.1057 - val_auc: 0.7028\n",
      "Epoch 671/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0530 - auc: 0.7028 - val_loss: 0.1056 - val_auc: 0.7028\n",
      "Epoch 672/1000\n",
      "4059/4059 [==============================] - 0s 42us/step - loss: 0.0522 - auc: 0.7028 - val_loss: 0.1052 - val_auc: 0.7028\n",
      "Epoch 673/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0512 - auc: 0.7028 - val_loss: 0.1050 - val_auc: 0.7029\n",
      "Epoch 674/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0511 - auc: 0.7029 - val_loss: 0.1052 - val_auc: 0.7029\n",
      "Epoch 675/1000\n",
      "4059/4059 [==============================] - 0s 43us/step - loss: 0.0512 - auc: 0.7029 - val_loss: 0.1053 - val_auc: 0.7030\n",
      "Epoch 676/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0502 - auc: 0.7030 - val_loss: 0.1057 - val_auc: 0.7030\n",
      "Epoch 677/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0531 - auc: 0.7030 - val_loss: 0.1060 - val_auc: 0.7030\n",
      "Epoch 678/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0516 - auc: 0.7030 - val_loss: 0.1062 - val_auc: 0.7030\n",
      "Epoch 679/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0531 - auc: 0.7030 - val_loss: 0.1056 - val_auc: 0.7031\n",
      "Epoch 680/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0497 - auc: 0.7031 - val_loss: 0.1056 - val_auc: 0.7031\n",
      "Epoch 681/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0490 - auc: 0.7031 - val_loss: 0.1059 - val_auc: 0.7032\n",
      "Epoch 682/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0496 - auc: 0.7032 - val_loss: 0.1063 - val_auc: 0.7033\n",
      "Epoch 683/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0509 - auc: 0.7033 - val_loss: 0.1065 - val_auc: 0.7033\n",
      "Epoch 684/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0508 - auc: 0.7033 - val_loss: 0.1063 - val_auc: 0.7033\n",
      "Epoch 685/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0492 - auc: 0.7034 - val_loss: 0.1062 - val_auc: 0.7034\n",
      "Epoch 686/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0531 - auc: 0.7034 - val_loss: 0.1059 - val_auc: 0.7034\n",
      "Epoch 687/1000\n",
      "4059/4059 [==============================] - 0s 21us/step - loss: 0.0518 - auc: 0.7034 - val_loss: 0.1060 - val_auc: 0.7034\n",
      "Epoch 688/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0507 - auc: 0.7034 - val_loss: 0.1058 - val_auc: 0.7035\n",
      "Epoch 689/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0526 - auc: 0.7035 - val_loss: 0.1056 - val_auc: 0.7035\n",
      "Epoch 690/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0515 - auc: 0.7035 - val_loss: 0.1055 - val_auc: 0.7035\n",
      "Epoch 691/1000\n",
      "4059/4059 [==============================] - 0s 19us/step - loss: 0.0507 - auc: 0.7035 - val_loss: 0.1058 - val_auc: 0.7036\n",
      "Epoch 692/1000\n",
      "4059/4059 [==============================] - 0s 24us/step - loss: 0.0503 - auc: 0.7036 - val_loss: 0.1059 - val_auc: 0.7036\n",
      "Epoch 693/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0512 - auc: 0.7036 - val_loss: 0.1065 - val_auc: 0.7037\n",
      "Epoch 694/1000\n",
      "4059/4059 [==============================] - 0s 20us/step - loss: 0.0506 - auc: 0.7037 - val_loss: 0.1062 - val_auc: 0.7037\n",
      "Epoch 695/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0510 - auc: 0.7037 - val_loss: 0.1060 - val_auc: 0.7037\n",
      "Epoch 696/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0503 - auc: 0.7037 - val_loss: 0.1056 - val_auc: 0.7038\n",
      "Epoch 697/1000\n",
      "4059/4059 [==============================] - 0s 23us/step - loss: 0.0521 - auc: 0.7038 - val_loss: 0.1054 - val_auc: 0.7038\n",
      "Epoch 698/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0523 - auc: 0.7038 - val_loss: 0.1054 - val_auc: 0.7038\n",
      "Epoch 699/1000\n",
      "4059/4059 [==============================] - 0s 20us/step - loss: 0.0496 - auc: 0.7039 - val_loss: 0.1058 - val_auc: 0.7039\n",
      "Epoch 700/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0526 - auc: 0.7039 - val_loss: 0.1058 - val_auc: 0.7039\n",
      "Epoch 701/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0507 - auc: 0.7040 - val_loss: 0.1060 - val_auc: 0.7040\n",
      "Epoch 702/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0506 - auc: 0.7040 - val_loss: 0.1061 - val_auc: 0.7040\n",
      "Epoch 703/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0483 - auc: 0.7041 - val_loss: 0.1065 - val_auc: 0.7041\n",
      "Epoch 704/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0528 - auc: 0.7041 - val_loss: 0.1065 - val_auc: 0.7042\n",
      "Epoch 705/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0519 - auc: 0.7042 - val_loss: 0.1066 - val_auc: 0.7042\n",
      "Epoch 706/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0510 - auc: 0.7042 - val_loss: 0.1064 - val_auc: 0.7042\n",
      "Epoch 707/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0492 - auc: 0.7042 - val_loss: 0.1066 - val_auc: 0.7042\n",
      "Epoch 708/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0512 - auc: 0.7042 - val_loss: 0.1063 - val_auc: 0.7043\n",
      "Epoch 709/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0508 - auc: 0.7043 - val_loss: 0.1062 - val_auc: 0.7043\n",
      "Epoch 710/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0511 - auc: 0.7043 - val_loss: 0.1060 - val_auc: 0.7044\n",
      "Epoch 711/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0512 - auc: 0.7044 - val_loss: 0.1066 - val_auc: 0.7044\n",
      "Epoch 712/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0527 - auc: 0.7044 - val_loss: 0.1060 - val_auc: 0.7044\n",
      "Epoch 713/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0521 - auc: 0.7044 - val_loss: 0.1056 - val_auc: 0.7044\n",
      "Epoch 714/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0508 - auc: 0.7044 - val_loss: 0.1055 - val_auc: 0.7045\n",
      "Epoch 715/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0504 - auc: 0.7045 - val_loss: 0.1059 - val_auc: 0.7045\n",
      "Epoch 716/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0493 - auc: 0.7045 - val_loss: 0.1064 - val_auc: 0.7046\n",
      "Epoch 717/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0517 - auc: 0.7046 - val_loss: 0.1066 - val_auc: 0.7046\n",
      "Epoch 718/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0507 - auc: 0.7046 - val_loss: 0.1065 - val_auc: 0.7046\n",
      "Epoch 719/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0500 - auc: 0.7047 - val_loss: 0.1063 - val_auc: 0.7047\n",
      "Epoch 720/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0513 - auc: 0.7047 - val_loss: 0.1066 - val_auc: 0.7047\n",
      "Epoch 721/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0523 - auc: 0.7047 - val_loss: 0.1060 - val_auc: 0.7048\n",
      "Epoch 722/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0515 - auc: 0.7048 - val_loss: 0.1055 - val_auc: 0.7048\n",
      "Epoch 723/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0507 - auc: 0.7048 - val_loss: 0.1052 - val_auc: 0.7048\n",
      "Epoch 724/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0509 - auc: 0.7049 - val_loss: 0.1051 - val_auc: 0.7049\n",
      "Epoch 725/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0515 - auc: 0.7049 - val_loss: 0.1052 - val_auc: 0.7049\n",
      "Epoch 726/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0488 - auc: 0.7050 - val_loss: 0.1056 - val_auc: 0.7050\n",
      "Epoch 727/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0538 - auc: 0.7050 - val_loss: 0.1053 - val_auc: 0.7050\n",
      "Epoch 728/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0515 - auc: 0.7050 - val_loss: 0.1053 - val_auc: 0.7051\n",
      "Epoch 729/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0512 - auc: 0.7051 - val_loss: 0.1057 - val_auc: 0.7051\n",
      "Epoch 730/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0509 - auc: 0.7051 - val_loss: 0.1061 - val_auc: 0.7051\n",
      "Epoch 731/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0529 - auc: 0.7051 - val_loss: 0.1059 - val_auc: 0.7051\n",
      "Epoch 732/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0532 - auc: 0.7051 - val_loss: 0.1057 - val_auc: 0.7051\n",
      "Epoch 733/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0505 - auc: 0.7052 - val_loss: 0.1054 - val_auc: 0.7052\n",
      "Epoch 734/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0491 - auc: 0.7052 - val_loss: 0.1057 - val_auc: 0.7052\n",
      "Epoch 735/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0494 - auc: 0.7053 - val_loss: 0.1068 - val_auc: 0.7053\n",
      "Epoch 736/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0517 - auc: 0.7053 - val_loss: 0.1069 - val_auc: 0.7053\n",
      "Epoch 737/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0508 - auc: 0.7053 - val_loss: 0.1068 - val_auc: 0.7053\n",
      "Epoch 738/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0527 - auc: 0.7053 - val_loss: 0.1062 - val_auc: 0.7053\n",
      "Epoch 739/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0517 - auc: 0.7053 - val_loss: 0.1054 - val_auc: 0.7054\n",
      "Epoch 740/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0502 - auc: 0.7054 - val_loss: 0.1055 - val_auc: 0.7054\n",
      "Epoch 741/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0509 - auc: 0.7054 - val_loss: 0.1059 - val_auc: 0.7054\n",
      "Epoch 742/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0530 - auc: 0.7054 - val_loss: 0.1058 - val_auc: 0.7054\n",
      "Epoch 743/1000\n",
      "4059/4059 [==============================] - 0s 23us/step - loss: 0.0503 - auc: 0.7054 - val_loss: 0.1049 - val_auc: 0.7055\n",
      "Epoch 744/1000\n",
      "4059/4059 [==============================] - 0s 23us/step - loss: 0.0517 - auc: 0.7055 - val_loss: 0.1045 - val_auc: 0.7055\n",
      "Epoch 745/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0520 - auc: 0.7055 - val_loss: 0.1047 - val_auc: 0.7055\n",
      "Epoch 746/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0494 - auc: 0.7055 - val_loss: 0.1055 - val_auc: 0.7056\n",
      "Epoch 747/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0523 - auc: 0.7055 - val_loss: 0.1059 - val_auc: 0.7056\n",
      "Epoch 748/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0521 - auc: 0.7056 - val_loss: 0.1060 - val_auc: 0.7056\n",
      "Epoch 749/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0499 - auc: 0.7056 - val_loss: 0.1061 - val_auc: 0.7056\n",
      "Epoch 750/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0508 - auc: 0.7056 - val_loss: 0.1057 - val_auc: 0.7056\n",
      "Epoch 751/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0509 - auc: 0.7056 - val_loss: 0.1058 - val_auc: 0.7057\n",
      "Epoch 752/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0506 - auc: 0.7057 - val_loss: 0.1058 - val_auc: 0.7057\n",
      "Epoch 753/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0508 - auc: 0.7057 - val_loss: 0.1056 - val_auc: 0.7058\n",
      "Epoch 754/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0519 - auc: 0.7058 - val_loss: 0.1051 - val_auc: 0.7058\n",
      "Epoch 755/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0530 - auc: 0.7058 - val_loss: 0.1052 - val_auc: 0.7058\n",
      "Epoch 756/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0502 - auc: 0.7058 - val_loss: 0.1059 - val_auc: 0.7059\n",
      "Epoch 757/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0491 - auc: 0.7059 - val_loss: 0.1071 - val_auc: 0.7059\n",
      "Epoch 758/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0501 - auc: 0.7059 - val_loss: 0.1070 - val_auc: 0.7059\n",
      "Epoch 759/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0518 - auc: 0.7059 - val_loss: 0.1060 - val_auc: 0.7060\n",
      "Epoch 760/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0521 - auc: 0.7060 - val_loss: 0.1053 - val_auc: 0.7060\n",
      "Epoch 761/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0488 - auc: 0.7060 - val_loss: 0.1054 - val_auc: 0.7060\n",
      "Epoch 762/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0496 - auc: 0.7061 - val_loss: 0.1052 - val_auc: 0.7061\n",
      "Epoch 763/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0508 - auc: 0.7061 - val_loss: 0.1055 - val_auc: 0.7061\n",
      "Epoch 764/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0498 - auc: 0.7061 - val_loss: 0.1059 - val_auc: 0.7062\n",
      "Epoch 765/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0513 - auc: 0.7062 - val_loss: 0.1059 - val_auc: 0.7062\n",
      "Epoch 766/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0517 - auc: 0.7062 - val_loss: 0.1059 - val_auc: 0.7063\n",
      "Epoch 767/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0512 - auc: 0.7063 - val_loss: 0.1056 - val_auc: 0.7063\n",
      "Epoch 768/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0508 - auc: 0.7063 - val_loss: 0.1056 - val_auc: 0.7063\n",
      "Epoch 769/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0515 - auc: 0.7063 - val_loss: 0.1061 - val_auc: 0.7064\n",
      "Epoch 770/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0520 - auc: 0.7064 - val_loss: 0.1054 - val_auc: 0.7064\n",
      "Epoch 771/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0516 - auc: 0.7064 - val_loss: 0.1051 - val_auc: 0.7064\n",
      "Epoch 772/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0510 - auc: 0.7064 - val_loss: 0.1054 - val_auc: 0.7065\n",
      "Epoch 773/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0498 - auc: 0.7065 - val_loss: 0.1056 - val_auc: 0.7065\n",
      "Epoch 774/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0501 - auc: 0.7065 - val_loss: 0.1053 - val_auc: 0.7066\n",
      "Epoch 775/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0513 - auc: 0.7066 - val_loss: 0.1055 - val_auc: 0.7066\n",
      "Epoch 776/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0511 - auc: 0.7066 - val_loss: 0.1053 - val_auc: 0.7066\n",
      "Epoch 777/1000\n",
      "4059/4059 [==============================] - 0s 42us/step - loss: 0.0517 - auc: 0.7066 - val_loss: 0.1053 - val_auc: 0.7067\n",
      "Epoch 778/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0504 - auc: 0.7067 - val_loss: 0.1055 - val_auc: 0.7067\n",
      "Epoch 779/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0518 - auc: 0.7067 - val_loss: 0.1059 - val_auc: 0.7067\n",
      "Epoch 780/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0505 - auc: 0.7067 - val_loss: 0.1060 - val_auc: 0.7067\n",
      "Epoch 781/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0514 - auc: 0.7068 - val_loss: 0.1061 - val_auc: 0.7068\n",
      "Epoch 782/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0515 - auc: 0.7068 - val_loss: 0.1057 - val_auc: 0.7068\n",
      "Epoch 783/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0497 - auc: 0.7068 - val_loss: 0.1054 - val_auc: 0.7069\n",
      "Epoch 784/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0508 - auc: 0.7069 - val_loss: 0.1057 - val_auc: 0.7069\n",
      "Epoch 785/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0526 - auc: 0.7069 - val_loss: 0.1057 - val_auc: 0.7069\n",
      "Epoch 786/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0503 - auc: 0.7069 - val_loss: 0.1059 - val_auc: 0.7070\n",
      "Epoch 787/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0510 - auc: 0.7070 - val_loss: 0.1056 - val_auc: 0.7070\n",
      "Epoch 788/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0514 - auc: 0.7070 - val_loss: 0.1051 - val_auc: 0.7070\n",
      "Epoch 789/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0510 - auc: 0.7070 - val_loss: 0.1049 - val_auc: 0.7070\n",
      "Epoch 790/1000\n",
      "4059/4059 [==============================] - 0s 24us/step - loss: 0.0527 - auc: 0.7070 - val_loss: 0.1048 - val_auc: 0.7070\n",
      "Epoch 791/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0506 - auc: 0.7070 - val_loss: 0.1049 - val_auc: 0.7071\n",
      "Epoch 792/1000\n",
      "4059/4059 [==============================] - 0s 23us/step - loss: 0.0504 - auc: 0.7071 - val_loss: 0.1055 - val_auc: 0.7071\n",
      "Epoch 793/1000\n",
      "4059/4059 [==============================] - 0s 23us/step - loss: 0.0504 - auc: 0.7071 - val_loss: 0.1057 - val_auc: 0.7071\n",
      "Epoch 794/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0500 - auc: 0.7072 - val_loss: 0.1054 - val_auc: 0.7072\n",
      "Epoch 795/1000\n",
      "4059/4059 [==============================] - 0s 21us/step - loss: 0.0512 - auc: 0.7072 - val_loss: 0.1051 - val_auc: 0.7072\n",
      "Epoch 796/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0509 - auc: 0.7072 - val_loss: 0.1054 - val_auc: 0.7073\n",
      "Epoch 797/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0502 - auc: 0.7073 - val_loss: 0.1058 - val_auc: 0.7073\n",
      "Epoch 798/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0496 - auc: 0.7074 - val_loss: 0.1058 - val_auc: 0.7074\n",
      "Epoch 799/1000\n",
      "4059/4059 [==============================] - 0s 23us/step - loss: 0.0511 - auc: 0.7074 - val_loss: 0.1062 - val_auc: 0.7074\n",
      "Epoch 800/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0493 - auc: 0.7075 - val_loss: 0.1063 - val_auc: 0.7075\n",
      "Epoch 801/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0517 - auc: 0.7075 - val_loss: 0.1062 - val_auc: 0.7075\n",
      "Epoch 802/1000\n",
      "4059/4059 [==============================] - 0s 24us/step - loss: 0.0520 - auc: 0.7075 - val_loss: 0.1059 - val_auc: 0.7075\n",
      "Epoch 803/1000\n",
      "4059/4059 [==============================] - 0s 19us/step - loss: 0.0517 - auc: 0.7075 - val_loss: 0.1054 - val_auc: 0.7075\n",
      "Epoch 804/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0508 - auc: 0.7075 - val_loss: 0.1048 - val_auc: 0.7076\n",
      "Epoch 805/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0525 - auc: 0.7076 - val_loss: 0.1050 - val_auc: 0.7076\n",
      "Epoch 806/1000\n",
      "4059/4059 [==============================] - 0s 23us/step - loss: 0.0525 - auc: 0.7076 - val_loss: 0.1050 - val_auc: 0.7076\n",
      "Epoch 807/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0505 - auc: 0.7076 - val_loss: 0.1052 - val_auc: 0.7076\n",
      "Epoch 808/1000\n",
      "4059/4059 [==============================] - 0s 21us/step - loss: 0.0530 - auc: 0.7076 - val_loss: 0.1052 - val_auc: 0.7076\n",
      "Epoch 809/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0500 - auc: 0.7076 - val_loss: 0.1052 - val_auc: 0.7077\n",
      "Epoch 810/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0501 - auc: 0.7077 - val_loss: 0.1060 - val_auc: 0.7077\n",
      "Epoch 811/1000\n",
      "4059/4059 [==============================] - 0s 24us/step - loss: 0.0519 - auc: 0.7077 - val_loss: 0.1062 - val_auc: 0.7077\n",
      "Epoch 812/1000\n",
      "4059/4059 [==============================] - 0s 24us/step - loss: 0.0514 - auc: 0.7077 - val_loss: 0.1054 - val_auc: 0.7077\n",
      "Epoch 813/1000\n",
      "4059/4059 [==============================] - 0s 19us/step - loss: 0.0505 - auc: 0.7077 - val_loss: 0.1054 - val_auc: 0.7078\n",
      "Epoch 814/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0514 - auc: 0.7078 - val_loss: 0.1063 - val_auc: 0.7078\n",
      "Epoch 815/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0501 - auc: 0.7078 - val_loss: 0.1066 - val_auc: 0.7079\n",
      "Epoch 816/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0480 - auc: 0.7079 - val_loss: 0.1068 - val_auc: 0.7079\n",
      "Epoch 817/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0506 - auc: 0.7079 - val_loss: 0.1067 - val_auc: 0.7079\n",
      "Epoch 818/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0513 - auc: 0.7079 - val_loss: 0.1066 - val_auc: 0.7080\n",
      "Epoch 819/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0508 - auc: 0.7080 - val_loss: 0.1062 - val_auc: 0.7080\n",
      "Epoch 820/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0511 - auc: 0.7080 - val_loss: 0.1063 - val_auc: 0.7080\n",
      "Epoch 821/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0499 - auc: 0.7080 - val_loss: 0.1065 - val_auc: 0.7081\n",
      "Epoch 822/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0520 - auc: 0.7081 - val_loss: 0.1073 - val_auc: 0.7081\n",
      "Epoch 823/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0509 - auc: 0.7081 - val_loss: 0.1075 - val_auc: 0.7081\n",
      "Epoch 824/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0495 - auc: 0.7082 - val_loss: 0.1069 - val_auc: 0.7082\n",
      "Epoch 825/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0512 - auc: 0.7082 - val_loss: 0.1065 - val_auc: 0.7082\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0501 - auc: 0.7082 - val_loss: 0.1065 - val_auc: 0.7083\n",
      "Epoch 827/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0497 - auc: 0.7083 - val_loss: 0.1062 - val_auc: 0.7083\n",
      "Epoch 828/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0516 - auc: 0.7083 - val_loss: 0.1063 - val_auc: 0.7083\n",
      "Epoch 829/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0515 - auc: 0.7083 - val_loss: 0.1065 - val_auc: 0.7083\n",
      "Epoch 830/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0494 - auc: 0.7084 - val_loss: 0.1068 - val_auc: 0.7084\n",
      "Epoch 831/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0525 - auc: 0.7084 - val_loss: 0.1065 - val_auc: 0.7084\n",
      "Epoch 832/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0493 - auc: 0.7084 - val_loss: 0.1057 - val_auc: 0.7084\n",
      "Epoch 833/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0503 - auc: 0.7085 - val_loss: 0.1063 - val_auc: 0.7085\n",
      "Epoch 834/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0522 - auc: 0.7085 - val_loss: 0.1064 - val_auc: 0.7085\n",
      "Epoch 835/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0506 - auc: 0.7085 - val_loss: 0.1059 - val_auc: 0.7085\n",
      "Epoch 836/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0510 - auc: 0.7085 - val_loss: 0.1059 - val_auc: 0.7085\n",
      "Epoch 837/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0503 - auc: 0.7086 - val_loss: 0.1061 - val_auc: 0.7086\n",
      "Epoch 838/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0517 - auc: 0.7086 - val_loss: 0.1054 - val_auc: 0.7086\n",
      "Epoch 839/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0490 - auc: 0.7086 - val_loss: 0.1050 - val_auc: 0.7086\n",
      "Epoch 840/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0506 - auc: 0.7086 - val_loss: 0.1055 - val_auc: 0.7086\n",
      "Epoch 841/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0526 - auc: 0.7086 - val_loss: 0.1050 - val_auc: 0.7086\n",
      "Epoch 842/1000\n",
      "4059/4059 [==============================] - 0s 21us/step - loss: 0.0517 - auc: 0.7086 - val_loss: 0.1050 - val_auc: 0.7086\n",
      "Epoch 843/1000\n",
      "4059/4059 [==============================] - 0s 24us/step - loss: 0.0513 - auc: 0.7086 - val_loss: 0.1049 - val_auc: 0.7086\n",
      "Epoch 844/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0514 - auc: 0.7086 - val_loss: 0.1054 - val_auc: 0.7087\n",
      "Epoch 845/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0505 - auc: 0.7087 - val_loss: 0.1053 - val_auc: 0.7087\n",
      "Epoch 846/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0497 - auc: 0.7087 - val_loss: 0.1054 - val_auc: 0.7088\n",
      "Epoch 847/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0507 - auc: 0.7088 - val_loss: 0.1054 - val_auc: 0.7088\n",
      "Epoch 848/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0513 - auc: 0.7088 - val_loss: 0.1048 - val_auc: 0.7088\n",
      "Epoch 849/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0510 - auc: 0.7088 - val_loss: 0.1049 - val_auc: 0.7089\n",
      "Epoch 850/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0507 - auc: 0.7089 - val_loss: 0.1055 - val_auc: 0.7089\n",
      "Epoch 851/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0503 - auc: 0.7089 - val_loss: 0.1061 - val_auc: 0.7090\n",
      "Epoch 852/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0491 - auc: 0.7090 - val_loss: 0.1065 - val_auc: 0.7090\n",
      "Epoch 853/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0514 - auc: 0.7090 - val_loss: 0.1062 - val_auc: 0.7090\n",
      "Epoch 854/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0518 - auc: 0.7090 - val_loss: 0.1061 - val_auc: 0.7090\n",
      "Epoch 855/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0501 - auc: 0.7090 - val_loss: 0.1063 - val_auc: 0.7090\n",
      "Epoch 856/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0513 - auc: 0.7090 - val_loss: 0.1065 - val_auc: 0.7090\n",
      "Epoch 857/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0517 - auc: 0.7090 - val_loss: 0.1057 - val_auc: 0.7090\n",
      "Epoch 858/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0516 - auc: 0.7090 - val_loss: 0.1056 - val_auc: 0.7091\n",
      "Epoch 859/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0509 - auc: 0.7091 - val_loss: 0.1053 - val_auc: 0.7091\n",
      "Epoch 860/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0485 - auc: 0.7091 - val_loss: 0.1061 - val_auc: 0.7092\n",
      "Epoch 861/1000\n",
      "4059/4059 [==============================] - 0s 24us/step - loss: 0.0499 - auc: 0.7092 - val_loss: 0.1069 - val_auc: 0.7092\n",
      "Epoch 862/1000\n",
      "4059/4059 [==============================] - 0s 23us/step - loss: 0.0505 - auc: 0.7092 - val_loss: 0.1073 - val_auc: 0.7092\n",
      "Epoch 863/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0523 - auc: 0.7092 - val_loss: 0.1072 - val_auc: 0.7092\n",
      "Epoch 864/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0500 - auc: 0.7092 - val_loss: 0.1064 - val_auc: 0.7092\n",
      "Epoch 865/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0513 - auc: 0.7092 - val_loss: 0.1063 - val_auc: 0.7092\n",
      "Epoch 866/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0510 - auc: 0.7092 - val_loss: 0.1059 - val_auc: 0.7093\n",
      "Epoch 867/1000\n",
      "4059/4059 [==============================] - 0s 24us/step - loss: 0.0513 - auc: 0.7093 - val_loss: 0.1057 - val_auc: 0.7093\n",
      "Epoch 868/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0504 - auc: 0.7093 - val_loss: 0.1058 - val_auc: 0.7093\n",
      "Epoch 869/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0509 - auc: 0.7093 - val_loss: 0.1057 - val_auc: 0.7094\n",
      "Epoch 870/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0530 - auc: 0.7093 - val_loss: 0.1056 - val_auc: 0.7094\n",
      "Epoch 871/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0512 - auc: 0.7094 - val_loss: 0.1055 - val_auc: 0.7094\n",
      "Epoch 872/1000\n",
      "4059/4059 [==============================] - 0s 20us/step - loss: 0.0524 - auc: 0.7094 - val_loss: 0.1053 - val_auc: 0.7094\n",
      "Epoch 873/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0515 - auc: 0.7094 - val_loss: 0.1050 - val_auc: 0.7094\n",
      "Epoch 874/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0511 - auc: 0.7094 - val_loss: 0.1053 - val_auc: 0.7094\n",
      "Epoch 875/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0504 - auc: 0.7094 - val_loss: 0.1053 - val_auc: 0.7095\n",
      "Epoch 876/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0505 - auc: 0.7095 - val_loss: 0.1050 - val_auc: 0.7095\n",
      "Epoch 877/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0512 - auc: 0.7095 - val_loss: 0.1054 - val_auc: 0.7095\n",
      "Epoch 878/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0492 - auc: 0.7095 - val_loss: 0.1052 - val_auc: 0.7096\n",
      "Epoch 879/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0514 - auc: 0.7096 - val_loss: 0.1058 - val_auc: 0.7096\n",
      "Epoch 880/1000\n",
      "4059/4059 [==============================] - 0s 21us/step - loss: 0.0500 - auc: 0.7096 - val_loss: 0.1053 - val_auc: 0.7097\n",
      "Epoch 881/1000\n",
      "4059/4059 [==============================] - 0s 24us/step - loss: 0.0483 - auc: 0.7097 - val_loss: 0.1054 - val_auc: 0.7097\n",
      "Epoch 882/1000\n",
      "4059/4059 [==============================] - 0s 23us/step - loss: 0.0518 - auc: 0.7097 - val_loss: 0.1059 - val_auc: 0.7097\n",
      "Epoch 883/1000\n",
      "4059/4059 [==============================] - 0s 21us/step - loss: 0.0492 - auc: 0.7097 - val_loss: 0.1056 - val_auc: 0.7098\n",
      "Epoch 884/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0513 - auc: 0.7098 - val_loss: 0.1059 - val_auc: 0.7098\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0489 - auc: 0.7098 - val_loss: 0.1063 - val_auc: 0.7098\n",
      "Epoch 886/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0490 - auc: 0.7099 - val_loss: 0.1068 - val_auc: 0.7099\n",
      "Epoch 887/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0491 - auc: 0.7099 - val_loss: 0.1067 - val_auc: 0.7099\n",
      "Epoch 888/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0512 - auc: 0.7099 - val_loss: 0.1068 - val_auc: 0.7100\n",
      "Epoch 889/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0507 - auc: 0.7100 - val_loss: 0.1062 - val_auc: 0.7100\n",
      "Epoch 890/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0493 - auc: 0.7100 - val_loss: 0.1062 - val_auc: 0.7100\n",
      "Epoch 891/1000\n",
      "4059/4059 [==============================] - 0s 21us/step - loss: 0.0504 - auc: 0.7100 - val_loss: 0.1062 - val_auc: 0.7101\n",
      "Epoch 892/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0494 - auc: 0.7101 - val_loss: 0.1060 - val_auc: 0.7101\n",
      "Epoch 893/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0502 - auc: 0.7101 - val_loss: 0.1058 - val_auc: 0.7102\n",
      "Epoch 894/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0516 - auc: 0.7102 - val_loss: 0.1058 - val_auc: 0.7102\n",
      "Epoch 895/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0512 - auc: 0.7102 - val_loss: 0.1060 - val_auc: 0.7102\n",
      "Epoch 896/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0501 - auc: 0.7102 - val_loss: 0.1063 - val_auc: 0.7102\n",
      "Epoch 897/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0510 - auc: 0.7102 - val_loss: 0.1063 - val_auc: 0.7102\n",
      "Epoch 898/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0510 - auc: 0.7102 - val_loss: 0.1059 - val_auc: 0.7102\n",
      "Epoch 899/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0516 - auc: 0.7103 - val_loss: 0.1055 - val_auc: 0.7103\n",
      "Epoch 900/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0516 - auc: 0.7103 - val_loss: 0.1047 - val_auc: 0.7103\n",
      "Epoch 901/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0520 - auc: 0.7103 - val_loss: 0.1049 - val_auc: 0.7103\n",
      "Epoch 902/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0511 - auc: 0.7103 - val_loss: 0.1049 - val_auc: 0.7103\n",
      "Epoch 903/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0508 - auc: 0.7103 - val_loss: 0.1053 - val_auc: 0.7104\n",
      "Epoch 904/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0498 - auc: 0.7104 - val_loss: 0.1057 - val_auc: 0.7104\n",
      "Epoch 905/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0492 - auc: 0.7104 - val_loss: 0.1054 - val_auc: 0.7104\n",
      "Epoch 906/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0491 - auc: 0.7105 - val_loss: 0.1060 - val_auc: 0.7105\n",
      "Epoch 907/1000\n",
      "4059/4059 [==============================] - 0s 25us/step - loss: 0.0497 - auc: 0.7105 - val_loss: 0.1065 - val_auc: 0.7105\n",
      "Epoch 908/1000\n",
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0515 - auc: 0.7105 - val_loss: 0.1059 - val_auc: 0.7106\n",
      "Epoch 909/1000\n",
      "4059/4059 [==============================] - 0s 23us/step - loss: 0.0520 - auc: 0.7105 - val_loss: 0.1056 - val_auc: 0.7105\n",
      "Epoch 910/1000\n",
      "4059/4059 [==============================] - 0s 21us/step - loss: 0.0519 - auc: 0.7105 - val_loss: 0.1057 - val_auc: 0.7106\n",
      "Epoch 911/1000\n",
      "4059/4059 [==============================] - 0s 22us/step - loss: 0.0499 - auc: 0.7106 - val_loss: 0.1057 - val_auc: 0.7106\n",
      "Epoch 912/1000\n",
      "4059/4059 [==============================] - 0s 20us/step - loss: 0.0491 - auc: 0.7106 - val_loss: 0.1055 - val_auc: 0.7106\n",
      "Epoch 913/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0507 - auc: 0.7106 - val_loss: 0.1052 - val_auc: 0.7106\n",
      "Epoch 914/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0506 - auc: 0.7106 - val_loss: 0.1053 - val_auc: 0.7107\n",
      "Epoch 915/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0504 - auc: 0.7107 - val_loss: 0.1053 - val_auc: 0.7107\n",
      "Epoch 916/1000\n",
      "4059/4059 [==============================] - 0s 43us/step - loss: 0.0503 - auc: 0.7107 - val_loss: 0.1054 - val_auc: 0.7107\n",
      "Epoch 917/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0495 - auc: 0.7107 - val_loss: 0.1055 - val_auc: 0.7108\n",
      "Epoch 918/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0506 - auc: 0.7108 - val_loss: 0.1056 - val_auc: 0.7108\n",
      "Epoch 919/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0503 - auc: 0.7108 - val_loss: 0.1058 - val_auc: 0.7108\n",
      "Epoch 920/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0482 - auc: 0.7108 - val_loss: 0.1062 - val_auc: 0.7109\n",
      "Epoch 921/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0509 - auc: 0.7109 - val_loss: 0.1063 - val_auc: 0.7109\n",
      "Epoch 922/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0513 - auc: 0.7109 - val_loss: 0.1057 - val_auc: 0.7109\n",
      "Epoch 923/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0495 - auc: 0.7109 - val_loss: 0.1056 - val_auc: 0.7109\n",
      "Epoch 924/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0511 - auc: 0.7109 - val_loss: 0.1064 - val_auc: 0.7109\n",
      "Epoch 925/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0507 - auc: 0.7109 - val_loss: 0.1057 - val_auc: 0.7110\n",
      "Epoch 926/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0508 - auc: 0.7110 - val_loss: 0.1054 - val_auc: 0.7110\n",
      "Epoch 927/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0506 - auc: 0.7110 - val_loss: 0.1057 - val_auc: 0.7110\n",
      "Epoch 928/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0520 - auc: 0.7110 - val_loss: 0.1059 - val_auc: 0.7110\n",
      "Epoch 929/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0522 - auc: 0.7110 - val_loss: 0.1054 - val_auc: 0.7110\n",
      "Epoch 930/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0501 - auc: 0.7110 - val_loss: 0.1057 - val_auc: 0.7110\n",
      "Epoch 931/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0506 - auc: 0.7110 - val_loss: 0.1059 - val_auc: 0.7110\n",
      "Epoch 932/1000\n",
      "4059/4059 [==============================] - 0s 29us/step - loss: 0.0496 - auc: 0.7110 - val_loss: 0.1060 - val_auc: 0.7111\n",
      "Epoch 933/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0492 - auc: 0.7111 - val_loss: 0.1067 - val_auc: 0.7111\n",
      "Epoch 934/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0489 - auc: 0.7111 - val_loss: 0.1066 - val_auc: 0.7111\n",
      "Epoch 935/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0513 - auc: 0.7111 - val_loss: 0.1059 - val_auc: 0.7112\n",
      "Epoch 936/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0511 - auc: 0.7112 - val_loss: 0.1055 - val_auc: 0.7112\n",
      "Epoch 937/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0497 - auc: 0.7112 - val_loss: 0.1063 - val_auc: 0.7112\n",
      "Epoch 938/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0487 - auc: 0.7112 - val_loss: 0.1066 - val_auc: 0.7113\n",
      "Epoch 939/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0492 - auc: 0.7113 - val_loss: 0.1066 - val_auc: 0.7113\n",
      "Epoch 940/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0482 - auc: 0.7113 - val_loss: 0.1064 - val_auc: 0.7113\n",
      "Epoch 941/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0503 - auc: 0.7113 - val_loss: 0.1056 - val_auc: 0.7114\n",
      "Epoch 942/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0516 - auc: 0.7114 - val_loss: 0.1058 - val_auc: 0.7114\n",
      "Epoch 943/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0495 - auc: 0.7114 - val_loss: 0.1060 - val_auc: 0.7114\n",
      "Epoch 944/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 0s 26us/step - loss: 0.0485 - auc: 0.7114 - val_loss: 0.1070 - val_auc: 0.7115\n",
      "Epoch 945/1000\n",
      "4059/4059 [==============================] - 0s 27us/step - loss: 0.0506 - auc: 0.7114 - val_loss: 0.1069 - val_auc: 0.7115\n",
      "Epoch 946/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0511 - auc: 0.7115 - val_loss: 0.1064 - val_auc: 0.7115\n",
      "Epoch 947/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0514 - auc: 0.7115 - val_loss: 0.1059 - val_auc: 0.7115\n",
      "Epoch 948/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0502 - auc: 0.7115 - val_loss: 0.1059 - val_auc: 0.7115\n",
      "Epoch 949/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0492 - auc: 0.7115 - val_loss: 0.1064 - val_auc: 0.7116\n",
      "Epoch 950/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0511 - auc: 0.7115 - val_loss: 0.1062 - val_auc: 0.7116\n",
      "Epoch 951/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0502 - auc: 0.7116 - val_loss: 0.1062 - val_auc: 0.7116\n",
      "Epoch 952/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0519 - auc: 0.7116 - val_loss: 0.1060 - val_auc: 0.7116\n",
      "Epoch 953/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0513 - auc: 0.7116 - val_loss: 0.1058 - val_auc: 0.7116\n",
      "Epoch 954/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0486 - auc: 0.7116 - val_loss: 0.1054 - val_auc: 0.7116\n",
      "Epoch 955/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0505 - auc: 0.7116 - val_loss: 0.1061 - val_auc: 0.7117\n",
      "Epoch 956/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0512 - auc: 0.7116 - val_loss: 0.1056 - val_auc: 0.7117\n",
      "Epoch 957/1000\n",
      "4059/4059 [==============================] - 0s 40us/step - loss: 0.0497 - auc: 0.7117 - val_loss: 0.1054 - val_auc: 0.7117\n",
      "Epoch 958/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0499 - auc: 0.7117 - val_loss: 0.1052 - val_auc: 0.7117\n",
      "Epoch 959/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0491 - auc: 0.7118 - val_loss: 0.1060 - val_auc: 0.7118\n",
      "Epoch 960/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0509 - auc: 0.7118 - val_loss: 0.1058 - val_auc: 0.7118\n",
      "Epoch 961/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0506 - auc: 0.7118 - val_loss: 0.1056 - val_auc: 0.7118\n",
      "Epoch 962/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0496 - auc: 0.7119 - val_loss: 0.1055 - val_auc: 0.7119\n",
      "Epoch 963/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0490 - auc: 0.7119 - val_loss: 0.1060 - val_auc: 0.7119\n",
      "Epoch 964/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0510 - auc: 0.7119 - val_loss: 0.1061 - val_auc: 0.7120\n",
      "Epoch 965/1000\n",
      "4059/4059 [==============================] - 0s 41us/step - loss: 0.0507 - auc: 0.7119 - val_loss: 0.1056 - val_auc: 0.7120\n",
      "Epoch 966/1000\n",
      "4059/4059 [==============================] - 0s 39us/step - loss: 0.0504 - auc: 0.7120 - val_loss: 0.1054 - val_auc: 0.7120\n",
      "Epoch 967/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0510 - auc: 0.7120 - val_loss: 0.1063 - val_auc: 0.7120\n",
      "Epoch 968/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0499 - auc: 0.7120 - val_loss: 0.1065 - val_auc: 0.7120\n",
      "Epoch 969/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0491 - auc: 0.7120 - val_loss: 0.1062 - val_auc: 0.7120\n",
      "Epoch 970/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0494 - auc: 0.7120 - val_loss: 0.1063 - val_auc: 0.7121\n",
      "Epoch 971/1000\n",
      "4059/4059 [==============================] - 0s 38us/step - loss: 0.0507 - auc: 0.7120 - val_loss: 0.1062 - val_auc: 0.7121\n",
      "Epoch 972/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0495 - auc: 0.7121 - val_loss: 0.1060 - val_auc: 0.7121\n",
      "Epoch 973/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0498 - auc: 0.7121 - val_loss: 0.1061 - val_auc: 0.7121\n",
      "Epoch 974/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0509 - auc: 0.7121 - val_loss: 0.1054 - val_auc: 0.7121\n",
      "Epoch 975/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0508 - auc: 0.7121 - val_loss: 0.1054 - val_auc: 0.7122\n",
      "Epoch 976/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0499 - auc: 0.7122 - val_loss: 0.1056 - val_auc: 0.7122\n",
      "Epoch 977/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0501 - auc: 0.7122 - val_loss: 0.1055 - val_auc: 0.7122\n",
      "Epoch 978/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0489 - auc: 0.7122 - val_loss: 0.1055 - val_auc: 0.7122\n",
      "Epoch 979/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0504 - auc: 0.7122 - val_loss: 0.1056 - val_auc: 0.7122\n",
      "Epoch 980/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0497 - auc: 0.7122 - val_loss: 0.1059 - val_auc: 0.7123\n",
      "Epoch 981/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0503 - auc: 0.7123 - val_loss: 0.1062 - val_auc: 0.7123\n",
      "Epoch 982/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0497 - auc: 0.7123 - val_loss: 0.1053 - val_auc: 0.7123\n",
      "Epoch 983/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0511 - auc: 0.7123 - val_loss: 0.1048 - val_auc: 0.7123\n",
      "Epoch 984/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0504 - auc: 0.7123 - val_loss: 0.1058 - val_auc: 0.7123\n",
      "Epoch 985/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0492 - auc: 0.7124 - val_loss: 0.1055 - val_auc: 0.7124\n",
      "Epoch 986/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0498 - auc: 0.7124 - val_loss: 0.1052 - val_auc: 0.7124\n",
      "Epoch 987/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0505 - auc: 0.7124 - val_loss: 0.1053 - val_auc: 0.7124\n",
      "Epoch 988/1000\n",
      "4059/4059 [==============================] - 0s 34us/step - loss: 0.0496 - auc: 0.7124 - val_loss: 0.1058 - val_auc: 0.7125\n",
      "Epoch 989/1000\n",
      "4059/4059 [==============================] - 0s 30us/step - loss: 0.0490 - auc: 0.7125 - val_loss: 0.1059 - val_auc: 0.7125\n",
      "Epoch 990/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0517 - auc: 0.7125 - val_loss: 0.1059 - val_auc: 0.7125\n",
      "Epoch 991/1000\n",
      "4059/4059 [==============================] - 0s 32us/step - loss: 0.0499 - auc: 0.7125 - val_loss: 0.1053 - val_auc: 0.7126\n",
      "Epoch 992/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0486 - auc: 0.7126 - val_loss: 0.1061 - val_auc: 0.7126\n",
      "Epoch 993/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0490 - auc: 0.7126 - val_loss: 0.1066 - val_auc: 0.7126\n",
      "Epoch 994/1000\n",
      "4059/4059 [==============================] - 0s 33us/step - loss: 0.0514 - auc: 0.7126 - val_loss: 0.1064 - val_auc: 0.7126\n",
      "Epoch 995/1000\n",
      "4059/4059 [==============================] - 0s 28us/step - loss: 0.0503 - auc: 0.7126 - val_loss: 0.1060 - val_auc: 0.7126\n",
      "Epoch 996/1000\n",
      "4059/4059 [==============================] - 0s 35us/step - loss: 0.0507 - auc: 0.7126 - val_loss: 0.1060 - val_auc: 0.7126\n",
      "Epoch 997/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0495 - auc: 0.7126 - val_loss: 0.1056 - val_auc: 0.7127\n",
      "Epoch 998/1000\n",
      "4059/4059 [==============================] - 0s 31us/step - loss: 0.0511 - auc: 0.7127 - val_loss: 0.1061 - val_auc: 0.7127\n",
      "Epoch 999/1000\n",
      "4059/4059 [==============================] - 0s 36us/step - loss: 0.0499 - auc: 0.7127 - val_loss: 0.1060 - val_auc: 0.7127\n",
      "Epoch 1000/1000\n",
      "4059/4059 [==============================] - 0s 37us/step - loss: 0.0504 - auc: 0.7127 - val_loss: 0.1065 - val_auc: 0.7127\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "sgd = Adam()\n",
    "\n",
    "model_5.compile(loss=\"binary_crossentropy\", optimizer = sgd, metrics=[auc_metric])\n",
    "history_5 = model_5.fit(X_trains, y_train, batch_size=256, epochs=1000, verbose=1, validation_split=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_5 = model_5.predict(X_tests)[:, 0]\n",
    "fpr_5, tpr_5, thresholds_5 = roc_curve(y_test, y_pred_5)\n",
    "\n",
    "roc_auc_5 = auc(fpr_5, tpr_5)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_5, tpr_5, 'b',label='AUC = %0.3f'% roc_auc_5)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "model_6 = LinearDiscriminantAnalysis()\n",
    "model_6.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_6 = model_6.predict_proba(X_test_red)[:, 1]\n",
    "\n",
    "fpr_6, tpr_6, thresholds_6 = roc_curve(y_test, y_pred_6)\n",
    "\n",
    "roc_auc_6 = auc(fpr_6, tpr_6)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_6, tpr_6, 'b',label='AUC = %0.3f'% roc_auc_6)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndoannguyen\\AppData\\Local\\Continuum\\miniconda3\\envs\\py35\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "model_7 = QuadraticDiscriminantAnalysis()\n",
    "model_7.fit(X_train_red, y_train)\n",
    "\n",
    "y_pred_7 = model_7.predict_proba(X_test_red)[:, 1]\n",
    "\n",
    "fpr_7, tpr_7, thresholds_7 = roc_curve(y_test, y_pred_7)\n",
    "\n",
    "roc_auc_7 = auc(fpr_7, tpr_7)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_7, tpr_7, 'b',label='AUC = %0.3f'% roc_auc_7)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 640 out of 640 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "parameters_8 = {\n",
    "    'max_depth': [2, 3, 4, 5, 8, 10, 15, 20],\n",
    "    'max_leaf_nodes': [2, 3, 4, 5, 8, 10, 15, 20],\n",
    "    'class_weight': [None, 'balanced']   \n",
    "}\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "model_8 = DecisionTreeClassifier()\n",
    "clf_8 = GridSearchCV(model_8, parameters_8, cv=5, verbose=5, n_jobs=4, scoring = 'roc_auc', return_train_score = True)\n",
    "clf_8.fit(X_train_red, y_train)\n",
    "\n",
    "result_8 = clf_8.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean on train</th>\n",
       "      <td>0.509922</td>\n",
       "      <td>0.541773</td>\n",
       "      <td>0.596375</td>\n",
       "      <td>0.611781</td>\n",
       "      <td>0.611781</td>\n",
       "      <td>0.611781</td>\n",
       "      <td>0.611781</td>\n",
       "      <td>0.611781</td>\n",
       "      <td>0.509922</td>\n",
       "      <td>0.541773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861018</td>\n",
       "      <td>0.889346</td>\n",
       "      <td>0.634317</td>\n",
       "      <td>0.711281</td>\n",
       "      <td>0.748773</td>\n",
       "      <td>0.762919</td>\n",
       "      <td>0.802154</td>\n",
       "      <td>0.824006</td>\n",
       "      <td>0.861018</td>\n",
       "      <td>0.889346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_on_test</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503404</td>\n",
       "      <td>0.518027</td>\n",
       "      <td>0.530404</td>\n",
       "      <td>0.530404</td>\n",
       "      <td>0.530404</td>\n",
       "      <td>0.530404</td>\n",
       "      <td>0.530404</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627608</td>\n",
       "      <td>0.604026</td>\n",
       "      <td>0.552684</td>\n",
       "      <td>0.600175</td>\n",
       "      <td>0.634311</td>\n",
       "      <td>0.616125</td>\n",
       "      <td>0.63898</td>\n",
       "      <td>0.661751</td>\n",
       "      <td>0.627608</td>\n",
       "      <td>0.604026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4          5    \\\n",
       "max_depth       2.000000  2.000000  2.000000  2.000000  2.000000   2.000000   \n",
       "max_leaf_nodes  2.000000  3.000000  4.000000  5.000000  8.000000  10.000000   \n",
       "class_weight         NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "mean on train   0.509922  0.541773  0.596375  0.611781  0.611781   0.611781   \n",
       "mean_on_test    0.500000  0.503404  0.518027  0.530404  0.530404   0.530404   \n",
       "\n",
       "                      6          7         8         9      ...          118  \\\n",
       "max_depth        2.000000   2.000000  3.000000  3.000000    ...           15   \n",
       "max_leaf_nodes  15.000000  20.000000  2.000000  3.000000    ...           15   \n",
       "class_weight          NaN        NaN       NaN       NaN    ...     balanced   \n",
       "mean on train    0.611781   0.611781  0.509922  0.541773    ...     0.861018   \n",
       "mean_on_test     0.530404   0.530404  0.500000  0.503404    ...     0.627608   \n",
       "\n",
       "                     119       120       121       122       123       124  \\\n",
       "max_depth             15        20        20        20        20        20   \n",
       "max_leaf_nodes        20         2         3         4         5         8   \n",
       "class_weight    balanced  balanced  balanced  balanced  balanced  balanced   \n",
       "mean on train   0.889346  0.634317  0.711281  0.748773  0.762919  0.802154   \n",
       "mean_on_test    0.604026  0.552684  0.600175  0.634311  0.616125   0.63898   \n",
       "\n",
       "                     125       126       127  \n",
       "max_depth             20        20        20  \n",
       "max_leaf_nodes        10        15        20  \n",
       "class_weight    balanced  balanced  balanced  \n",
       "mean on train   0.824006  0.861018  0.889346  \n",
       "mean_on_test    0.661751  0.627608  0.604026  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([result_8['param_' + param] for param in parameters_8] + [result_8['mean_train_score'], result_8['mean_test_score']], index=list(parameters_8.keys()) + ['mean on train', 'mean_on_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced', 'max_depth': 8, 'max_leaf_nodes': 10}"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_8.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,\n",
       "            max_features=None, max_leaf_nodes=10,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "model_8_best = DecisionTreeClassifier(max_depth = clf_8.best_params_['max_depth'], max_leaf_nodes=clf_8.best_params_['max_leaf_nodes'], class_weight=clf_8.best_params_['class_weight'])\n",
    "model_8_best.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_8 = model_8_best.predict_proba(X_test_red)[:, 1]\n",
    "\n",
    "fpr_8, tpr_8, thresholds_8 = roc_curve(y_test, y_pred_8)\n",
    "\n",
    "roc_auc_8 = auc(fpr_8, tpr_8)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_8, tpr_8, 'b',label='AUC = %0.3f'% roc_auc_8)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:   10.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "parameters_9 = {\n",
    "    'n_estimators': [5, 10, 20, 40],\n",
    "    'max_features': [ 0.5, 0.75, 1.0],\n",
    "    'max_samples': [0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "model_9 = BaggingClassifier(DecisionTreeClassifier(max_depth = clf_8.best_params_['max_depth'], max_leaf_nodes=clf_8.best_params_['max_leaf_nodes'], class_weight=clf_8.best_params_['class_weight']), random_state = RANDOM_SEED)\n",
    "clf_9 = GridSearchCV(model_9, parameters_9, cv=5, verbose=5, n_jobs=4, scoring = 'roc_auc', return_train_score = True)\n",
    "clf_9.fit(X_train, y_train)\n",
    "\n",
    "result_9 = clf_9.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_features</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_samples</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean on train</th>\n",
       "      <td>0.857753</td>\n",
       "      <td>0.898645</td>\n",
       "      <td>0.917548</td>\n",
       "      <td>0.931021</td>\n",
       "      <td>0.878606</td>\n",
       "      <td>0.917275</td>\n",
       "      <td>0.927838</td>\n",
       "      <td>0.936844</td>\n",
       "      <td>0.886162</td>\n",
       "      <td>0.925956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927357</td>\n",
       "      <td>0.935157</td>\n",
       "      <td>0.895510</td>\n",
       "      <td>0.917737</td>\n",
       "      <td>0.928956</td>\n",
       "      <td>0.934975</td>\n",
       "      <td>0.901551</td>\n",
       "      <td>0.922634</td>\n",
       "      <td>0.937092</td>\n",
       "      <td>0.939347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_on_test</th>\n",
       "      <td>0.684829</td>\n",
       "      <td>0.746023</td>\n",
       "      <td>0.745171</td>\n",
       "      <td>0.734691</td>\n",
       "      <td>0.697768</td>\n",
       "      <td>0.729330</td>\n",
       "      <td>0.731003</td>\n",
       "      <td>0.726705</td>\n",
       "      <td>0.693661</td>\n",
       "      <td>0.712385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698794</td>\n",
       "      <td>0.699039</td>\n",
       "      <td>0.655106</td>\n",
       "      <td>0.726092</td>\n",
       "      <td>0.715327</td>\n",
       "      <td>0.716327</td>\n",
       "      <td>0.714690</td>\n",
       "      <td>0.717781</td>\n",
       "      <td>0.712481</td>\n",
       "      <td>0.714097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0          1          2          3         4          5   \\\n",
       "max_features   0.500000   0.500000   0.500000   0.500000  0.500000   0.500000   \n",
       "n_estimators   5.000000  10.000000  20.000000  40.000000  5.000000  10.000000   \n",
       "max_samples    0.500000   0.500000   0.500000   0.500000  0.750000   0.750000   \n",
       "mean on train  0.857753   0.898645   0.917548   0.931021  0.878606   0.917275   \n",
       "mean_on_test   0.684829   0.746023   0.745171   0.734691  0.697768   0.729330   \n",
       "\n",
       "                      6          7         8          9     ...      \\\n",
       "max_features    0.500000   0.500000  0.500000   0.500000    ...       \n",
       "n_estimators   20.000000  40.000000  5.000000  10.000000    ...       \n",
       "max_samples     0.750000   0.750000  1.000000   1.000000    ...       \n",
       "mean on train   0.927838   0.936844  0.886162   0.925956    ...       \n",
       "mean_on_test    0.731003   0.726705  0.693661   0.712385    ...       \n",
       "\n",
       "                      26         27        28         29         30  \\\n",
       "max_features    1.000000   1.000000  1.000000   1.000000   1.000000   \n",
       "n_estimators   20.000000  40.000000  5.000000  10.000000  20.000000   \n",
       "max_samples     0.500000   0.500000  0.750000   0.750000   0.750000   \n",
       "mean on train   0.927357   0.935157  0.895510   0.917737   0.928956   \n",
       "mean_on_test    0.698794   0.699039  0.655106   0.726092   0.715327   \n",
       "\n",
       "                      31        32         33         34         35  \n",
       "max_features    1.000000  1.000000   1.000000   1.000000   1.000000  \n",
       "n_estimators   40.000000  5.000000  10.000000  20.000000  40.000000  \n",
       "max_samples     0.750000  1.000000   1.000000   1.000000   1.000000  \n",
       "mean on train   0.934975  0.901551   0.922634   0.937092   0.939347  \n",
       "mean_on_test    0.716327  0.714690   0.717781   0.712481   0.714097  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([result_9['param_' + param] for param in parameters_9] + [result_9['mean_train_score'], result_9['mean_test_score']], index=list(parameters_9.keys()) + ['mean on train', 'mean_on_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.5, 'max_samples': 0.5, 'n_estimators': 10}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_9.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,\n",
       "            max_features=None, max_leaf_nodes=10,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "         max_samples=0.5, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "model_9_best = BaggingClassifier(DecisionTreeClassifier(max_depth = clf_8.best_params_['max_depth'], max_leaf_nodes=clf_8.best_params_['max_leaf_nodes'], class_weight=clf_8.best_params_['class_weight']), \n",
    "                                max_features = clf_9.best_params_['max_features'], max_samples = clf_9.best_params_['max_samples'], n_estimators = clf_9.best_params_['n_estimators'], random_state = RANDOM_SEED)\n",
    "model_9_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_9 = model_9_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr_9, tpr_9, thresholds_9 = roc_curve(y_test, y_pred_9)\n",
    "\n",
    "roc_auc_9 = auc(fpr_9, tpr_9)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_9, tpr_9, 'b',label='AUC = %0.3f'% roc_auc_9)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging with Decision Trees - With Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 150 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    5.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "parameters_10 = {\n",
    "    'n_estimators': [5, 10, 20, 40],\n",
    "    'max_features': [ 0.5, 0.75, 1.0],\n",
    "    'max_samples': [0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "model_10 = BaggingClassifier(DecisionTreeClassifier(max_depth = clf_8.best_params_['max_depth'], max_leaf_nodes=clf_8.best_params_['max_leaf_nodes'], class_weight=clf_8.best_params_['class_weight']), random_state = RANDOM_SEED)\n",
    "clf_10 = GridSearchCV(model_10, parameters_10, cv=5, verbose=5, n_jobs=4, scoring = 'roc_auc', return_train_score = True)\n",
    "clf_10.fit(X_train_red, y_train)\n",
    "\n",
    "result_10 = clf_10.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_features</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_samples</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean on train</th>\n",
       "      <td>0.818835</td>\n",
       "      <td>0.866834</td>\n",
       "      <td>0.893589</td>\n",
       "      <td>0.903443</td>\n",
       "      <td>0.831693</td>\n",
       "      <td>0.874416</td>\n",
       "      <td>0.898453</td>\n",
       "      <td>0.905361</td>\n",
       "      <td>0.856581</td>\n",
       "      <td>0.885750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893973</td>\n",
       "      <td>0.899931</td>\n",
       "      <td>0.877825</td>\n",
       "      <td>0.892234</td>\n",
       "      <td>0.901536</td>\n",
       "      <td>0.904068</td>\n",
       "      <td>0.877102</td>\n",
       "      <td>0.894147</td>\n",
       "      <td>0.907621</td>\n",
       "      <td>0.906393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_on_test</th>\n",
       "      <td>0.664826</td>\n",
       "      <td>0.700060</td>\n",
       "      <td>0.728794</td>\n",
       "      <td>0.735205</td>\n",
       "      <td>0.679292</td>\n",
       "      <td>0.708790</td>\n",
       "      <td>0.727193</td>\n",
       "      <td>0.737232</td>\n",
       "      <td>0.698952</td>\n",
       "      <td>0.721534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712498</td>\n",
       "      <td>0.706959</td>\n",
       "      <td>0.658364</td>\n",
       "      <td>0.699999</td>\n",
       "      <td>0.702159</td>\n",
       "      <td>0.719219</td>\n",
       "      <td>0.647355</td>\n",
       "      <td>0.708125</td>\n",
       "      <td>0.705676</td>\n",
       "      <td>0.715057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0          1          2          3         4          5   \\\n",
       "max_features   0.500000   0.500000   0.500000   0.500000  0.500000   0.500000   \n",
       "n_estimators   5.000000  10.000000  20.000000  40.000000  5.000000  10.000000   \n",
       "max_samples    0.500000   0.500000   0.500000   0.500000  0.750000   0.750000   \n",
       "mean on train  0.818835   0.866834   0.893589   0.903443  0.831693   0.874416   \n",
       "mean_on_test   0.664826   0.700060   0.728794   0.735205  0.679292   0.708790   \n",
       "\n",
       "                      6          7         8          9     ...      \\\n",
       "max_features    0.500000   0.500000  0.500000   0.500000    ...       \n",
       "n_estimators   20.000000  40.000000  5.000000  10.000000    ...       \n",
       "max_samples     0.750000   0.750000  1.000000   1.000000    ...       \n",
       "mean on train   0.898453   0.905361  0.856581   0.885750    ...       \n",
       "mean_on_test    0.727193   0.737232  0.698952   0.721534    ...       \n",
       "\n",
       "                      26         27        28         29         30  \\\n",
       "max_features    1.000000   1.000000  1.000000   1.000000   1.000000   \n",
       "n_estimators   20.000000  40.000000  5.000000  10.000000  20.000000   \n",
       "max_samples     0.500000   0.500000  0.750000   0.750000   0.750000   \n",
       "mean on train   0.893973   0.899931  0.877825   0.892234   0.901536   \n",
       "mean_on_test    0.712498   0.706959  0.658364   0.699999   0.702159   \n",
       "\n",
       "                      31        32         33         34         35  \n",
       "max_features    1.000000  1.000000   1.000000   1.000000   1.000000  \n",
       "n_estimators   40.000000  5.000000  10.000000  20.000000  40.000000  \n",
       "max_samples     0.750000  1.000000   1.000000   1.000000   1.000000  \n",
       "mean on train   0.904068  0.877102   0.894147   0.907621   0.906393  \n",
       "mean_on_test    0.719219  0.647355   0.708125   0.705676   0.715057  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([result_10['param_' + param] for param in parameters_10] + [result_10['mean_train_score'], result_10['mean_test_score']], index=list(parameters_10.keys()) + ['mean on train', 'mean_on_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 40}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_10.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,\n",
       "            max_features=None, max_leaf_nodes=10,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "         max_samples=1.0, n_estimators=40, n_jobs=1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "model_10_best = BaggingClassifier(DecisionTreeClassifier(max_depth = clf_8.best_params_['max_depth'], max_leaf_nodes=clf_8.best_params_['max_leaf_nodes'], class_weight=clf_8.best_params_['class_weight']), \n",
    "                                max_features = clf_10.best_params_['max_features'], max_samples = clf_10.best_params_['max_samples'], n_estimators = clf_10.best_params_['n_estimators'], random_state = RANDOM_SEED)\n",
    "model_10_best.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_10 = model_10_best.predict_proba(X_test_red)[:, 1]\n",
    "\n",
    "fpr_10, tpr_10, thresholds_10 = roc_curve(y_test, y_pred_10)\n",
    "\n",
    "roc_auc_10 = auc(fpr_10, tpr_10)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_10, tpr_10, 'b',label='AUC = %0.3f'% roc_auc_10)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 380 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=4)]: Done 640 out of 640 | elapsed:    5.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters_11 = {\n",
    "    'max_depth': [2, 3, 4, 5, 8, 10, 15, 20],\n",
    "    'max_leaf_nodes': [2, 3, 4, 5, 8, 10, 15, 20],\n",
    "    'class_weight': [None, 'balanced']   \n",
    "}\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "model_11 = RandomForestClassifier(random_state = 0)\n",
    "clf_11 = GridSearchCV(model_11, parameters_11, cv=5, verbose=5, n_jobs=4, scoring = 'roc_auc', return_train_score = True)\n",
    "clf_11.fit(X_train_red, y_train)\n",
    "\n",
    "result_11 = clf_11.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean on train</th>\n",
       "      <td>0.712899</td>\n",
       "      <td>0.759841</td>\n",
       "      <td>0.770116</td>\n",
       "      <td>0.782008</td>\n",
       "      <td>0.803801</td>\n",
       "      <td>0.803801</td>\n",
       "      <td>0.803801</td>\n",
       "      <td>0.803801</td>\n",
       "      <td>0.712899</td>\n",
       "      <td>0.759841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910789</td>\n",
       "      <td>0.93479</td>\n",
       "      <td>0.743539</td>\n",
       "      <td>0.780511</td>\n",
       "      <td>0.800045</td>\n",
       "      <td>0.817173</td>\n",
       "      <td>0.854799</td>\n",
       "      <td>0.871634</td>\n",
       "      <td>0.910789</td>\n",
       "      <td>0.93479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_on_test</th>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.663837</td>\n",
       "      <td>0.679885</td>\n",
       "      <td>0.706786</td>\n",
       "      <td>0.717805</td>\n",
       "      <td>0.717805</td>\n",
       "      <td>0.717805</td>\n",
       "      <td>0.717805</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.663837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735841</td>\n",
       "      <td>0.730603</td>\n",
       "      <td>0.69525</td>\n",
       "      <td>0.726806</td>\n",
       "      <td>0.743937</td>\n",
       "      <td>0.733768</td>\n",
       "      <td>0.739543</td>\n",
       "      <td>0.740804</td>\n",
       "      <td>0.735841</td>\n",
       "      <td>0.730603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4          5    \\\n",
       "max_depth       2.000000  2.000000  2.000000  2.000000  2.000000   2.000000   \n",
       "max_leaf_nodes  2.000000  3.000000  4.000000  5.000000  8.000000  10.000000   \n",
       "class_weight         NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "mean on train   0.712899  0.759841  0.770116  0.782008  0.803801   0.803801   \n",
       "mean_on_test    0.672566  0.663837  0.679885  0.706786  0.717805   0.717805   \n",
       "\n",
       "                      6          7         8         9      ...          118  \\\n",
       "max_depth        2.000000   2.000000  3.000000  3.000000    ...           15   \n",
       "max_leaf_nodes  15.000000  20.000000  2.000000  3.000000    ...           15   \n",
       "class_weight          NaN        NaN       NaN       NaN    ...     balanced   \n",
       "mean on train    0.803801   0.803801  0.712899  0.759841    ...     0.910789   \n",
       "mean_on_test     0.717805   0.717805  0.672566  0.663837    ...     0.735841   \n",
       "\n",
       "                     119       120       121       122       123       124  \\\n",
       "max_depth             15        20        20        20        20        20   \n",
       "max_leaf_nodes        20         2         3         4         5         8   \n",
       "class_weight    balanced  balanced  balanced  balanced  balanced  balanced   \n",
       "mean on train    0.93479  0.743539  0.780511  0.800045  0.817173  0.854799   \n",
       "mean_on_test    0.730603   0.69525  0.726806  0.743937  0.733768  0.739543   \n",
       "\n",
       "                     125       126       127  \n",
       "max_depth             20        20        20  \n",
       "max_leaf_nodes        10        15        20  \n",
       "class_weight    balanced  balanced  balanced  \n",
       "mean on train   0.871634  0.910789   0.93479  \n",
       "mean_on_test    0.740804  0.735841  0.730603  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([result_11['param_' + param] for param in parameters_11] + [result_11['mean_train_score'], result_11['mean_test_score']], index=list(parameters_11.keys()) + ['mean on train', 'mean_on_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=4, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "model_11_best = DecisionTreeClassifier(max_depth = clf_11.best_params_['max_depth'], max_leaf_nodes=clf_11.best_params_['max_leaf_nodes'], class_weight=clf_11.best_params_['class_weight'], random_state = RANDOM_SEED)\n",
    "model_11_best.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_11 = model_11_best.predict_proba(X_test_red)[:, 1]\n",
    "\n",
    "fpr_11, tpr_11, thresholds_11 = roc_curve(y_test, y_pred_11)\n",
    "\n",
    "roc_auc_11 = auc(fpr_11, tpr_11)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_11, tpr_11, 'b',label='AUC = %0.3f'% roc_auc_11)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging with Other Classifiers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=4)]: Done 252 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=4)]: Done 540 out of 540 | elapsed:   22.2s finished\n"
     ]
    }
   ],
   "source": [
    "parameters_12 = {\n",
    "    'base_estimator': [LogisticRegression(C = 0.1, penalty='l1'), \n",
    "                        DecisionTreeClassifier(max_depth = clf_8.best_params_['max_depth'], max_leaf_nodes=clf_8.best_params_['max_leaf_nodes'], class_weight=clf_8.best_params_['class_weight'], random_state=RANDOM_SEED),\n",
    "                        LinearDiscriminantAnalysis()],\n",
    "    'n_estimators': [5, 10, 20, 40],\n",
    "    'max_features': [ 0.5, 0.75, 1.0],\n",
    "    'max_samples': [0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "model_12 = BaggingClassifier(random_state = RANDOM_SEED)\n",
    "clf_12 = GridSearchCV(model_12, parameters_12, cv=5, verbose=5, n_jobs=4, scoring = 'roc_auc', return_train_score = True)\n",
    "clf_12.fit(X_train_red, y_train)\n",
    "\n",
    "result_12 = clf_12.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_features</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_samples</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_estimator</th>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean on train</th>\n",
       "      <td>0.751038</td>\n",
       "      <td>0.762304</td>\n",
       "      <td>0.764055</td>\n",
       "      <td>0.766079</td>\n",
       "      <td>0.758541</td>\n",
       "      <td>0.768348</td>\n",
       "      <td>0.77077</td>\n",
       "      <td>0.770968</td>\n",
       "      <td>0.764822</td>\n",
       "      <td>0.770412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749952</td>\n",
       "      <td>0.746067</td>\n",
       "      <td>0.759908</td>\n",
       "      <td>0.763749</td>\n",
       "      <td>0.759079</td>\n",
       "      <td>0.755612</td>\n",
       "      <td>0.76644</td>\n",
       "      <td>0.765818</td>\n",
       "      <td>0.765138</td>\n",
       "      <td>0.760553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_on_test</th>\n",
       "      <td>0.732353</td>\n",
       "      <td>0.748615</td>\n",
       "      <td>0.739673</td>\n",
       "      <td>0.737462</td>\n",
       "      <td>0.739171</td>\n",
       "      <td>0.748024</td>\n",
       "      <td>0.740402</td>\n",
       "      <td>0.739847</td>\n",
       "      <td>0.740058</td>\n",
       "      <td>0.746216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723034</td>\n",
       "      <td>0.723428</td>\n",
       "      <td>0.706616</td>\n",
       "      <td>0.730403</td>\n",
       "      <td>0.727611</td>\n",
       "      <td>0.732677</td>\n",
       "      <td>0.697887</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.714879</td>\n",
       "      <td>0.715334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              0    \\\n",
       "max_features                                                  0.5   \n",
       "n_estimators                                                    5   \n",
       "max_samples                                                   0.5   \n",
       "base_estimator  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "mean on train                                            0.751038   \n",
       "mean_on_test                                             0.732353   \n",
       "\n",
       "                                                              1    \\\n",
       "max_features                                                  0.5   \n",
       "n_estimators                                                   10   \n",
       "max_samples                                                   0.5   \n",
       "base_estimator  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "mean on train                                            0.762304   \n",
       "mean_on_test                                             0.748615   \n",
       "\n",
       "                                                              2    \\\n",
       "max_features                                                  0.5   \n",
       "n_estimators                                                   20   \n",
       "max_samples                                                   0.5   \n",
       "base_estimator  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "mean on train                                            0.764055   \n",
       "mean_on_test                                             0.739673   \n",
       "\n",
       "                                                              3    \\\n",
       "max_features                                                  0.5   \n",
       "n_estimators                                                   40   \n",
       "max_samples                                                   0.5   \n",
       "base_estimator  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "mean on train                                            0.766079   \n",
       "mean_on_test                                             0.737462   \n",
       "\n",
       "                                                              4    \\\n",
       "max_features                                                  0.5   \n",
       "n_estimators                                                    5   \n",
       "max_samples                                                  0.75   \n",
       "base_estimator  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "mean on train                                            0.758541   \n",
       "mean_on_test                                             0.739171   \n",
       "\n",
       "                                                              5    \\\n",
       "max_features                                                  0.5   \n",
       "n_estimators                                                   10   \n",
       "max_samples                                                  0.75   \n",
       "base_estimator  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "mean on train                                            0.768348   \n",
       "mean_on_test                                             0.748024   \n",
       "\n",
       "                                                              6    \\\n",
       "max_features                                                  0.5   \n",
       "n_estimators                                                   20   \n",
       "max_samples                                                  0.75   \n",
       "base_estimator  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "mean on train                                             0.77077   \n",
       "mean_on_test                                             0.740402   \n",
       "\n",
       "                                                              7    \\\n",
       "max_features                                                  0.5   \n",
       "n_estimators                                                   40   \n",
       "max_samples                                                  0.75   \n",
       "base_estimator  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "mean on train                                            0.770968   \n",
       "mean_on_test                                             0.739847   \n",
       "\n",
       "                                                              8    \\\n",
       "max_features                                                  0.5   \n",
       "n_estimators                                                    5   \n",
       "max_samples                                                     1   \n",
       "base_estimator  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "mean on train                                            0.764822   \n",
       "mean_on_test                                             0.740058   \n",
       "\n",
       "                                                              9    \\\n",
       "max_features                                                  0.5   \n",
       "n_estimators                                                   10   \n",
       "max_samples                                                     1   \n",
       "base_estimator  LogisticRegression(C=0.1, class_weight=None, d...   \n",
       "mean on train                                            0.770412   \n",
       "mean_on_test                                             0.746216   \n",
       "\n",
       "                                      ...                          \\\n",
       "max_features                          ...                           \n",
       "n_estimators                          ...                           \n",
       "max_samples                           ...                           \n",
       "base_estimator                        ...                           \n",
       "mean on train                         ...                           \n",
       "mean_on_test                          ...                           \n",
       "\n",
       "                                                              98   \\\n",
       "max_features                                                    1   \n",
       "n_estimators                                                   20   \n",
       "max_samples                                                   0.5   \n",
       "base_estimator  LinearDiscriminantAnalysis(n_components=None, ...   \n",
       "mean on train                                            0.749952   \n",
       "mean_on_test                                             0.723034   \n",
       "\n",
       "                                                              99   \\\n",
       "max_features                                                    1   \n",
       "n_estimators                                                   40   \n",
       "max_samples                                                   0.5   \n",
       "base_estimator  LinearDiscriminantAnalysis(n_components=None, ...   \n",
       "mean on train                                            0.746067   \n",
       "mean_on_test                                             0.723428   \n",
       "\n",
       "                                                              100  \\\n",
       "max_features                                                    1   \n",
       "n_estimators                                                    5   \n",
       "max_samples                                                  0.75   \n",
       "base_estimator  LinearDiscriminantAnalysis(n_components=None, ...   \n",
       "mean on train                                            0.759908   \n",
       "mean_on_test                                             0.706616   \n",
       "\n",
       "                                                              101  \\\n",
       "max_features                                                    1   \n",
       "n_estimators                                                   10   \n",
       "max_samples                                                  0.75   \n",
       "base_estimator  LinearDiscriminantAnalysis(n_components=None, ...   \n",
       "mean on train                                            0.763749   \n",
       "mean_on_test                                             0.730403   \n",
       "\n",
       "                                                              102  \\\n",
       "max_features                                                    1   \n",
       "n_estimators                                                   20   \n",
       "max_samples                                                  0.75   \n",
       "base_estimator  LinearDiscriminantAnalysis(n_components=None, ...   \n",
       "mean on train                                            0.759079   \n",
       "mean_on_test                                             0.727611   \n",
       "\n",
       "                                                              103  \\\n",
       "max_features                                                    1   \n",
       "n_estimators                                                   40   \n",
       "max_samples                                                  0.75   \n",
       "base_estimator  LinearDiscriminantAnalysis(n_components=None, ...   \n",
       "mean on train                                            0.755612   \n",
       "mean_on_test                                             0.732677   \n",
       "\n",
       "                                                              104  \\\n",
       "max_features                                                    1   \n",
       "n_estimators                                                    5   \n",
       "max_samples                                                     1   \n",
       "base_estimator  LinearDiscriminantAnalysis(n_components=None, ...   \n",
       "mean on train                                             0.76644   \n",
       "mean_on_test                                             0.697887   \n",
       "\n",
       "                                                              105  \\\n",
       "max_features                                                    1   \n",
       "n_estimators                                                   10   \n",
       "max_samples                                                     1   \n",
       "base_estimator  LinearDiscriminantAnalysis(n_components=None, ...   \n",
       "mean on train                                            0.765818   \n",
       "mean_on_test                                             0.716377   \n",
       "\n",
       "                                                              106  \\\n",
       "max_features                                                    1   \n",
       "n_estimators                                                   20   \n",
       "max_samples                                                     1   \n",
       "base_estimator  LinearDiscriminantAnalysis(n_components=None, ...   \n",
       "mean on train                                            0.765138   \n",
       "mean_on_test                                             0.714879   \n",
       "\n",
       "                                                              107  \n",
       "max_features                                                    1  \n",
       "n_estimators                                                   40  \n",
       "max_samples                                                     1  \n",
       "base_estimator  LinearDiscriminantAnalysis(n_components=None, ...  \n",
       "mean on train                                            0.760553  \n",
       "mean_on_test                                             0.715334  \n",
       "\n",
       "[6 rows x 108 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([result_12['param_' + param] for param in parameters_12] + [result_12['mean_train_score'], result_12['mean_test_score']], index=list(parameters_12.keys()) + ['mean on train', 'mean_on_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'max_features': 0.5,\n",
       " 'max_samples': 0.5,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_12.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "         max_samples=0.5, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "model_12_best = BaggingClassifier(base_estimator=clf_12.best_params_['base_estimator'], \n",
    "                                max_features = clf_12.best_params_['max_features'], max_samples = clf_12.best_params_['max_samples'], n_estimators = clf_12.best_params_['n_estimators'], random_state = RANDOM_SEED)\n",
    "model_12_best.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_12 = model_12_best.predict_proba(X_test_red)[:, 1]\n",
    "\n",
    "fpr_12, tpr_12, thresholds_12 = roc_curve(y_test, y_pred_12)\n",
    "\n",
    "roc_auc_12 = auc(fpr_12, tpr_12)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_12, tpr_12, 'b',label='AUC = %0.3f'% roc_auc_12)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    9.1s finished\n"
     ]
    }
   ],
   "source": [
    "parameters_13 = {\n",
    "    'base_estimator': [ DecisionTreeClassifier(max_depth = clf_8.best_params_['max_depth'], max_leaf_nodes=clf_8.best_params_['max_leaf_nodes'], class_weight=clf_8.best_params_['class_weight']), RandomForestClassifier(max_depth = clf_11.best_params_['max_depth'], max_leaf_nodes=clf_11.best_params_['max_leaf_nodes'], class_weight=clf_11.best_params_['class_weight'])],\n",
    "    'n_estimators': [5, 10, 20],\n",
    "    'learning_rate': [ 0.5, 0.75, 1.0],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "model_13 = AdaBoostClassifier(random_state = RANDOM_SEED)\n",
    "clf_13 = GridSearchCV(model_13, parameters_13, cv=5, verbose=5, n_jobs=4, scoring = 'roc_auc', return_train_score = True)\n",
    "clf_13.fit(X_train_red, y_train)\n",
    "\n",
    "result_13 = clf_13.cv_results_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_estimator</th>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>...</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <td>SAMME</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>SAMME.R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean on train</th>\n",
       "      <td>0.840142</td>\n",
       "      <td>0.846332</td>\n",
       "      <td>0.846332</td>\n",
       "      <td>0.872404</td>\n",
       "      <td>0.877572</td>\n",
       "      <td>0.877572</td>\n",
       "      <td>0.877733</td>\n",
       "      <td>0.886271</td>\n",
       "      <td>0.888769</td>\n",
       "      <td>0.748103</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.87019</td>\n",
       "      <td>0.908641</td>\n",
       "      <td>0.847492</td>\n",
       "      <td>0.893616</td>\n",
       "      <td>0.938112</td>\n",
       "      <td>0.857999</td>\n",
       "      <td>0.910729</td>\n",
       "      <td>0.953473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_on_test</th>\n",
       "      <td>0.681485</td>\n",
       "      <td>0.684169</td>\n",
       "      <td>0.684169</td>\n",
       "      <td>0.678993</td>\n",
       "      <td>0.665696</td>\n",
       "      <td>0.665696</td>\n",
       "      <td>0.626082</td>\n",
       "      <td>0.640678</td>\n",
       "      <td>0.63879</td>\n",
       "      <td>0.627679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621126</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.722188</td>\n",
       "      <td>0.715923</td>\n",
       "      <td>0.72733</td>\n",
       "      <td>0.710037</td>\n",
       "      <td>0.70416</td>\n",
       "      <td>0.72047</td>\n",
       "      <td>0.707291</td>\n",
       "      <td>0.696121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               0   \\\n",
       "learning_rate                                                 0.5   \n",
       "n_estimators                                                    5   \n",
       "base_estimator  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "algorithm                                                   SAMME   \n",
       "mean on train                                            0.840142   \n",
       "mean_on_test                                             0.681485   \n",
       "\n",
       "                                                               1   \\\n",
       "learning_rate                                                 0.5   \n",
       "n_estimators                                                   10   \n",
       "base_estimator  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "algorithm                                                   SAMME   \n",
       "mean on train                                            0.846332   \n",
       "mean_on_test                                             0.684169   \n",
       "\n",
       "                                                               2   \\\n",
       "learning_rate                                                 0.5   \n",
       "n_estimators                                                   20   \n",
       "base_estimator  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "algorithm                                                   SAMME   \n",
       "mean on train                                            0.846332   \n",
       "mean_on_test                                             0.684169   \n",
       "\n",
       "                                                               3   \\\n",
       "learning_rate                                                0.75   \n",
       "n_estimators                                                    5   \n",
       "base_estimator  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "algorithm                                                   SAMME   \n",
       "mean on train                                            0.872404   \n",
       "mean_on_test                                             0.678993   \n",
       "\n",
       "                                                               4   \\\n",
       "learning_rate                                                0.75   \n",
       "n_estimators                                                   10   \n",
       "base_estimator  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "algorithm                                                   SAMME   \n",
       "mean on train                                            0.877572   \n",
       "mean_on_test                                             0.665696   \n",
       "\n",
       "                                                               5   \\\n",
       "learning_rate                                                0.75   \n",
       "n_estimators                                                   20   \n",
       "base_estimator  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "algorithm                                                   SAMME   \n",
       "mean on train                                            0.877572   \n",
       "mean_on_test                                             0.665696   \n",
       "\n",
       "                                                               6   \\\n",
       "learning_rate                                                   1   \n",
       "n_estimators                                                    5   \n",
       "base_estimator  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "algorithm                                                   SAMME   \n",
       "mean on train                                            0.877733   \n",
       "mean_on_test                                             0.626082   \n",
       "\n",
       "                                                               7   \\\n",
       "learning_rate                                                   1   \n",
       "n_estimators                                                   10   \n",
       "base_estimator  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "algorithm                                                   SAMME   \n",
       "mean on train                                            0.886271   \n",
       "mean_on_test                                             0.640678   \n",
       "\n",
       "                                                               8   \\\n",
       "learning_rate                                                   1   \n",
       "n_estimators                                                   20   \n",
       "base_estimator  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "algorithm                                                   SAMME   \n",
       "mean on train                                            0.888769   \n",
       "mean_on_test                                              0.63879   \n",
       "\n",
       "                                                               9   \\\n",
       "learning_rate                                                 0.5   \n",
       "n_estimators                                                    5   \n",
       "base_estimator  RandomForestClassifier(bootstrap=True, class_w...   \n",
       "algorithm                                                   SAMME   \n",
       "mean on train                                            0.748103   \n",
       "mean_on_test                                             0.627679   \n",
       "\n",
       "                                      ...                          \\\n",
       "learning_rate                         ...                           \n",
       "n_estimators                          ...                           \n",
       "base_estimator                        ...                           \n",
       "algorithm                             ...                           \n",
       "mean on train                         ...                           \n",
       "mean_on_test                          ...                           \n",
       "\n",
       "                                                               26  \\\n",
       "learning_rate                                                   1   \n",
       "n_estimators                                                   20   \n",
       "base_estimator  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "algorithm                                                 SAMME.R   \n",
       "mean on train                                                   1   \n",
       "mean_on_test                                             0.621126   \n",
       "\n",
       "                                                               27  \\\n",
       "learning_rate                                                 0.5   \n",
       "n_estimators                                                    5   \n",
       "base_estimator  RandomForestClassifier(bootstrap=True, class_w...   \n",
       "algorithm                                                 SAMME.R   \n",
       "mean on train                                            0.837153   \n",
       "mean_on_test                                             0.724409   \n",
       "\n",
       "                                                               28  \\\n",
       "learning_rate                                                 0.5   \n",
       "n_estimators                                                   10   \n",
       "base_estimator  RandomForestClassifier(bootstrap=True, class_w...   \n",
       "algorithm                                                 SAMME.R   \n",
       "mean on train                                             0.87019   \n",
       "mean_on_test                                             0.722188   \n",
       "\n",
       "                                                               29  \\\n",
       "learning_rate                                                 0.5   \n",
       "n_estimators                                                   20   \n",
       "base_estimator  RandomForestClassifier(bootstrap=True, class_w...   \n",
       "algorithm                                                 SAMME.R   \n",
       "mean on train                                            0.908641   \n",
       "mean_on_test                                             0.715923   \n",
       "\n",
       "                                                               30  \\\n",
       "learning_rate                                                0.75   \n",
       "n_estimators                                                    5   \n",
       "base_estimator  RandomForestClassifier(bootstrap=True, class_w...   \n",
       "algorithm                                                 SAMME.R   \n",
       "mean on train                                            0.847492   \n",
       "mean_on_test                                              0.72733   \n",
       "\n",
       "                                                               31  \\\n",
       "learning_rate                                                0.75   \n",
       "n_estimators                                                   10   \n",
       "base_estimator  RandomForestClassifier(bootstrap=True, class_w...   \n",
       "algorithm                                                 SAMME.R   \n",
       "mean on train                                            0.893616   \n",
       "mean_on_test                                             0.710037   \n",
       "\n",
       "                                                               32  \\\n",
       "learning_rate                                                0.75   \n",
       "n_estimators                                                   20   \n",
       "base_estimator  RandomForestClassifier(bootstrap=True, class_w...   \n",
       "algorithm                                                 SAMME.R   \n",
       "mean on train                                            0.938112   \n",
       "mean_on_test                                              0.70416   \n",
       "\n",
       "                                                               33  \\\n",
       "learning_rate                                                   1   \n",
       "n_estimators                                                    5   \n",
       "base_estimator  RandomForestClassifier(bootstrap=True, class_w...   \n",
       "algorithm                                                 SAMME.R   \n",
       "mean on train                                            0.857999   \n",
       "mean_on_test                                              0.72047   \n",
       "\n",
       "                                                               34  \\\n",
       "learning_rate                                                   1   \n",
       "n_estimators                                                   10   \n",
       "base_estimator  RandomForestClassifier(bootstrap=True, class_w...   \n",
       "algorithm                                                 SAMME.R   \n",
       "mean on train                                            0.910729   \n",
       "mean_on_test                                             0.707291   \n",
       "\n",
       "                                                               35  \n",
       "learning_rate                                                   1  \n",
       "n_estimators                                                   20  \n",
       "base_estimator  RandomForestClassifier(bootstrap=True, class_w...  \n",
       "algorithm                                                 SAMME.R  \n",
       "mean on train                                            0.953473  \n",
       "mean_on_test                                             0.696121  \n",
       "\n",
       "[6 rows x 36 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([result_13['param_' + param] for param in parameters_13] + [result_13['mean_train_score'], result_13['mean_test_score']], index=list(parameters_13.keys()) + ['mean on train', 'mean_on_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R',\n",
       " 'base_estimator': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=2, max_features='auto',\n",
       "             max_leaf_nodes=4, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "             verbose=0, warm_start=False),\n",
       " 'learning_rate': 0.75,\n",
       " 'n_estimators': 5}"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_13.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=2, max_features='auto',\n",
       "            max_leaf_nodes=4, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "          learning_rate=0.75, n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "model_13_best = AdaBoostClassifier(base_estimator=clf_13.best_params_['base_estimator'], \n",
    "                                n_estimators = clf_13.best_params_['n_estimators'], \n",
    "                                learning_rate = clf_13.best_params_['learning_rate'],\n",
    "                                algorithm = clf_13.best_params_['algorithm'],\n",
    "                                random_state = RANDOM_SEED)\n",
    "model_13_best.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd8FHX6wPHPQ0elKHgWiiCg0gNGil2xoIeAiBT1LIeHDUVRf2LvZxflxBPkPI9TQUGaCnIWOCtCQECKHkiRUJQWDD0Jz++P7wSWkGwmyc7ObvK8X6997e7M7Mwzm80++y3z/YqqYowxxhSkXNgBGGOMSWyWKIwxxkRlicIYY0xUliiMMcZEZYnCGGNMVJYojDHGRGWJwvgmIleKyH/CjiORiMg2ETk+hOM2EBEVkQrxPnYQRGSRiJxdjNfZZzIOLFEkKRFZKSI7vS+q9SLypogcFuQxVfVtVb0gyGNEEpFTReRzEckUka0i8oGINIvX8fOJZ4aIXB+5TFUPU9XlAR3vBBEZKyIbvfNfICKDRKR8EMcrLi9hNS7JPlS1uarOKOQ4ByXHeH8myypLFMntElU9DEgB2gD3hhxPseT3q1hEOgL/ASYBxwINgfnA10H8gk+0X+Yi0gj4DlgNtFTVGsDlQCpQLcbHCu3cE+19NwVQVbsl4Q1YCZwX8fxZ4KOI55WB54FfgF+B14CqEeu7AfOA34Gfgc7e8hrAP4B1wBrgCaC8t+5a4Cvv8WvA83limgQM8h4fC7wPbABWALdFbPcIMA54yzv+9fmc35fAq/ksnwqM8h6fDaQD9wEbvffkSj/vQcRr7wHWA/8GDgc+9GLe4j2u623/JJAD7AK2Aa94yxVo7D1+ExgGfARk4r7oG0XEcwHwE7AVeBX4b37n7m37VuTfM5/1DbxjX+Od30bg/oj17YBvgQzvb/kKUClivQK3AEuBFd6yl3GJ6XdgDnBGxPblvff5Z+/c5gD1gC+8fW333pfe3vZdcJ+vDOAboFWez+49wAJgN1CBiM+zF3uaF8evwIve8l+8Y23zbh2J+Ex62zQHPgE2e6+9L+z/1dJwCz0AuxXzD3fgP1Zd4Afg5Yj1LwGTgSNwv0A/AJ7y1rXzvqzOx5Uq6wAneesmAsOBQ4E/ALOAG7x1+/4pgTO9LxXxnh8O7MQliHLeF8lDQCXgeGA5cKG37SNAFtDd27ZqnnM7BPelfE4+530dsM57fDaQDbyISwpneV9YJ/p4D3Jf+4z32qpALeAy7/jVgLHAxIhjzyDPFzsHJ4rN3vtbAXgbGOOtq+198fXw1g303oOCEsV64Loof/8G3rFf92JvjfvSbeqtPxno4B2rAbAEuD1P3J94701u8rzKew8qAHd6MVTx1t2N+4ydCIh3vFp53wPveVvgN6A9LsFcg/u8Vo747M7DJZqqEctyP8/fAn/yHh8GdMhzzhUijnUt+z+T1XBJ8U6give8fdj/q6XhFnoAdivmH879Y23D/bpT4DOgprdOcF+Ykb9mO7L/l+NwYEg++zzK+7KJLHn0BaZ7jyP/KQX3C+9M7/lfgM+9x+2BX/Ls+17gn97jR4AvopxbXe+cTspnXWcgy3t8Nu7L/tCI9e8BD/p4D84G9uR+ERYQRwqwJeL5DApPFCMj1l0M/Og9vhr4NmKd4BJtQYkiC6+UV8D63C/NuhHLZgF9Ctj+dmBCnrjPLeQztgVo7T3+CehWwHZ5E8XfgcfzbPMTcFbEZ/fP+XyecxPFF8CjQO0CzrmgRNEX+D7I/7uyerP6weTWXVU/FZGzgHdwv1ozgCNxv4rniEjutoL7dQful9yUfPZ3HFARWBfxunK4L7QDqKqKyBjcP+cXwBW46pLc/RwrIhkRLymPq07KddA+I2wB9gLHAD/mWXcMrppl37aquj3i+Spcqaaw9wBgg6ru2rdS5BBgCC4ZHe4triYi5VU1J0q8kdZHPN6B+0WMF9O+c/bev/Qo+9mEO9diHU9ETsCVtFJx70MFXCkv0gF/AxG5E7jei1WB6rjPFLjPzM8+4gH3979GRG6NWFbJ22++x86jH/AY8KOIrAAeVdUPfRy3KDGaIrDG7FJAVf+L+zX7vLdoI64aqLmq1vRuNdQ1fIP7J22Uz65W40oUtSNeV11Vmxdw6NFATxE5DleKeD9iPysi9lFTVaup6sWRYUc5n+246ofL81ndC1d6ynW4iBwa8bw+sNbHe5BfDHfiqlbaq2p1XPUauAQTNWYf1uFKSm6HLnvVLXhzPsVVgxXX33FJtol3Lvex/zxy7TsfETkD127QCzhcVWviqidzX1PQZyY/q4En8/z9D1HV0fkdOy9VXaqqfXFVn88A47y/cWHvf1FiNEVgiaL0eAk4X0RSVHUvru56iIj8AUBE6ojIhd62/wCuE5FOIlLOW3eSqq7D9TR6QUSqe+saeSWWg6jq97iG35HANFXNLUHMAn4XkXtEpKqIlBeRFiJyShHOZzDuV+ltIlJNRA4XkSdw1UeP5tn2URGp5H3ZdQHG+ngP8lMNl1wyROQI4OE863/FtbcUx0dASxHp7vX0uQU4Osr2DwOnishzInK0F39jEXlLRGr6OF41XJvINhE5CbjJx/bZuL9nBRF5CFeiyDUSeFxEmojTSkRqeevyvi+vAzeKSHtv20NF5I8i4qu3lohcJSJHen/D3M9UjhfbXgr+G3wIHC0it4tIZe9z097PMU10lihKCVXdAIzC1c+D+3W4DJgpIr/jfqGe6G07C9coPAT3q/G/uOoCcHXplYDFuCqgcUSvAhkNnIer+sqNJQe4BFfHvwL3634krkeV3/P5CrgQ1/i7Dlel1AY4XVWXRmy63otzLa7x+EZVza2uKvA9KMBLuIbhjcBM4OM861/GlaC2iMhQv+finc9GXAnpWVy1UjNcz57dBWz/My4pNgAWichWXIktDdcuVZi7cNWBmbgv7ncL2X4arkfZ/3Dv9S4OrB56Edf+8x9cAvoH7r0C1+b0LxHJEJFeqpqGa7N6Bfe3WYZrS/CrM+6ct+He8z6quktVd+B6n33tHatD5ItUNRPXQeMS3OdiKXBOEY5rCpDbY8WYpONdyfuWqkarwklIIlIO1z33SlWdHnY8xkRjJQpj4kRELhSRmiJSmf1tBjNDDsuYQlmiMCZ+OuJ65WzEVY90V9Wd4YZkTOGs6skYY0xUgZUoROQNEflNRBYWsF5EZKiILPMGO2sbVCzGGGOKL8gL7t7E9XoYVcD6i4Am3q09rt93oV3ZateurQ0aNIhNhMYYU0bMmTNno6oeWZzXBpYoVPULEWkQZZNuuMHdFNd9saaIHOP15S9QgwYNSEtLi2GkxhhTemRnw7vvwqZN3gJVDtu6hn5z6q0q7j7DHMKjDgf20073lh2UKESkP9AfoH79+nEJzhhjktErr8Add7jHdUjnVW6mI9+WaJ9h9nrKO5wAFHCJvqqOUNVUVU098shilZyMMabU27oVnngCOp2rbHthOL9Ua84lVT/l0McGl2i/YSaKdNwgXrnq4q6uNcYYUwzPP++qnJ55Bg6dNp5yp6QiP/zAIQ/eWaL9hpkoJgNXe72fOgBbC2ufMMYYk7/1q7PgmWe4ucsvnJwqMHYsfPopNCr5OImBtVGIyGjcmP+1veGUH8YNYY2qvoYb5vpi3DgwO3BjDxljjCmqtDSyOl/P41nz2dhUgP+D6tULfZlfQfZ66lvI+typGI0xJiGNGQOPPw6Jel1ylb07GLDhYa7Z/CLlOYrhnSdww7PdY34cm7jIGGMK8Pnn8PPP0LVr2JHkr+8PT3Dp5uf55Pj+TDnzGe5/zs8I9EVnicIYY6I44gh4772wo4iwZQts3AhNmkDG/8H8Czn/rLM4P8BD2qCAxhiTLN5/H5o1gz59XH1YzZpwVr7zisWUJQpjjEl0a9dCjx7Qsycccwy8/jpIfpeiBcOqnowxJo+tW2HBAliXCB32586Fc8+F3bvdBRKDBkGF+H51W6Iwxpg8broJRo92j5s0CSmIrCyoWBFatIDeveGuu0ILxqqejDEmj3XroFUrd73aJ5/E+eDZ2a7k0LSpK9pUqgTDh4eYsaxEYYwxB9m2DerWhU6d4nzg77+Hfv3c/aWXwp49cQ4gf1aiMMaYPDIz4bDD4njA7GwYPBhOOcUVZ8aNg/HjIUEGQbVEYYwxeWzbBtWqxfGA5cvD/Plw7bWweDFcdlkcD144q3oyxpR6U6fC22/7337DhjiUKDIy4IEH4O674bjjYPJk13idgCxRGGNKvddec9/DfgdSPe44OOecAAOaOBFuvhl+/RVSU11JIkGTBFiiMMaUESkpro04VOvXw623ujaI1q3hgw/g5JNDDqpw1kZhjDHx8tRTLjk89RTMnp0USQKsRGGMMcH6+WfYudNdOPfoo3DLLXDCCWFHVSSWKIwpIVXYsSPsKEw02dkhHfSll+Chh1zJ4csv3SB+NYMZCjxIliiMKaFBg9z3gUlsqalxPNi8eXD99TBnjpvM4tVX43jw2LNEYUwJLV/uBvS8446wIzHRnH56nA40Ywacdx7UquUmsujZM64jvQbBEoUxMXDUUa47vCnDfv/dzVN92mlw773ul8MRR4QdVUxYrydjjCmJrVvdcLPNmrmL6CpWdBNtl5IkAZYojDGm+CZPhubNYcQINxR4pUphRxQIq3oyCWf7dvjXv2DXrrAj8WfZslL7/WAKsnOnu5r6vfegZUuYMMEN6FdKWaIwCWfcONfVPJlcemnYEZi4qlLFDQH+xBOucaqU/1KwRGESzvz5cMghsGYNlEuSytG4DkltwrFihWugfuklaNDADQOe5L2Z/LJEYRLOggWu2jcJr0sypVFODgwd6kZ6LVcOFi50iaKMJAmwxmyTYFRdiaJVq7AjMQb3q6VjR3dV5TnnuLkiunQJO6q4sxKFSSi//gobN7r2QWNC9/e/w8qVMHq069VUhkoRkSxRmNBs3w7nnw+//ba/LSK3p5OVKExovvrKNZK1bQtPP+0arGvVCjuqUFmiMKFZswa+/RYqV4YePfYvP/xwOPXU8OIyZdTvv7srql99Ff74R/jwQ6hRI+yoEoIlChO6N96AK64IOwpTpn30Edx4o/v1MnCgK0WYfQJtzBaRziLyk4gsE5HB+ayvLyLTReR7EVkgIhcHGY8xxhxkwgTXQF2jBnzzjev+av2dDxBYohCR8sAw4CKgGdBXRJrl2ewB4D1VbQP0AZJ7LF5jTHJQhfR097hLF3jlFZg7Fzp0CDeuBBVk1VM7YJmqLgcQkTFAN2BxxDYKVPce1wDWBhiPCYGqG5I/M/PgdatXxz8eY1i1Cm64wXV9XbLElSSSbSiAOAsyUdQBIr8K0oH2ebZ5BPiPiNwKHAqcl9+ORKQ/0B+gfv36MQ/UBOf77wsfAqdatfjEYsq4nBxXcrj/fvf8qaesismnIBNFfh2ONc/zvsCbqvqCiHQE/i0iLVR17wEvUh0BjABITU3Nuw+TwDIy3P3LL0Pr1gevr1KlVI+lZhLF1q3QuTPMnAkXXQSvvQb2o9O3IBNFOlAv4nldDq5a6gd0BlDVb0WkClAb+C3AuEwc5c5VnJpqXV5NCFTdRXLVq0OTJjBggOtiV0YvnCuuIHs9zQaaiEhDEamEa6yenGebX4BOACLSFKgCbAgwJhNnuYmignXENvH2zTfQvr0bzE8ERo2CK6+0JFEMgSUKVc0GBgDTgCW43k2LROQxEenqbXYn8BcRmQ+MBq5VVataKkUsUZi4y8yEW291k2SvX+9upkQC/fdV1SnAlDzLHop4vBg4LcgYTLDmzYNnn4W9e/Nfn9sD0RKFiYupU92Fc6tXu2qmJ5+03hIxYP++pkTef9+Nl3biiQVv07GjG5XZmMBNmgSHHurGa7JGsZixRGFKrFw5+PHHsKMwZZKq+6XSpInrPvf881CxohtAzMSMzUdhjElOv/zirqq+8ko3kB+46yIsScScJQpjTHLZu9ddONe8OcyY4cZmGjky7KhKNat6MiWSmVlwQ7YxgRg1yvVquuACGD7cGsDiwBKFKbaRI90V1+WsXGqCtmcPLFsGzZq5qqbq1eHSS+2aiDixf3FTbKtWufvJeS+jNCaWvvvOzTbXqZObFrFiRTfTlSWJuLFEYUqkXDk3GZgxMbd9O9xxh+tfvXUrvP666/pq4s6qnowxiWf9epcgVq6Em292I71Wr17oy0wwLFEYYxJHdra7jP+oo+CSS6BXLzcUhwmVVT2ZYvvqK+vxZGJEFd59F044Yf8gfkOHWpJIEJYoTLEtWRJ2BKZUSE+Hbt2gTx+oVQt27w47IpOHJQpTbJUqwVVXhR2FSWrDh7sur59+Ci+8AN9+CyedFHZUJg9rozDFVq4clC8fdhQmqc2b5+aMGD4cjj8+7GhMASxRGGPiJyvLjUt/3nkuQbz0kiua2jURCc0ShTEmPmbPhn794Icf3DUS7dvbAH5JwtooTJHcdx80auRuuZMSGRPV9u1w553QoQNs2gQTJ8Jf/xp2VKYIrERhimTcONeT8bTT3Lww/fqFHZFJeP/8J7z4ItxwAzzzDNSoEXZEpoh8JQoRqQTUV9VlAcdjEty6dXD99TBkSNiRmIS2ZQssXQrt2rmpSVNTXYnCJKVCq55E5I/AD8An3vMUEZkQdGAm8Wzb5m5HHx12JCZhqbpiZ9OmcNllbtTXChUsSSQ5P20UjwHtgQwAVZ0HNA4yKJOY1q1z98ccE24cJkGtWeOG/r78cqhTxw0rXKlS2FGZGPBT9ZSlqhlyYPc1DSgeE6KlS90YbAVZtMjdW6IwB1m+HNq0cSWIZ591o75WsCbQ0sLPX3KJiPQCyolIQ2AgMDPYsEwYOnZ0nVIKY9dFmX22bXPzVDdsCAMHwtVXQ2OrcCht/CSKAcBDwF5gPDANuDfIoEw4MjLc/3n//gVvU7Om6xpryrisLDfkxnPPuesjjj8eHnss7KhMQPwkigtV9R7gntwFItIDlzRMKaEKOTnuh+Fpp4UdjUloc+a4rm/z5rmZ5g45JOyITMD8NGY/kM+y+2MdiAlXdra7t2plUyBVGDzYXVG9fj28/767WTe4Uq/ArwURuRDoDNQRkRcjVlXHVUOZUsQShSmUiGuTuO46V+VUs2bYEZk4ifa18BuwENgFLIpYngkMDjIoE3+bN7v7ihXDjcMkmIwMuPtudwl+hw5uMqFyNvJPWVNgolDV74HvReRtVd0Vx5hMCJYudfc2RpvZZ/x4uOUW2LABWrVyicKSRJnkp6Khjog8CTQDquQuVNUTAovKxF1Ojrtv3TrcOEwCWLcOBgxwiSIlBT76CNq2DTsqEyI/Pw/eBP4JCHAR8B4wJsCYTAiysty9tVEY3nkHpkyBp5+GWbMsSRhfieIQVZ0GoKo/q+oDwDl+di4inUXkJxFZJiL5tmuISC8RWSwii0TkHf+hm1iyxuwybtkymDHDPR44EBYuhHvusUYrA/iretotbvyOn0XkRmAN8IfCXiQi5YFhwPlAOjBbRCar6uKIbZrgLt47TVW3iEih+zXR7dgBO3cW/XVbtrh7+14oY7Kz3RDgDz8Mxx0Hixe7Xwt2VaWJ4CdR3AEcBtwGPAnUAP7s43XtgGWquhxARMYA3YDFEdv8BRimqlsAVPU3/6GbvDZuhPr1i5coclWpUvg2ppSYN8/1Zpo7F7p3h2HDrLHa5KvQRKGq33kPM4E/AYhIXR/7rgOsjniejhuFNtIJ3v6+BsoDj6jqx3l3JCL9gf4A9evX93HosmnzZpckrr7aDf9fVEccASeeGPu4TAL64Qf3IaldG8aOdUOC27zVpgBRE4WInIL7wv9KVTeKSHPcUB7nAoUli/w+dXlHna0ANAHO9vb3pYi0UNWMA16kOgIYAZCammoj1xbiwgvhiivCjsIkpPXr3ZXULVq4KqerrnK/EIyJosBypog8BbwNXAl8LCL3A9OB+XglgUKkA/UintcF1uazzSRVzVLVFcBPuMRhjImlrVvdVKSNGrkhwUXgttssSRhfopUougGtVXWniByB+5Jvrao/+dz3bKCJNzT5GqAPkPd37kSgL/CmiNTGJaDlRTkBY0whJk2Cm292pYlBg2xsJlNk0RLFLlXdCaCqm0XkxyIkCVQ1W0QG4IYlLw+8oaqLROQxIE1VJ3vrLhCRxUAOcLeq+pgRweT65pv9vRo3bgw1FJNo9u6Fvn3hvffcldWTJhWv8cqUeaKaf5W/iGQAn+c+xV07kfscVe0ReHT5SE1N1bS0tDAOnZBOPRW+/Xb/84oVYfp0GyrceO66y1Uv3X239X0u40RkjqoW65dCtBLFZXmev1KcA5hg5eTABRfABx+45+XK2UVzZdry5XDTTfDII27KwuefDzsiUwpEGxTws3gGYoqvXDmbw77My86Gl1+GBx90vxTS08OOyJQi9tvTmGS3YIG7cC4tDS65BF59Fer6udTJGH8sURiT7D7+GFatgjFjoFcvu3DOxJzv6/VFxGYqSDBr17rBPQvoj2BKsy+/hKlT3eNBg+DHH6F3b0sSJhCFJgoRaSciPwBLveetReRvgUdmCvW//7l7GwW6DPn9d9dYfeaZ8Oij7ldChQp24ZwJlJ8SxVCgC7AJQFXn43OYcROs3KHBL7443DhMnHzwATRrBiNGwB13wGefWQnCxIWfNopyqrpKDvxA5gQUjykCm0OiDPn6a+ja1Y3RNH48tGsXdkSmDPFTolgtIu0AFZHyInI78L+A4zI+2Kx0pZyqmx8C3JWV77wDc+ZYkjBx5ydR3AQMAuoDvwIdvGUmZJu8wU4sUZRCK1dC585uyI1Vq1wVU9++dsGMCYWfr5hsVe0TeCSmyKZNc/fWjlmK5OTA3/4G99/vrqR87jmoV6/w1xkTID+JYraI/AS8C4xX1cyAYzI+VavmfmjaXE6lxJ49cPbZbvCuiy+Gv//d/rgmIRRa9aSqjYAngJOBH0RkoohYCSNB2IjRpcDeve6+UiU4/3x4+2348ENLEiZh+LrgTlW/UdXbgLbA77gJjYwxJfX119CypRsvHty1EVdcYd1eTULxc8HdYSJypYh8AMwCNgCnBh6ZMaVZZiYMGABnnAHbtu3vwmZMAvLTRrEQ+AB4VlW/DDgek4+0NPjrX/fXUOT6/vtw4jElNHUq9O8Pa9bArbfCk0/CYYeFHZUxBfKTKI5X1b2Fb2aCMmkSTJgArVsfuPzww+Gss8KJyZTAwoVQvbqbea5jx7CjMaZQBSYKEXlBVe8E3heRg4adC2uGu7KqXDmYNy/sKEyxqLqL5Q49FLp3d8Nv3HYbVLZxNk1yiFaieNe7t5ntjCmuVavcIH5Tp7ohOLp3d1dI2lWSJokU2JitqrO8h01V9bPIG9A0PuEZk6RyL5xr3hy++MLNPjd+fNhRGVMsfrrH/jmfZf1iHYjZLzsbfv11/23btrAjMkX26aeueun0012bxG23QfnyYUdlTLFEa6PoDfQBGopI5E+hakBG0IGVZZdfDhMnHrisSpVwYjFFsHu366J22mlwwQUuWZx7rl0TYZJetIrSWbg5KOoCwyKWZwLWMTNAy5e7Hk433LB/WZMm4cVjfJg5081bvWKFux11FHTqFHZUxsREgYlCVVcAK4BP4xeOAdi1C9q0cW2gJsFt2+YG8Pvb36BuXRg71iUJY0qRaFVP/1XVs0RkCxDZPVYAVVUbszQgu3ZB1aphR2EKtX07tGrlhgS/5RZ3VWS1amFHZUzMRat6yp3utHY8AjH77dplbRIJbedOl8kPPdQV+047zU0sZEwpFa3qKfdq7HrAWlXdIyKnA62At3CDA5oS+vhjmDXrwGVbt1qiSEiqMGaMu2Du/fddgrj77rCjMiZwfq76mQicIiKNgFHAR8A7QJcgAysrbrnFNV5HEnFTI5sEsnq1Kz189JGbirRmzbAjMiZu/FxHsVdVs4AewEuqeitQJ9iwyo6cHLj6anefe8vOdh1oTIIYORKaNYPp0+HFF92Q4M2bhx2VMXHjaypUEbkc+BPQ3VtWMbiQyh4RN5aTSVAZGW7wvuHDoWHDsKMxJu78Xpl9Dm6Y8eUi0hAY7WfnItJZRH4SkWUiMjjKdj1FREUk1V/YxgRozx544gnX1RVg0CA3QbklCVNG+ZkKdSFwG5AmIicBq1X1ycJeJyLlcRfqXQQ0A/qKSLN8tqvm7f+7IsZuTOzNmgWpqfDgg/Df/7pl5crZ1dWmTCu06klEzgD+DazBXUNxtIj8SVW/LuSl7YBlqrrc288YoBuwOM92jwPPAncVMfaEt2aNuzg3M7Pgbdavt++ghLB9u0sOL78MxxwDkyfDJZeEHZUxCcFPG8UQ4GJVXQwgIk1xiaOwaqI6wOqI5+lA+8gNRKQNUE9VPxSRAhOFiPQH+gPUT6IJ55cvh59+gosugjpRmv//nN+wiya+Pv0UhgxxPZueegpq1Ag7ImMShp9EUSk3SQCo6hIRqeTjdfn9Tt53hbeIlMMloWsL25GqjgBGAKSmph40iVKiu/NOG/YnIW3eDN995zJ5167www/WL9mYfPhpzJ4rIsNF5HTv9nf8DQqYjrtYL1ddYG3E82pAC2CGiKwEOgCTrUHbBE7VTUPatCn07u2ucLSLV4wpkJ9EcSPwM/B/wD3AcuCGqK9wZgNNRKShVwLpA0zOXamqW1W1tqo2UNUGwEygq6qmFfEcjPEvPR26dXMJol49+PJLq2YyphBRq55EpCXQCJigqs8WZceqmi0iA4BpQHngDVVdJCKPAWmqOjn6HpLX3LmuIXvRorAjMQfYvBlatnTzRjz/PAwcaFOSGuNDtNFj78PNZDcXN4THY6r6RlF2rqpTgCl5lj1UwLZnF2XfiWrHDmjf3l1dnctGewjZxo1QuzYccQQ8/TScdx40ahR2VMYkjWhVT1cCrVT1cuAUwGZH8CEryyWJO+5wk539+COcfHLYUZVRWVlu6O/69eGrr9yyG26wJGFMEUUrd+9W1e0AqrrB66VkfKpXzxJEqNLS4PrrYf586NkTGjcOOyJjkla0RHF8xFzZAjSKnDtbVXsEGpkxxfXQQ/Dkk26muQkToHv3wl9jjClQtERxWZ7nrwQZiDExc/h8FSG0AAAXj0lEQVThrjTxzDPWQGRMDESbuOizeAZiTLFt2QJ33QXnnw99+rgGImNMzFjfQJPc3n8fBgyADRugSZOwozGmVLJEYZLT2rUuQUyYAG3bwpQp0KZN2FEZUyr57skkIpWDDMSYIvn2W5g61bVDfPedJQljAlRoohCRdiLyA7DUe95aRP4WeGTG5LV0Kbz7rnt82WXw88/wf/9nV1cbEzA/JYqhQBdgE4CqzsfNeGdMfGRluZJDq1Zw++2wc6dbfuyx4cZlTBnhJ1GUU9VVeZblBBGMMQeZO9eNiTJ4sBsOfM4cqFo17KiMKVP8lNlXi0g7QL3pTW8F/hdsWMbgRlbs0AFq1XK9m3rYNZ7GhMFPieImYBBQH/gVN2+EjftkgrNsmbuvUwf+/W9YvNiShDEhKjRRqOpvqtrHmzuitvd4YzyCM2VMRgb07w8nnADffOOW9e7trrQ2xoSm0KonEXmdiClMc6lq/0AiMmXThAlwyy3w229w992QkhJ2RMYYj582ik8jHlcBLgVWBxOOKZOuuQZGjXLJ4cMP3QV0xpiEUWiiUNV3I5+LyL+BTwKLKMnt2ePurWt/IdQrpIpAu3Zw0kluvKaKFcONyxhzkOLMMdEQOC7WgZQWGRnu3qrVo/j5ZzfL3Jgx7vktt8C991qSMCZB+bkye4uIbPZuGbjSxH3Bh5actmxx9za6dT6ys91c1S1buomFIueLNcYkrKgVJCIiQGtgjbdor6oe1LBt9rMSRQEWLIA//9ldMNetGwwb5rq/GmMSXtREoaoqIhNU1Sb19MlKFAVYtgxWr4b33nNTk4qEHZExxic/bRSzRMS6ofjw9NPwl7+4x1aiAL74Av7xD/e4Rw+XLC6/3JKEMUmmwEQhIrmljdNxyeInEZkrIt+LyNz4hJdcvvoKqlSBJ56AY44JO5oQbd0KN94IZ50FL7zgBvUDqFYt3LiMMcUSreppFtAWsJnpfcrKgkaN4P77w44kRJMmwc03w/r1MGgQPPaY9WYyJslFSxQCoKo/xymWpJedXcavn1i61FUxtWgBEyfCKaeEHZExJgaifa0dKSKDClqpqi8GEE9SK5OJQhVmzoSOHd2c1R9/DGefbaUIY0qRaI3Z5YHDgGoF3Ewe2dll7PtxxQq48EI49VR3XQTA+eeXsTfBmNIv2u/fdar6WNwiKQXKTIkiJweGDoUHHoDy5eHVV218JmNKsULbKIx/WVllIFGoulLD9OnQpYtLEvXqhR2VMSZA0b7WOsUtilKiVJcodu+GSpXcNRBXXunmjejd266JMKYMKLCNQlU3l3TnItLZu/5imYgMzmf9IBFZLCILROQzEUnqwQZLbaL46ito3Rreecc979cP+vSxJGFMGVGc0WN98ebXHgZcBDQD+opIszybfQ+kqmorYBzwbFDxxEOpSxS//+5Gdj3jDNi1C44+OuyIjDEhCPJrrR2wTFWXA4jIGKAbsDh3A1WdHrH9TOCqAOOJmZkz3XVke/ceuHz1aujQIZyYYu4//3ElhzVr4Pbb4fHH4bDDwo7KGBOCIBNFHQ6cCS8daB9l+37A1PxWiEh/oD9A/fr1YxVfsX34IUydCu3znE3r1tC1azgxxdy2bW5kw3HjDj5RY0yZEmSiyK8CO98hykXkKiAVOCu/9ao6AhgBkJqaGvow5zk57lKBmTPDjiSGVOGtt9w46bfe6q6w7tq1lNWlGWOKI7A2ClwJIrLfZF1gbd6NROQ84H6gq6ruDjCemNm7F8oF+c7F26pVcNFFcPXVMGHC/jo1SxLGGIJNFLOBJiLSUEQqAX2AyZEbiEgbYDguSfwWYCwxVWoSRU4OvPwyNG/uejYNHQqffFJKTs4YEyuB/WRU1WwRGQBMww0H8oaqLhKRx4A0VZ0MPIcbJmSsm0yPX1Q14Wv5S02iWLjQjfB64YXw2muQAO0/xpjEE2jdgqpOAabkWfZQxOPzgjx+UJI6Ueze7Xo0XXKJa32fPRvatLFrIowxBUrWr7tQJW2i+OYblxS6doUlS9yytm0tSRhjokrGr7vQ7d3rxsJLGpmZrifT6ae7bq9TpkDTpmFHZYxJEtatpRiSqkSRk+OuAlyyBAYMgCeftClJjTFFYomiGJIiUWRkQI0aruhz//3QsKGbXMgYY4oo0b/uEtIXX7jr0xKSqhu8r0kTePttt+yKKyxJGGOKzRJFMfz2m/vBnnB++cXNEXHlldCoEaSkhB2RMaYUsERRDHv2wM03hx1FHqNGuQvnZsyAl16Cr7+GFi3CjsoYUwpYG0URqbqOQwk3kGq1am7u6uHDoUGDsKMxxpQiliiKaOdO15gdesehPXvg6aehalW4+2649FLo3t2uiTDGxJxVPRVRZqa7D7VE8d13cPLJ8PDDrttrbsu6JQljTAAsUfiUleUuYj7xRPc8lBLFtm1uEqGOHV1r+gcfwBtvWIIwxgTKqp582rQJvv8ezj4bUlPh4otDCOKnn2DYMLjpJnjqKahePYQgjDFljSUKn7Ztc/f9+sFV8ZywddMmN6XeNde46qZly+C44+IYgDGmrLOqJ5/i3jahCmPGuDGZ/vIXd40EWJIwxsSdJQqfcksUcWmbSE93I7z27eu6uqal2VwRxpjQWNWTT/Pnu/vASxS7d0P79rBlC7zwAgwcmGRD1RpjShtLFD69+qq7P/bYgA6wapUrNVSu7A7WsiUcf3xABzPGGP+s6smnPXtcj6d69WK846wsN/T3CSfsH8SvWzdLEsaYhGGJwqeMDGjWLMY7nT3b9WR64AGXHM5LyplhjTGlnCUKH1Rdojj88Bju9Kmn3IRCmzbBxInw3ntw9NExPIAxxsSGJQofMjPdRHE1a8ZgZ7nDbTRr5rq9Ll7sShPGGJOgLFH4sGWLuy9RiWLzZvjzn11JAlxyeO01NwudMcYkMEsUPuze7e6rVi3Gi1Vh7FhXghg1yjVeG2NMErHusUFau9bNcDRpkhtR8OOPbdY5Y0zSsRJFkNauhc8+g+eec0ODW5IwxiQhK1HE2v/+B1OmuOHAU1Nh9eoYtYIbY0w4rEQRK1lZrqG6VSt47DHYsMEttyRhjElylihiYc4caNcO7rsPunSBRYvgyCPDjsoYY2LCqp5KKjMTOnWCQw6B8ePd3NXGGFOKWKIorrlzoU0bN+74+PGuV5NVMxljSqFAE4WIdAZeBsoDI1X16TzrKwOjgJOBTUBvVV0ZZEwllpEBd98NI0e6iYV694Zzzw07KmNClZWVRXp6Ort27Qo7lDKvSpUq1K1bl4oVK8Zsn4ElChEpDwwDzgfSgdkiMllVF0ds1g/YoqqNRaQP8AzQO6iYSqru7PFw5y2uofqee9zkQsYY0tPTqVatGg0aNEBEwg6nzFJVNm3aRHp6Og0bNozZfoNszG4HLFPV5aq6BxgD5B3UqBvwL+/xOKCTJOCnbMUK+BsDOPOly+CYY2DWLHj66WJeqm1M6bNr1y5q1aplSSJkIkKtWrViXrILMlHUAVZHPE/3luW7japmA1uBWnl3JCL9RSRNRNI25HY7jaPKleGrQzuz+pan3YVzbdvGPQZjEp0licQQxN8hyDaK/KLVYmyDqo4ARgCkpqYetD5oZ58NZ2/rAnSJ96GNMSZ0QZYo0oHI+eDqAmsL2kZEKgA1gM0BxmSMKcUmTJiAiPDjjz/uWzZjxgy6dDnwR961117LuHHjANcQP3jwYJo0aUKLFi1o164dU6dOLXEsTz31FI0bN+bEE09k2rRp+W5zxhlnkJKSQkpKCsceeyzdu3cHYMuWLVx66aW0atWKdu3asXDhwn2vGTJkCM2bN6dFixb07ds3Lh0IgkwUs4EmItJQRCoBfYDJebaZDFzjPe4JfK6qcS8xGGNKh9GjR3P66aczZswY36958MEHWbduHQsXLmThwoV88MEHZGZmliiOxYsXM2bMGBYtWsTHH3/MzTffTE5OzkHbffnll8ybN4958+bRsWNHevToAcBf//pXUlJSWLBgAaNGjWLgwIEArFmzhqFDh5KWlsbChQvJyckp0rkWV2BVT6qaLSIDgGm47rFvqOoiEXkMSFPVycA/gH+LyDJcSaJPUPEYY+Lj9tth3rzY7jMlBV56Kfo227Zt4+uvv2b69Ol07dqVRx55pND97tixg9dff50VK1ZQuXJlAI466ih69epVongnTZpEnz59qFy5Mg0bNqRx48bMmjWLjh075rt9ZmYmn3/+Of/85z8Bl2juvfdeAE466SRWrlzJr7/+CkB2djY7d+6kYsWK7Nixg2OPPbZEsfoR6HUUqjoFmJJn2UMRj3cBlwcZgzGmbJg4cSKdO3fmhBNO4IgjjmDu3Lm0LaTjybJly6hfvz7Vq1cvdP933HEH06dPP2h5nz59GDx48AHL1qxZQ4cOHfY9r1u3LmvWrClw3xMmTKBTp0774mjdujXjx4/n9NNPZ9asWaxatYr09HROPvlk7rrrLurXr0/VqlW54IILuOCCCwqNvaTsymxjTEwV9ss/KKNHj+b2228H3Jf36NGjadu2bYG9gIraO2jIkCG+t82vBj3a8UaPHs3111+/7/ngwYMZOHAgKSkptGzZkjZt2lChQgW2bNnCpEmTWLFiBTVr1uTyyy/nrbfe4qqrrirSuRSVJQpjTNLbtGkTn3/+OQsXLkREyMnJQUR49tlnqVWrFlty5zP2bN68mdq1a9O4cWN++eUXMjMzqVatWtRjFKVEUbduXVav3n91QHp6eoFVRJs2bWLWrFlMmDBh37Lq1avvq4ZSVRo2bEjDhg2ZNm0aDRs25Ehv0NEePXrwzTffBJ4obPRYY0zSGzduHFdffTWrVq1i5cqVrF69moYNG/LVV1/RpEkT1q5dy5IlSwBYtWoV8+fPJyUlhUMOOYR+/fpx2223sWfPHgDWrVvHW2+9ddAxhgwZsq/hOfKWN0kAdO3alTFjxrB7925WrFjB0qVLadeuXb6xjx07li5dulClSpV9yzIyMvbFM3LkSM4880yqV69O/fr1mTlzJjt27EBV+eyzz2jatGmJ37/CWKIwxiS90aNHc2mekZsvu+wy3nnnHSpXrsxbb73FddddR0pKCj179mTkyJHUqFEDgCeeeIIjjzySZs2a0aJFC7p3777vF3txNW/enF69etGsWTM6d+7MsGHDKF++PAAXX3wxa9fuv1JgzJgx9O3b94DXL1myhObNm3PSSScxdepUXn75ZQDat29Pz549adu2LS1btmTv3r3079+/RLH6IcnWGzU1NVXT0tLCDsMYE2HJkiVx+WVr/Mnv7yEic1Q1tTj7sxKFMcaYqCxRGGOMicoShTEmJpKtGru0CuLvYInCGFNiVapUYdOmTZYsQpY7H0VkD6pYsOsojDElVrduXdLT0wljGgBzoNwZ7mLJEoUxpsQqVqwY0xnVTGKxqidjjDFRWaIwxhgTlSUKY4wxUSXdldkisgFYFdLhawMbQzp2GMra+YKdc1lRFs/5RFWNPvJhAZKuMVtVSzYISwmISFpxL4FPRmXtfMHOuawoq+dc3Nda1ZMxxpioLFEYY4yJyhJF0YwIO4A4K2vnC3bOZYWdcxEkXWO2McaY+LIShTHGmKgsURhjjInKEkUeItJZRH4SkWUictBkuCJSWUTe9dZ/JyIN4h9lbPk450EislhEFojIZyJyXBhxxlJh5xyxXU8RURFJ+q6Ufs5ZRHp5f+tFIvJOvGOMNR+f7foiMl1Evvc+3xeHEWesiMgbIvKbiCwsYL2IyFDv/VggIm197VhV7ebdgPLAz8DxQCVgPtAszzY3A695j/sA74YddxzO+RzgEO/xTWXhnL3tqgFfADOB1LDjjsPfuQnwPXC49/wPYccdh3MeAdzkPW4GrAw77hKe85lAW2BhAesvBqYCAnQAvvOzXytRHKgdsExVl6vqHmAM0C3PNt2Af3mPxwGdRETiGGOsFXrOqjpdVXd4T2cCsR3DOP78/J0BHgeeBXbFM7iA+DnnvwDDVHULgKr+FucYY83POStQ3XtcA1gbx/hiTlW/ADZH2aQbMEqdmUBNETmmsP1aojhQHWB1xPN0b1m+26hqNrAVqBWX6ILh55wj9cP9IklmhZ6ziLQB6qnqh/EMLEB+/s4nACeIyNciMlNEOsctumD4OedHgKtEJB2YAtwan9BCU9T/dyAJh/AIWH4lg7z9h/1sk0x8n4+IXAWkAmcFGlHwop6ziJQDhgDXxiugOPDzd66Aq346G1dq/FJEWqhqRsCxBcXPOfcF3lTVF0SkI/Bv75z3Bh9eKIr1/WUligOlA/Uintfl4KLovm1EpAKuuBqtqJfo/JwzInIecD/QVVV3xym2oBR2ztWAFsAMEVmJq8udnOQN2n4/25NUNUtVVwA/4RJHsvJzzv2A9wBU9VugCm7AwNLK1/97XpYoDjQbaCIiDUWkEq6xenKebSYD13iPewKfq9dKlKQKPWevGmY4Lkkke701FHLOqrpVVWuragNVbYBrl+mqqsUeVC0B+PlsT8R1XEBEauOqopbHNcrY8nPOvwCdAESkKS5RlOb5XCcDV3u9nzoAW1V1XWEvsqqnCKqaLSIDgGm4HhNvqOoiEXkMSFPVycA/cMXTZbiSRJ/wIi45n+f8HHAYMNZrt/9FVbuGFnQJ+TznUsXnOU8DLhCRxUAOcLeqbgov6pLxec53Aq+LyB24Kphrk/mHn4iMxlUd1vbaXR4GKgKo6mu4dpiLgWXADuA6X/tN4vfEGGNMHFjVkzHGmKgsURhjjInKEoUxxpioLFEYY4yJyhKFMcaYqCxRmIQjIjkiMi/i1iDKtg0KGimziMec4Y0yOt8bwuLEYuzjRhG52nt8rYgcG7FupIg0i3Gcs0UkxcdrbheRQ0p6bFN2WaIwiWinqqZE3FbG6bhXqmpr3KCPzxX1xar6mqqO8p5eCxwbse56VV0ckyj3x/kq/uK8HbBEYYrNEoVJCl7J4UsRmevdTs1nm+YiMssrhSwQkSbe8qsilg8XkfKFHO4LoLH32k7eXAU/eGP9V/aWPy375+h43lv2iIjcJSI9cWNive0ds6pXEkgVkZtE5NmImK8Vkb8VM85viRjQTUT+LiJp4uaSeNRbdhsuYU0XkenesgtE5FvvfRwrIocVchxTxlmiMImoakS10wRv2W/A+araFugNDM3ndTcCL6tqCu6LOt0blqE3cJq3PAe4spDjXwL8ICJVgDeB3qraEjeSwU0icgRwKdBcVVsBT0S+WFXHAWm4X/4pqrozYvU4oEfE897Au8WMszNu2I1c96tqKtAKOEtEWqnqUNxYPueo6jne0BwPAOd572UaMKiQ45gyzobwMIlop/dlGaki8IpXJ5+DG4cor2+B+0WkLjBeVZeKSCfgZGC2N/xIVVzSyc/bIrITWIkbbvpEYIWq/s9b/y/gFuAV3BwVI0XkI8D3UOSqukFElnvj7Cz1jvG1t9+ixHkobliKyBnKeolIf9z/9TG4iXgW5HltB2/5195xKuHeN2MKZInCJIs7gF+B1riS8EGTCanqOyLyHfBHYJqIXI8bVvlfqnqvj2NcGTnwn4jkO8+IN4ZQO9xgcn2AAcC5RTiXd4FewI/ABFVVcd/avuPEzdb2NDAM6CEiDYG7gFNUdYuIvIkb4C4vAT5R1b5FiNeUcVb1ZJJFDWCdN0/An3C/pg8gIscDy73qlsm4KpjPgJ4i8gdvmyPE/5zfPwINRKSx9/xPwH+9Ov0aqjoF11CcX8+jTNxw5fkZD3THzYXwrresSHGqahauCqmDV21VHdgObBWRo4CLCohlJnBa7jmJyCEikl/pzJh9LFGYZPEqcI2IzMRVO23PZ5vewEIRmQechJvycTHuC/U/IrIA+ARXLVMoVd2FG11zrIj8AOwFXsN96X7o7e+/uNJOXm8Cr+U2ZufZ7xZgMXCcqs7ylhU5Tq/t4wXgLlWdj5vvehHwBq46K9cIYKqITFfVDbgeWaO948zEvVfGFMhGjzXGGBOVlSiMMcZEZYnCGGNMVJYojDHGRGWJwhhjTFSWKIwxxkRlicIYY0xUliiMMcZE9f/lglW9i4dWMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_13 = model_13_best.predict_proba(X_test_red)[:, 1]\n",
    "\n",
    "fpr_13, tpr_13, thresholds_13 = roc_curve(y_test, y_pred_13)\n",
    "\n",
    "roc_auc_13 = auc(fpr_13, tpr_13)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_13, tpr_13, 'b',label='AUC = %0.3f'% roc_auc_13)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST_SIZE = 0.4**\n",
    "\n",
    "| ORDER | LIBRARY | MODEL                              | STATE_0 | STATE_1 | STATE_2 | STATE_3 | STATE_4 | MEAN   | STD      |\n",
    "|-------|---------|------------------------------------|---------|---------|---------|---------|---------|--------|----------|\n",
    "| 3     | keras   | LogisticRegression                 | 0,808   | 0,805   | 0,787   | 0,73    | 0,739   | 0,7738 | 0,036901 |\n",
    "| 1     | sklearn | LogisticRegression                 | 0,8     | 0,769   | 0,806   | 0,739   | 0,724   | 0,7676 | 0,036212 |\n",
    "| 5     | keras   | FNN (2)                            | 0,826   | 0,747   | 0,788   | 0,728   | 0,742   | 0,7662 | 0,040202 |\n",
    "| 12    | sklearn | Bagging, Dimension--               | 0,795   | 0,798   | 0,806   | 0,704   | 0,726   | 0,7658 | 0,047193 |\n",
    "| 13    | sklearn | AdaBoost, Dimension--              | 0,798   | 0,759   | 0,8     | 0,722   | 0,747   | 0,7652 | 0,033626 |\n",
    "| 6     | sklearn | LDA, Dimension--                   | 0,809   | 0,773   | 0,798   | 0,732   | 0,714   | 0,7652 | 0,041167 |\n",
    "| 2     | sklearn | LogisticRegression, Dimension--    | 0,809   | 0,769   | 0,793   | 0,731   | 0,724   | 0,7652 | 0,037326 |\n",
    "| 9     | sklearn | Bagging, DecisionTree              | 0,748   | 0,802   | 0,805   | 0,733   | 0,728   | 0,7632 | 0,037533 |\n",
    "| 10    | sklearn | Bagging, DecisionTree, Dimension-- | 0,817   | 0,764   | 0,796   | 0,724   | 0,703   | 0,7608 | 0,047704 |\n",
    "| 4     | keras   | FNN (1)                            | 0,82    | 0,724   | 0,723   | 0,694   | 0,715   | 0,7352 | 0,048915 |\n",
    "| 8     | sklearn | DecisionTree, Dimension--          | 0,74    | 0,67    | 0,7     | 0,711   | 0,644   | 0,693  | 0,037121 |\n",
    "| 7     | sklearn | QDA, Dimension--                   | 0,806   | 0,479   | 0,724   | 0,708   | 0,703   | 0,684  | 0,121908 |\n",
    "| 11    | sklearn | RandomForest                       | 0,737   | 0,571   | 0,669   | 0,617   | 0,55    | 0,6288 | 0,07585  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST_SIZE = 0.25**\n",
    "\n",
    "| ORDER | LIBRARY | MODEL                              | STATE_0 | STATE_1 | STATE_2 | STATE_3 | STATE_4 | MEAN   | STD      |\n",
    "|-------|---------|------------------------------------|---------|---------|---------|---------|---------|--------|----------|\n",
    "| 5     | keras   | FNN (2)                            | 0,821   | 0,829   | 0,826   | 0,705   | 0,761   | 0,7884 | 0,054386 |\n",
    "| 9     | sklearn | Bagging, DecisionTree              | 0,768   | 0,815   | 0,853   | 0,687   | 0,728   | 0,7702 | 0,066277 |\n",
    "| 10    | sklearn | Bagging, DecisionTree, Dimension-- | 0,765   | 0,799   | 0,822   | 0,697   | 0,741   | 0,7648 | 0,049002 |\n",
    "| 3     | keras   | LogisticRegression                 | 0,806   | 0,749   | 0,825   | 0,703   | 0,737   | 0,764  | 0,050398 |\n",
    "| 1     | sklearn | LogisticRegression                 | 0,783   | 0,772   | 0,812   | 0,697   | 0,735   | 0,7598 | 0,04464  |\n",
    "| 2     | sklearn | LogisticRegression, Dimension--    | 0,783   | 0,773   | 0,812   | 0,704   | 0,724   | 0,7592 | 0,044246 |\n",
    "| 4     | keras   | FNN (1)                            | 0,797   | 0,797   | 0,776   | 0,687   | 0,738   | 0,759  | 0,046909 |\n",
    "| 13    | sklearn | AdaBoost, Dimension--              | 0,765   | 0,748   | 0,824   | 0,698   | 0,747   | 0,7564 | 0,045313 |\n",
    "| 12    | sklearn | Bagging, Dimension--               | 0,765   | 0,764   | 0,769   | 0,701   | 0,734   | 0,7466 | 0,029074 |\n",
    "| 6     | sklearn | LDA, Dimension--                   | 0,78    | 0,759   | 0,782   | 0,688   | 0,723   | 0,7464 | 0,040352 |\n",
    "| 8     | sklearn | DecisionTree, Dimension--          | 0,684   | 0,771   | 0,721   | 0,591   | 0,615   | 0,6764 | 0,074262 |\n",
    "| 11    | sklearn | RandomForest                       | 0,571   | 0,678   | 0,701   | 0,592   | 0,548   | 0,618  | 0,067591 |\n",
    "| 7     | sklearn | QDA, Dimension--                   | 0,508   | 0,471   | 0,466   | 0,675   | 0,498   | 0,5236 | 0,086466 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST_SIZE = 0.2**\n",
    "\n",
    "| ORDER | LIBRARY | MODEL                              | STATE_0 | STATE_1 | STATE_2 | STATE_3 | STATE_4 | MEAN   | STD      |\n",
    "|-------|---------|------------------------------------|---------|---------|---------|---------|---------|--------|----------|\n",
    "| 5     | keras   | FNN (2)                            | 0,815   | 0,824   | 0,815   | 0,703   | 0,753   | 0,782  | 0,052498 |\n",
    "| 3     | keras   | LogisticRegression                 | 0,837   | 0,827   | 0,785   | 0,722   | 0,725   | 0,7792 | 0,054472 |\n",
    "| 9     | sklearn | Bagging, DecisionTree              | 0,811   | 0,828   | 0,784   | 0,712   | 0,7     | 0,767  | 0,058009 |\n",
    "| 13    | sklearn | AdaBoost, Dimension--              | 0,809   | 0,802   | 0,779   | 0,684   | 0,757   | 0,7662 | 0,050296 |\n",
    "| 2     | sklearn | LogisticRegression, Dimension--    | 0,828   | 0,819   | 0,76    | 0,709   | 0,713   | 0,7658 | 0,056451 |\n",
    "| 1     | sklearn | LogisticRegression                 | 0,808   | 0,815   | 0,779   | 0,709   | 0,713   | 0,7648 | 0,050953 |\n",
    "| 10    | sklearn | Bagging, DecisionTree, Dimension-- | 0,8     | 0,811   | 0,781   | 0,685   | 0,726   | 0,7606 | 0,053435 |\n",
    "| 12    | sklearn | Bagging, Dimension--               | 0,812   | 0,838   | 0,775   | 0,664   | 0,702   | 0,7582 | 0,073445 |\n",
    "| 6     | sklearn | LDA, Dimension--                   | 0,803   | 0,817   | 0,75    | 0,711   | 0,705   | 0,7572 | 0,051441 |\n",
    "| 4     | keras   | FNN (1)                            | 0,815   | 0,737   | 0,809   | 0,654   | 0,72    | 0,747  | 0,066981 |\n",
    "| 8     | sklearn | DecisionTree, Dimension--          | 0,757   | 0,798   | 0,749   | 0,617   | 0,735   | 0,7312 | 0,068009 |\n",
    "| 7     | sklearn | QDA, Dimension--                   | 0,816   | 0,46    | 0,656   | 0,579   | 0,68    | 0,6382 | 0,131279 |\n",
    "| 11    | sklearn | RandomForest                       | 0,7     | 0,695   | 0,587   | 0,563   | 0,473   | 0,6036 | 0,095691 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
